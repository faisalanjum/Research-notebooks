{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "0. For Feature Selection, we fit only on X and it fits only on Train Data - The scoring functions are however based on Time Series CV splits (which first fits the data on Train indices and then scores on Test Indices)\n",
    "1. sample_weights - If we want to use strategy P&L as score, we can't assign maximum weights to \"0\" values in sample_weights\n",
    "2. Outlier Detection & removal\n",
    "3. Imputation\n",
    "4. Create Score function - P&L - Based on Long Short position, position size and % return\n",
    "5. Rectify Class Imbalance \n",
    "6. F1_score weighted looks odd - even when both precision_weighted and recall_weighted is lower, f1_weighed is higher?\n",
    "7. Check each number in features_df!\n",
    "8. If we put returns as Sample weights, he model will ignore all rows where returns equals 0 and that class will be under represented - Look at class_weight and sample_weight - However, if we do # 1, then sample_weights no longer reflect P&L and we want our score function to represent that\n",
    "\n",
    "\n",
    "** Not able to pass sample_weight to transformation fit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**autoreload script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import _model_build_func\n",
    "# import importlib\n",
    "# importlib.reload(_model_build_func)\n",
    "# from _model_build_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions List**\n",
    "1. metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))  - return df          \n",
    "2. predictions_from_custom_cross_val(model,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=False) - returns original, predicted\n",
    "3. probabilities_from_custom_cross_val(model,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=False) - returns original, predicted_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 3.30 minutes to run\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from support._model_build_func import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in Getting Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Raw data from Excel\n",
    "2. Imputing Values for missing values - Backfilling and then frontfilling Variables DataFrame, and filling zeros with Median? - Check if it makes sense\n",
    "3. Adding Date Features\n",
    "4. Adding Technical Indicator Features\n",
    "5. Replacing punctuation strings in column names\n",
    "6. Finding Last Available Date for each column\n",
    "7. For now using custom based method - but change it eventually with KNN (or Multivariate) Imputation etc.- # Takes 35 secounds to run\n",
    "8. Remove Variables with all NaNs\n",
    "9. Change Bool cols (mostly date columns such as Is_year_end etc.) to int columns\n",
    "10. Winsorzing/Capping ['Adj_ret_2', 'Close_ret'] - **Instead of capping Adj_ret_2/Close_ret - try to figure out why we see abnormal returns such as -40% and +27%** - We don't now since using different adjustment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2675, 2675, (2675, 723), (2675, 7))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables = Variables_.copy(deep=True)\n",
    "Response = Response_.copy(deep=True)\n",
    "Variables_midx = Variables_midx_.copy(deep=True)\n",
    "last_valid_loc = last_valid_loc_.copy(deep=True)\n",
    "Variables_with_nans = Variables_with_nans_\n",
    "\n",
    "len(Variables), len(Response), Variables.shape, Response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiClassification Targets - Choose between 3 or 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1037625697130806, -0.09252264990408168, 1670.5, 216.2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Response.Adj_ret_3.max(), Response.Adj_ret_3.min(), Response.Close_3.max(), Response.Close_3.min()\n",
    "# Response.iloc[Response.Close_3.argmax()], Response.iloc[Response.Close_3.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      " 0        928\n",
      " 1        886\n",
      "-1        861\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pv_1 = 0.0025 # higher and lower than 0.25% return\n",
    "pv_2 = 0.0075 # higher and lower than 1% return\n",
    "col = 'Adj_ret_3'\n",
    "\n",
    "num_classes = 3 # Choose 3 or 5\n",
    "Response = get_multiclass_labels(num_classes,pv_1,pv_2, Response,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Engineered Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add engineered variables to this list\n",
    "\n",
    "emginereed_list = ['NetSpecLength','InvByOrder', 'lumbermovingaverages MA200', 'lumbermovingaverages MA30','LumberAdjusteddfs BasisByDte2',\n",
    "                'LumberContractSpreads FirstSecond', 'Investingdotcom USMBAPurchaseIndex', 'OverNightRates EFFR',]\n",
    "\n",
    "def add_engineered_variables(df1,var1,var2,func,new_name):\n",
    "    df = df1.copy(deep=True)\n",
    "    df[new_name] = func(df[var1],df[var2])\n",
    "    return df\n",
    "\n",
    "# 1. NET SPEC LENGTH, difference(1), no lags or roll\n",
    "var1 = \"CFTCdisaggregated PctofOIMMoneyLongAll\"\n",
    "var2 = \"CFTCdisaggregated PctofOIMMoneyShortAll\"\n",
    "feat_name_ = 'NetSpecLength'\n",
    "#inplace operation\n",
    "Variables = add_engineered_variables(Variables,var1,var2,func=np.subtract,new_name=feat_name_)\n",
    "\n",
    "# This is for calculating the change in the variable rather than absolute value\n",
    "Variables[feat_name_] = Variables[feat_name_].sort_index(ascending=True).diff().replace(np.nan,0)\n",
    "\n",
    "\n",
    "# 2. Inventory By Order, difference(1), 5 day lags\n",
    "var1 = \"WesternLumberinventorywestern WesternTotal\"\n",
    "var2 = \"WesternLumberorderswestern WesternTotal\"\n",
    "feat_name_ = 'InvByOrder'\n",
    "#inplace operation\n",
    "Variables = add_engineered_variables(Variables,var1,var2,func=np.divide,new_name=feat_name_)\n",
    "# Variables[feat_name_] = Variables[feat_name_].sort_index(ascending=True).pct_change().replace(np.nan,0)\n",
    "# Variables[feat_name_] = Variables[feat_name_][:30].sort_index(ascending=True).rolling(5).mean().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NetSpecLength</th>\n",
       "      <th>InvByOrder</th>\n",
       "      <th>lumbermovingaverages MA200</th>\n",
       "      <th>lumbermovingaverages MA30</th>\n",
       "      <th>LumberAdjusteddfs BasisByDte2</th>\n",
       "      <th>LumberContractSpreads FirstSecond</th>\n",
       "      <th>Investingdotcom USMBAPurchaseIndex</th>\n",
       "      <th>OverNightRates EFFR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-15</th>\n",
       "      <td>-4.3</td>\n",
       "      <td>1.064154</td>\n",
       "      <td>210.023653</td>\n",
       "      <td>13.056653</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>6.600037</td>\n",
       "      <td>205.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.064154</td>\n",
       "      <td>202.857683</td>\n",
       "      <td>8.856689</td>\n",
       "      <td>0.169232</td>\n",
       "      <td>2.699951</td>\n",
       "      <td>205.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.064154</td>\n",
       "      <td>196.389069</td>\n",
       "      <td>5.340737</td>\n",
       "      <td>-0.807407</td>\n",
       "      <td>-1.200012</td>\n",
       "      <td>205.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.064154</td>\n",
       "      <td>244.991736</td>\n",
       "      <td>55.808993</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>-1.200012</td>\n",
       "      <td>205.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.064154</td>\n",
       "      <td>278.218250</td>\n",
       "      <td>91.866939</td>\n",
       "      <td>2.437931</td>\n",
       "      <td>-10.700012</td>\n",
       "      <td>208.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-08</th>\n",
       "      <td>-11.5</td>\n",
       "      <td>1.069193</td>\n",
       "      <td>318.169027</td>\n",
       "      <td>135.417276</td>\n",
       "      <td>3.693333</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>208.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069193</td>\n",
       "      <td>297.499783</td>\n",
       "      <td>119.322768</td>\n",
       "      <td>2.903226</td>\n",
       "      <td>-4.200012</td>\n",
       "      <td>208.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069193</td>\n",
       "      <td>304.420477</td>\n",
       "      <td>130.420315</td>\n",
       "      <td>3.806250</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>208.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069193</td>\n",
       "      <td>276.645228</td>\n",
       "      <td>106.761061</td>\n",
       "      <td>2.842424</td>\n",
       "      <td>-19.099976</td>\n",
       "      <td>208.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069193</td>\n",
       "      <td>263.808566</td>\n",
       "      <td>97.117508</td>\n",
       "      <td>3.111764</td>\n",
       "      <td>-23.500000</td>\n",
       "      <td>206.4</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NetSpecLength  InvByOrder  lumbermovingaverages MA200  \\\n",
       "2022-08-15           -4.3    1.064154                  210.023653   \n",
       "2022-08-12            0.0    1.064154                  202.857683   \n",
       "2022-08-11            0.0    1.064154                  196.389069   \n",
       "2022-08-10            0.0    1.064154                  244.991736   \n",
       "2022-08-09            0.0    1.064154                  278.218250   \n",
       "2022-08-08          -11.5    1.069193                  318.169027   \n",
       "2022-08-05            0.0    1.069193                  297.499783   \n",
       "2022-08-04            0.0    1.069193                  304.420477   \n",
       "2022-08-03            0.0    1.069193                  276.645228   \n",
       "2022-08-02            0.0    1.069193                  263.808566   \n",
       "\n",
       "            lumbermovingaverages MA30  LumberAdjusteddfs BasisByDte2  \\\n",
       "2022-08-15                  13.056653                       0.452000   \n",
       "2022-08-12                   8.856689                       0.169232   \n",
       "2022-08-11                   5.340737                      -0.807407   \n",
       "2022-08-10                  55.808993                       0.971429   \n",
       "2022-08-09                  91.866939                       2.437931   \n",
       "2022-08-08                 135.417276                       3.693333   \n",
       "2022-08-05                 119.322768                       2.903226   \n",
       "2022-08-04                 130.420315                       3.806250   \n",
       "2022-08-03                 106.761061                       2.842424   \n",
       "2022-08-02                  97.117508                       3.111764   \n",
       "\n",
       "            LumberContractSpreads FirstSecond  \\\n",
       "2022-08-15                           6.600037   \n",
       "2022-08-12                           2.699951   \n",
       "2022-08-11                          -1.200012   \n",
       "2022-08-10                          -1.200012   \n",
       "2022-08-09                         -10.700012   \n",
       "2022-08-08                         -11.000000   \n",
       "2022-08-05                          -4.200012   \n",
       "2022-08-04                         -14.000000   \n",
       "2022-08-03                         -19.099976   \n",
       "2022-08-02                         -23.500000   \n",
       "\n",
       "            Investingdotcom USMBAPurchaseIndex  OverNightRates EFFR  \n",
       "2022-08-15                               205.4                 2.33  \n",
       "2022-08-12                               205.4                 2.33  \n",
       "2022-08-11                               205.4                 2.33  \n",
       "2022-08-10                               205.4                 2.33  \n",
       "2022-08-09                               208.4                 2.33  \n",
       "2022-08-08                               208.4                 2.33  \n",
       "2022-08-05                               208.4                 2.33  \n",
       "2022-08-04                               208.4                 2.33  \n",
       "2022-08-03                               208.4                 2.33  \n",
       "2022-08-02                               206.4                 2.33  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables[emginereed_list][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset in 3 Dictionaries of Training, Testing & Validation & Initiating features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: If metric calculations in add_metric function is calculated on Data which has even one class missing from y_predictions, it will throw an error (when error='raise' used), or it will be NaN for (roc_auc_ovr_weighted & roc_auc_ovo_weighted) if this option is not used in cross_val_score..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict, X_test_dict, X_val_dict, y_train, y_test, y_val, sample_weights_train, sample_weights_test, sample_weights_val \\\n",
    "    = ttv_split(Variables, Response, test_size=0.50, Validation_date_start = '2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>End_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lumber_Track_north_american_production</th>\n",
       "      <th>Prairies_And_Eastern_Canada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_North_America</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lumber_Track_north_american_shipment</th>\n",
       "      <th>Prairies_And_Eastern_Canada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_North_America</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CFTC_legacy</th>\n",
       "      <th>Total_Reportable_Positions_Long_All</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration_Gross_LT_4_TDR_Short_Ol</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             End_Dt\n",
       "Lumber_Track_north_american_production Prairies_And_Eastern_Canada              NaT\n",
       "                                       Total_North_America                      NaT\n",
       "Lumber_Track_north_american_shipment   Prairies_And_Eastern_Canada              NaT\n",
       "                                       Total_North_America                      NaT\n",
       "CFTC_legacy                            Total_Reportable_Positions_Long_All      NaT\n",
       "                                       Concentration_Gross_LT_4_TDR_Short_Ol    NaT"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_valid_loc[last_valid_loc.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why these variables have NaNs\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Variables_with_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CFTC_legacy', 'Concentration_Gross_LT_4_TDR_Short_Ol'),\n",
       " ('CFTC_legacy', 'Total_Reportable_Positions_Long_All'),\n",
       " ('Lumber_Track_north_american_production', 'Prairies_And_Eastern_Canada'),\n",
       " ('Lumber_Track_north_american_production', 'Total_North_America'),\n",
       " ('Lumber_Track_north_american_shipment', 'Prairies_And_Eastern_Canada'),\n",
       " ('Lumber_Track_north_american_shipment', 'Total_North_America')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables_with_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Types\n",
      "float64    708\n",
      "int64       10\n",
      "int32        7\n",
      "dtype: int64\n",
      "Total Variables: 725\n",
      "\n",
      "\n",
      "Response Types\n",
      "float64    7\n",
      "int32      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Variable Types\")\n",
    "print(pd.Series(Variables.dtypes.values).value_counts())\n",
    "print(\"Total Variables:\",pd.Series(Variables.dtypes.values).value_counts().sum())\n",
    "\n",
    "print('\\n')\n",
    "print(\"Response Types\")\n",
    "print(pd.Series(Response.dtypes.values).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample weights - Removed Outliers from Response by replacing with IQR*1.5 upper and lower limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.1037625697130806\n",
      "Min: -0.09252264990408168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0935, -0.0707]      0.22\n",
       "(-0.0707, -0.0489]      1.50\n",
       "(-0.0489, -0.0271]      6.95\n",
       "(-0.0271, -0.00528]    27.74\n",
       "(-0.00528, 0.0165]     42.58\n",
       "(0.0165, 0.0383]       16.67\n",
       "(0.0383, 0.0601]        3.66\n",
       "(0.0601, 0.082]         0.52\n",
       "(0.082, 0.104]          0.15\n",
       "Name: Adj_ret_3, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Adj_ret_3'\n",
    "create_bins_data(Response, col, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagnostic_plots(Response, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sample_weights\n",
      "Labels                \n",
      "-1          880.046639\n",
      " 0          930.858799\n",
      " 1          906.888052\n",
      "        sample_weights\n",
      "Labels                \n",
      "-1            1.022122\n",
      " 0            1.003081\n",
      " 1            1.023576\n"
     ]
    }
   ],
   "source": [
    "# print(winsoriser.left_tail_caps_)\n",
    "# print(winsoriser.right_tail_caps_)\n",
    "\n",
    "print(Response[['Labels','sample_weights']].groupby('Labels').sum())\n",
    "print(Response[['Labels','sample_weights']].groupby('Labels').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels\n",
       " 0        0.346916\n",
       " 1        0.331215\n",
       "-1        0.321869\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Response[['Labels']].value_counts()/len(Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1.1037625697130806\n",
      "Min: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.999, 1.012]    48.07\n",
       "(1.012, 1.023]    27.03\n",
       "(1.023, 1.035]    13.42\n",
       "(1.035, 1.046]     6.99\n",
       "(1.046, 1.058]     2.80\n",
       "(1.058, 1.069]     1.05\n",
       "(1.069, 1.081]     0.45\n",
       "(1.081, 1.092]     0.07\n",
       "(1.092, 1.104]     0.11\n",
       "Name: sample_weights, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bins_data(Response, 'sample_weights', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION METRICS & generate_sample_confusion_matrix\n",
    "    1. Recall/Sensitivity/TPR: tp / (tp + fn) - **%age of a TRUE/Positives class correctly identified/ ability to find all the positive samples**. This decides how many times we trade since its the propotion of actual positives we are able to detect.\n",
    "    2. Specificity (TNR) is tn / (tn + fp) - %age of a FALSE/Negatives class correctly identified\n",
    "    3. False Positive Rate (FPR) = 1 - Specificity or fp / (tn + fp). \n",
    "    4. Accuracy is TP+ TN/ entire matrix sum - only for Binary classification\n",
    "    5. Precision is tp / (tp + fp) - the ability not to label a negative sample as positive. This decides our PROFITABILITY since we don't want FALSE Positives\n",
    "    6. Support is the number of occurrences of each class  - sum of respective row\n",
    "    7. Macro - unweighted mean. This does not take label imbalance into account.\n",
    "    8. Wt_Avg - average weighted by support\n",
    "    9. Micro - same as accuracy - sum of diagnols/ sum of all matrix\n",
    "\n",
    "**True/False (Positives/Negatives) means if a sample belongs/doesn't belong to a class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1cc59_row0_col0, #T_1cc59_row0_col1, #T_1cc59_row1_col0, #T_1cc59_row1_col1 {\n",
       "  color: red;\n",
       "}\n",
       "#T_1cc59_row0_col2, #T_1cc59_row1_col2 {\n",
       "  color: orange;\n",
       "}\n",
       "#T_1cc59_row2_col0, #T_1cc59_row2_col1 {\n",
       "  color: blue;\n",
       "}\n",
       "#T_1cc59_row2_col2 {\n",
       "  color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1cc59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1cc59_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_1cc59_level1_col0\" class=\"col_heading level1 col0\" >-1</th>\n",
       "      <th id=\"T_1cc59_level1_col1\" class=\"col_heading level1 col1\" >0</th>\n",
       "      <th id=\"T_1cc59_level1_col2\" class=\"col_heading level1 col2\" >1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1cc59_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">Actual</th>\n",
       "      <th id=\"T_1cc59_level1_row0\" class=\"row_heading level1 row0\" >-1</th>\n",
       "      <td id=\"T_1cc59_row0_col0\" class=\"data row0 col0\" >True Negative</td>\n",
       "      <td id=\"T_1cc59_row0_col1\" class=\"data row0 col1\" >True Negative</td>\n",
       "      <td id=\"T_1cc59_row0_col2\" class=\"data row0 col2\" >False Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cc59_level1_row1\" class=\"row_heading level1 row1\" >0</th>\n",
       "      <td id=\"T_1cc59_row1_col0\" class=\"data row1 col0\" >True Negative</td>\n",
       "      <td id=\"T_1cc59_row1_col1\" class=\"data row1 col1\" >True Negative</td>\n",
       "      <td id=\"T_1cc59_row1_col2\" class=\"data row1 col2\" >False Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cc59_level1_row2\" class=\"row_heading level1 row2\" >1</th>\n",
       "      <td id=\"T_1cc59_row2_col0\" class=\"data row2 col0\" >False Negative</td>\n",
       "      <td id=\"T_1cc59_row2_col1\" class=\"data row2 col1\" >False Negative</td>\n",
       "      <td id=\"T_1cc59_row2_col2\" class=\"data row2 col2\" >True Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ba50dbb550>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = Response.Labels.unique()\n",
    "lab.sort()\n",
    "\n",
    "generate_sample_confusion_matrix(1,lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocked Time Series cross-validation\n",
    "https://goldinlocks.github.io/Time-Series-Cross-Validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "btscv = BlockingTimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics from Confusion Matrix Custom Func - These metrics (weighted & average) do NOT exactly match the output of features_df metrics** \n",
    "** Also note that the weighted average results are not based on sample_weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAJA \n",
    "\n",
    "# X = pd.concat([X_train_dict['Original'], X_test_dict['Original']], axis=0)\n",
    "# y = pd.concat([y_train, y_test], axis=0)\n",
    "# X.shape, y.shape\n",
    "# model = models[0]\n",
    "# train_idx  = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = False)['train']\n",
    "# test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = False)['test']\n",
    "\n",
    "# # Issue with shape - need to correct \n",
    "# predicted_proba1 = []\n",
    "# for i in range(len(train_idx)):\n",
    "#     model.fit(X.iloc[train_idx[i]], y.Labels.iloc[train_idx[i]])\n",
    "#     predicted_proba1.append(model.predict_proba(X.iloc[test_idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This func is only to initialize the X variables with some features set - typically, we use 'Original' if not passed in\n",
    "def fill_with_dataset(dataset,manual_list, original_dataset = 'Original'):\n",
    "    if manual_list:\n",
    "        X_train_dict[dataset] = X_train_dict[original_dataset][manual_list]\n",
    "        X_test_dict[dataset] = X_test_dict[original_dataset][manual_list]\n",
    "        X_val_dict[dataset] = X_val_dict[original_dataset][manual_list]\n",
    "        \n",
    "    else:\n",
    "        X_train_dict[dataset] = X_train_dict[original_dataset]\n",
    "        X_test_dict[dataset] = X_test_dict[original_dataset]\n",
    "        X_val_dict[dataset] = X_val_dict[original_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this func first fits the transformation to all indices of X_train from cv (btscv), then transforms the features from X_train, X_test and X_val\n",
    "# For each pipeline trasnformation, we are using same sample_weights_train - Not working\n",
    "def transform_features_space(dataset,pipe,sampled_weights=False):\n",
    "    print(\"\\nRemoving Features for dataset:\",dataset)\n",
    "    print(\"# Features before:\",len(X_train_dict[dataset].columns.to_list()))\n",
    "    \n",
    "    X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test,set='combined')\n",
    "    train_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['train']\n",
    "    \n",
    "    # Since this is not working sampled_weights True is same as False\n",
    "    if sampled_weights:\n",
    "\n",
    "        # NOT WORKING\n",
    "        # parameters = {pipe.steps[i][0] + \"__sample_weight\": y.iloc[train_idx].sample_weights.values for i in range(len(pipe.steps))}\n",
    "        # pipe.fit(X.iloc[train_idx], **parameters)\n",
    "        pipe.fit(X.iloc[train_idx])\n",
    "    else:\n",
    "        pipe.fit(X.iloc[train_idx])\n",
    "        \n",
    "    X_train_dict[dataset] = pipe.transform(X_train_dict[dataset])\n",
    "    X_test_dict[dataset] = pipe.transform(X_test_dict[dataset])\n",
    "    X_val_dict[dataset] = pipe.transform(X_val_dict[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_features_df(model,dataset):\n",
    "    model_name = type(model).__name__\n",
    "    features_df.loc[(model_name, dataset),'Num_Features'] = len(X_train_dict[dataset].columns) # so can store list of features\n",
    "    features_df.loc[(model_name, dataset),'Features_List'] = X_train_dict[dataset].columns.to_list()\n",
    "\n",
    "    original_list = set(features_df.loc[(model_name, 'Original'),'Features_List'])\n",
    "    dataset_list = set(features_df.loc[(model_name, dataset),'Features_List'])\n",
    "    removed_list = list(sorted(original_list - dataset_list))\n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Removed_Features'] = removed_list\n",
    "    features_df.loc[(model_name, dataset),'Model_Details'] = model\n",
    "\n",
    "def get_shapes(dataset):\n",
    "    # print(\"\\nShapes for dataset:\",dataset)\n",
    "    print(\"X_train Shape\",X_train_dict[dataset].shape)\n",
    "    print(\"X_test Shape\",X_test_dict[dataset].shape)\n",
    "    print(\"X_val Shape\",X_val_dict[dataset].shape)\n",
    "    # print(\"y_train Shape\",y_train.shape)\n",
    "    # print(\"y_test Shape\",y_test.shape)\n",
    "    # print(\"y_val Shape\",y_val.shape)\n",
    "\n",
    "def print_pipe_removed(pipe):\n",
    "    total_removed = 0\n",
    "    # print(\"\\nRemoved Features for Pipeline:\",pipe)\n",
    "    for i in range(len(pipe.steps)):\n",
    "        step_name = pipe.steps[i][0]\n",
    "        total_removed += len(pipe.named_steps[step_name].features_to_drop_)\n",
    "        print(step_name, \":\",len(pipe.named_steps[step_name].features_to_drop_))\n",
    "    print(\"Total removed:\",total_removed)\n",
    "\n",
    "# Calls all the above 3 functions\n",
    "def insert_and_print(model,dataset,pipe, manual_list):\n",
    "    print(\"\\nInserting Pipeline for dataset:\",dataset)\n",
    "\n",
    "    # This code INSERTS model's basic data into features_df\n",
    "    add_to_features_df(model,dataset)\n",
    "\n",
    "    # This code PRINTS X variables Shape\n",
    "    get_shapes(dataset)\n",
    "\n",
    "    # This code prints the features removed for each pipe step\n",
    "    if not manual_list: print_pipe_removed(pipe)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response['Labels'].unique()\n",
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/42562146/classification-report-with-nested-cross-validation-in-sklearn-average-individua\n",
    "# def predictions_from_custom_cross_val(model,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=False):    \n",
    "#     # Variables to store original and predicted values\n",
    "#     original = []\n",
    "#     predicted = []\n",
    "\n",
    "#     def score_func(y_true, y_pred):\n",
    "#         original.extend(y_true)\n",
    "#         predicted.extend(y_pred)\n",
    "\n",
    "#     if sampled_weights:\n",
    "#     # Cross Val Score with SAMPLE WeIGHTS        \n",
    "#         scores = cross_val_score(model, X, y.Labels, cv=custom_cv, scoring=make_scorer(score_func),fit_params={'sample_weight':y.sample_weights.values} ) #,error_score=\"raise\"\n",
    "#     else:\n",
    "#         scores = cross_val_score(model, X, y.Labels, cv=custom_cv, scoring=make_scorer(score_func) ) #,error_score=\"raise\"\n",
    "#     return original, predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*****Change between Labels & Close_Up_Down columns for y_combined to make it either a Multiclass (5) or (3)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **cross_val_score - accuracy_score**                                                      \n",
    "# scoring https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\n",
    "\n",
    "def add_metrics(model,dataset,X_train_dict,X_test_dict,y_train,y_test,set='combined', sampled_weights=False):\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    metrics_list = ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted','neg_log_loss']\n",
    "\n",
    "    # Using BlockedTimeSeriesSplit cross val to calculate metrics\n",
    "    X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "\n",
    "    for metric in metrics_list:\n",
    "\n",
    "        if sampled_weights:\n",
    "        # cross_val_score with SAMPLE_WEIGHTS\n",
    "            score = cross_val_score(model, X, y.Labels, cv=btscv, scoring = str(metric),fit_params={'sample_weight':y.sample_weights.values}) #,error_score=\"raise\"\n",
    "        else:\n",
    "            score = cross_val_score(model, X, y.Labels, cv=btscv, scoring = str(metric)) #,error_score=\"raise\"\n",
    "            \n",
    "        features_df.loc[(model_name, dataset),metric]= round(np.mean(score),2)\n",
    "\n",
    "    # Calculating Class Wise Metrics - although predictions_from_custom_cross_val uses sample_weights to fit & predict but the metrics_from_cm doesn't use sample_weights\n",
    "    original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=sampled_weights)\n",
    "    cm = pd.DataFrame(confusion_matrix(original, predicted), index=Response['Labels'].unique(), columns=Response['Labels'].unique())\n",
    "    all_class_metric = metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))\n",
    "    \n",
    "    # Calculating pnl_score & sharpe - Adj_ret_3 is Log Returns so can simply add them after multiplying with predictions\n",
    "    Test_adj_returns = y.Adj_ret_3.iloc[get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5)['test']].values.tolist()\n",
    "    return_list = [a*b for a,b in zip(Test_adj_returns,predicted)]\n",
    "    return_std = np.std(return_list) * np.sqrt(250) # Annualized\n",
    "    pnl_score = np.exp(np.average(return_list)*250) - 1 # https://investmentcache.com/magic-of-log-returns-practical-part-2/\n",
    "    sharpe_ratio = (pnl_score - 0.0)/return_std\n",
    "    features_df.loc[(model_name, dataset),'pnl'] = pnl_score\n",
    "    features_df.loc[(model_name, dataset),'sharpe'] = sharpe_ratio \n",
    "\n",
    "     \n",
    "    # Calculating Kappa Score \n",
    "    if sampled_weights:\n",
    "    # Kappa with SAMPLE_WEIGHTS\n",
    "        sample_weights = y.sample_weights.iloc[get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5)['test']].values.tolist()\n",
    "        kappa_score = cohen_kappa_score(original, predicted, sample_weight=sample_weights)\n",
    "    else:\n",
    "        kappa_score = cohen_kappa_score(original, predicted)\n",
    "    \n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Kappa']= kappa_score\n",
    "    \n",
    "    # Insert the dataframe in a cell in features_df\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'] = np.array([])\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'].astype(object)\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'] =  [all_class_metric]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Check!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Metrics from Confusion Matrix Custom Func\n",
    "def metrics_from_cm(cm, lab):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    pre = {}\n",
    "    rec = {}\n",
    "    tp = {}\n",
    "    tn = {}\n",
    "    fp = {}\n",
    "    fn = {}\n",
    "    weighted_average = {}\n",
    "    for cat in lab:\n",
    "        pre[cat] = np.nan_to_num(cm.loc[cat,cat]/cm.sum(axis=0).loc[cat], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        rec[cat] = np.nan_to_num(cm.loc[cat,cat]/cm.sum(axis=1).loc[cat], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        tp[cat] = cm.loc[cat, cat]\n",
    "        tn[cat] = cm.drop(cat,axis=1).drop(cat,axis=0).sum().sum()\n",
    "        fp[cat] = cm[cat].drop(cat).sum()\n",
    "        fn[cat] = cm.loc[cat].drop(cat).sum()\n",
    "\n",
    "    df = pd.concat([pd.DataFrame.from_dict(pre,orient='index', columns=['precision']),pd.DataFrame.from_dict(rec,orient='index', columns=['recall'])], axis=1)\n",
    "    df['fscore'] = (2 * ((df.precision * df.recall) / (df.precision + df.recall))).fillna(0)\n",
    "    df['tp'] = pd.Series(tp)\n",
    "    df['tn'] = pd.Series(tn)\n",
    "    df['fp'] = pd.Series(fp)\n",
    "    df['fn'] = pd.Series(fn)\n",
    "\n",
    "    df['specificity'] =  pd.Series(df.tn / (df.tn + df.fp))\n",
    "    df['fpr'] = pd.Series(df.fp / (df.tn + df.fp))\n",
    "    df['accuracy'] = (df.tp + df.tn) / (df.tp + df.tn + df.fp + df.fn)\n",
    "    df['support'] = cm.sum(axis=1)\n",
    "\n",
    "    main_metrics_list = ['precision', 'recall', 'fscore', 'specificity','fpr', 'accuracy']\n",
    "    df_perc = df[main_metrics_list]\n",
    "    df = pd.concat([df_perc,df.tp,df.tn,df.fp,df.fn,df.support], axis=1)\n",
    "\n",
    "    # Weighted average\n",
    "    for cols in df.columns:\n",
    "        if cols in main_metrics_list:\n",
    "            weighted_average[cols] = df[cols].dot(df.support)/df.support.sum()\n",
    "        else:\n",
    "            weighted_average[cols] = None\n",
    "\n",
    "    df.loc['macro',main_metrics_list] = df[main_metrics_list].mean()\n",
    "\n",
    "    weight_df = pd.DataFrame.from_dict(weighted_average,orient='index', columns=['Wt_Avg']).T\n",
    "    df = pd.concat([df, weight_df], axis=0)\n",
    "\n",
    "    # % Formatting\n",
    "    for col in main_metrics_list:\n",
    "        try:\n",
    "            df[col] = df[col].mul(100).round(0).astype(int).astype(str).add('%')\n",
    "        except:\n",
    "            pass\n",
    "    other_list = ['tp', 'tn', 'fp', 'fn', 'support']\n",
    "\n",
    "    df.loc['macro', other_list] = df.loc[lab, other_list] .sum()\n",
    "    df.loc['Wt_Avg', other_list] = df.loc[lab, other_list] .sum()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original, predicted = predictions_from_custom_cross_val(models[0],X, y, custom_cv = btscv, sampled_weights=True)\n",
    "# predicted.count(1)/len(predicted), predicted.count(-1)/len(predicted), predicted.count(0)/len(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Transformation Func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTE THE MODEL PIPELINES ARE BEING CHECKED/FITTED TO TRAINING DATA WHILE THE METRICS ARE calculated ON Set option in func argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the following steps:\n",
    "# 1. Fill the dataset with passed X Variables\n",
    "# 2. If transform = True is passed, it fits and transforms the X variable. If sampled_weights equals True, it provides test sample weights to the fitting transformation\n",
    "# 3. Inserts model's basic data (length of features etc) into features_df, PRINTS X variables Shape & the features removed for each pipe step\n",
    "# 4. Add metrics to features_df using Blocked Time Series Cross Validation with TEST set\n",
    "\n",
    "def apply_model_transform(dataset,original_dataset, pipe, model,X_train_dict,X_test_dict,y_train,y_test, set='combined',manual_list = None, sampled_weights=False, transform = False):\n",
    "    fill_with_dataset(dataset,manual_list,original_dataset)\n",
    "    if transform: transform_features_space(dataset,pipe,sampled_weights)\n",
    "    insert_and_print(model,dataset,pipe, manual_list)    \n",
    "    add_metrics(model,dataset,X_train_dict,X_test_dict,y_train,y_test,set, sampled_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Models for both Classifiers & Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using xgb_clf for now because it is too slow\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "\n",
    "models = [rf_clf,xgb_clf]\n",
    "# models = [rf_clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe to Store Model Features & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [type(m).__name__ for m in models]\n",
    "dataset = 'Original'\n",
    "multilevel_index = pd.MultiIndex.from_product([model_names,[dataset]],names=['Model', 'Dataset'])\n",
    "cols_names = ['Model_Details','Num_Features','Features_List','Removed_Features'] + ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted','neg_log_loss','Kappa','pnl','sharpe','ClassDf']\n",
    "features_df = pd.DataFrame(columns=cols_names, index=multilevel_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initaiaze Dataset 'Original' as well as features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "X_train Shape (1259, 725)\n",
      "X_test Shape (1260, 725)\n",
      "X_val Shape (156, 725)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAETCAYAAADNpUayAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPjUlEQVR4nO3df6zddX3H8edLCviLX4Ub5tpqO0UN0yldVRSnGbhMcLHEqHMzs9G6JhMnE5fJfrpf2ST7gbpMYyMsxRl/hJlBpnE6RNFsMltgKCCxQbHtUK5Y8FdQi+/9cT5ll3rbe257z/32fvp8JM093x/nnvfNDU++93u+55xUFZKkvjxs6AEkSQvPuEtSh4y7JHXIuEtSh4y7JHVo2dADAJxyyim1evXqoceQpCVl27Zt36yqqdm2HRZxX716NVu3bh16DElaUpLcub9tnpaRpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4dFq9QleZj9cUfGXqEifnqW1809AjqhEfuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQh4y5JHTLuktQhP4lJ0qLp+VO04PD6JC2P3CWpQ8Zdkjo0VtyTvDHJLUm+mOT9SR6eZE2S65NsT/LBJMe0fY9ty9vb9tUT/QkkST9hzrgnWQG8AVhXVU8BjgJeAVwCXFpVTwB2AxvbXTYCu9v6S9t+kqRFNO5pmWXAI5IsAx4J3AWcDVzZtm8Bzm+317dl2vZzkmRBppUkjWXOuFfVLuBvga8xivp9wDbg3qra03bbCaxot1cAO9p997T9T973+ybZlGRrkq3T09OH+nNIkmYY57TMSYyOxtcAPw08CnjhoT5wVW2uqnVVtW5qaupQv50kaYZxTsu8APhKVU1X1Y+ADwNnASe20zQAK4Fd7fYuYBVA234CcM+CTi1JOqBx4v414Mwkj2znzs8BbgWuBV7a9tkAXNVuX92Wads/WVW1cCNLkuYy5ytUq+r6JFcCNwB7gBuBzcBHgA8k+cu27rJ2l8uA9ybZDnyL0ZU1hxVfJSepd2O9/UBVvQV4yz6r7wCeOcu+9wMvO/TRJEkHy1eoSlKHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHxop7khOTXJnkS0luS/LsJMuTfCLJl9vXk9q+SfKOJNuT3Jxk7WR/BEnSvsY9cn878LGqejLwNOA24GLgmqo6DbimLQOcC5zW/m0C3rWgE0uS5jRn3JOcADwPuAygqn5YVfcC64EtbbctwPnt9nrgihr5HHBikscs8NySpAMY58h9DTAN/FOSG5O8J8mjgFOr6q62z9eBU9vtFcCOGfff2dY9RJJNSbYm2To9PX3wP4Ek6SeME/dlwFrgXVV1BvA9/v8UDABVVUDN54GranNVrauqdVNTU/O5qyRpDuPEfSews6qub8tXMor9N/aebmlf727bdwGrZtx/ZVsnSVokc8a9qr4O7EjypLbqHOBW4GpgQ1u3Abiq3b4aeFW7auZM4L4Zp28kSYtg2Zj7/TbwviTHAHcAr2b0P4YPJdkI3Am8vO37UeA8YDvw/bavJGkRjRX3qroJWDfLpnNm2beACw5tLEnSofAVqpLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0y7pLUIeMuSR0aO+5JjkpyY5J/a8trklyfZHuSDyY5pq0/ti1vb9tXT2h2SdJ+zOfI/ULgthnLlwCXVtUTgN3AxrZ+I7C7rb+07SdJWkRjxT3JSuBFwHvacoCzgSvbLluA89vt9W2Ztv2ctr8kaZGMe+T+NuD3gB+35ZOBe6tqT1veCaxot1cAOwDa9vva/g+RZFOSrUm2Tk9PH9z0kqRZzRn3JL8C3F1V2xbygatqc1Wtq6p1U1NTC/mtJemIt2yMfc4CXpzkPODhwPHA24ETkyxrR+crgV1t/13AKmBnkmXACcA9Cz65JGm/5jxyr6rfr6qVVbUaeAXwyap6JXAt8NK22wbgqnb76rZM2/7JqqoFnVqSdECHcp37m4GLkmxndE79srb+MuDktv4i4OJDG1GSNF/jnJZ5UFV9CvhUu30H8MxZ9rkfeNkCzCZJOki+QlWSOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOjRn3JOsSnJtkluT3JLkwrZ+eZJPJPly+3pSW58k70iyPcnNSdZO+oeQJD3UOEfue4A3VdXpwJnABUlOBy4Grqmq04Br2jLAucBp7d8m4F0LPrUk6YDmjHtV3VVVN7Tb3wFuA1YA64EtbbctwPnt9nrgihr5HHBikscs9OCSpP2b1zn3JKuBM4DrgVOr6q626evAqe32CmDHjLvtbOv2/V6bkmxNsnV6enq+c0uSDmDsuCd5NPAvwO9U1bdnbquqAmo+D1xVm6tqXVWtm5qams9dJUlzGCvuSY5mFPb3VdWH2+pv7D3d0r7e3dbvAlbNuPvKtk6StEjGuVomwGXAbVX19zM2XQ1saLc3AFfNWP+qdtXMmcB9M07fSJIWwbIx9jkL+A3gC0luauv+AHgr8KEkG4E7gZe3bR8FzgO2A98HXr2QA0uS5jZn3Kvqs0D2s/mcWfYv4IJDnEuSdAh8haokdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdWgicU/ywiS3J9me5OJJPIYkaf8WPO5JjgL+ETgXOB34tSSnL/TjSJL2bxJH7s8EtlfVHVX1Q+ADwPoJPI4kaT+WTeB7rgB2zFjeCTxr352SbAI2tcXvJrl9ArMcLk4BvrlYD5ZLFuuRjgj+7pa23n9/j9vfhknEfSxVtRnYPNTjL6YkW6tq3dBzaP783S1tR/LvbxKnZXYBq2Ysr2zrJEmLZBJx/zxwWpI1SY4BXgFcPYHHkSTtx4KflqmqPUleD/w7cBRweVXdstCPs8QcEaefOuXvbmk7Yn9/qaqhZ5AkLTBfoSpJHTLuktQh4y5JHTLukrqU5Pgkxw09x1B8QnWCkjwHWM2Mq5Kq6orBBtIBJVl+oO1V9a3FmkUHL8kzgMuB44AA9wKvqaptQ8612Iz7hCR5L/B44Cbggba6quoNgw2lA0ryFaAYBWFfVVU/s8gj6SAkuRm4oKo+05afC7yzqn5u2MkW12BvP3AEWAecXv7fc8moqjVDz6AF8cDesANU1WeT7BlyoCEY98n5IvBTwF1DD6L5S3IScBrw8L3rquq64SbSPHw6ybuB9zP6S+xXgU8lWQtQVTcMOdxi8bTMhCS5Fng68N/AD/aur6oXDzWTxpPktcCFjN4X6SbgTOC/qursIefSeNp/ezAKOzz0NFsdKb9H4z4hSZ4/2/qq+vRiz6L5SfIF4BnA56rq6UmeDPxVVb1k4NF0AEku2nuzfS1gGvhsVX1lmKmG42mZyXkCcF1VfXnoQTRv91fV/UlIcmxVfSnJk4YeSnOa7bLHxwF/mORPq+oDiz3QkIz75DwWeHeS1cA24DrgM1V105BDaSw7k5wI/CvwiSS7gTsHnUhzqqo/m219u8T1Pxh9KtwRw9MyE5bkEcBvAr8LrKiqowYeSfPQTq+dAHysfWyklqAkN1bVGUPPsZg8cp+QJH8EnAU8GriRUdw/c8A7aXDtA95vqaong8+R9CDJLwK7h55jsRn3yXkJsAf4CPBpRldb/ODAd9HQquqBJLcneWxVfW3oeTS+9kT4vqcilgP/C7xq8ScalqdlJijJ8YyO3p8LvAy4u6qeO+xUmkuS64AzGF3G+r29672M9fCWZN8Piy7gnqr63mz7984j9wlJ8hTgF4DnM3q16g48LbNU/PHQA2j+qsonvWcw7pPzVkYxfwfw+ar60cDzaHznVdWbZ65Icgmj02vSkuBpmQlqHxD+xLZ4u4FfGpLcUFVr91l385H2xlNa2jxyn5B2Cd0VwFcZvWJuVZINvj/J4SvJbwGvAx7f3llwr+OA/xxmKungeOQ+IUm2Ab9eVbe35ScC76+qnx92Mu1PkhOAk4C/Bi6esek7vpe7lhrjPiGz/Rnvn/ZLQ5LHzrbeSyO1lBj3CUlyOfBj4J/bqlcCR1XVa4abSuOYcb10GL3l7xpGz5n87KCDSfNg3CckybHABYyucYfRlTPv9IVMS097H/DXVdVrh55FGpdxn6AkUwBVNT30LDo0Sb5QVU8deg5pXF4ts8CSBHgL8HrgYW3dA8A/VNWfDzmbxjPjfcFh9Dtcy+gl7NKS8bChB+jQGxm95cAzqmp5VS0HngWcleSNw46mMR0349+xjN4faP2gE0nz5GmZBZbkRuCXquqb+6yfAj5+pL3t6FKW5JFV9f2h55AOhkfuC+/ofcMOD553P3qAeTRPSZ6d5FbgS235aUneOfBY0rwY94V3oA908MMeloa3Ab8M3ANQVf8DPG/IgaT58gnVhfe0JN+eZf3ea6a1BFTVjtFz4w96YKhZpINh3BeYH6PXhR1JngNUkqOBC4HbBp5JmhefUJX2keQU4O3ACxj9xfVx4MKqumfQwaR5MO6S1CFPy0hNkj85wOaqqr9YtGGkQ+SRu9QkedMsqx8FbAROrqpHL/JI0kEz7tIskhzH6InUjcCHgL+rqruHnUoan6dlpBmSLAcuYvQWzVuAtVW1e9ippPkz7lKT5G+AlwCbgadW1XcHHkk6aJ6WkZokPwZ+AOxh9GEdD25i9ITq8YMMJh0E4y5JHfK9ZSSpQ8Zdkjpk3CWpQ8Zdkjr0fwg832o+QiSWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Takes 8.30 mins to run\n",
    "for m in models:\n",
    "    add_to_features_df(m,dataset='Original')\n",
    "    add_metrics(model=m,dataset='Original',X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test,set='combined')\n",
    "    \n",
    "# Shapes\n",
    "get_shapes(dataset = 'Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Functions to plot Blocked TimeSeries Split****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "cv = BlockingTimeSeriesSplit\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "print(\"The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\")\n",
    "plot_timeseries_split(np.array(X_train_dict['Original']),np.array(y_train.Labels),n_splits,cmap_cv,cmap_data,cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all constant Variables\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why the following features have only one value\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Constant_weighted\n",
      "# Features before: 725\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Constant_weighted\n",
      "X_train Shape (1259, 682)\n",
      "X_test Shape (1260, 682)\n",
      "X_val Shape (156, 682)\n",
      "Constant_weighted : 43\n",
      "Total removed: 43\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Removing Features for dataset: Constant\n",
      "# Features before: 725\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Constant\n",
      "X_train Shape (1259, 682)\n",
      "X_test Shape (1260, 682)\n",
      "X_val Shape (156, 682)\n",
      "Constant : 43\n",
      "Total removed: 43\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Issue with using XGBOOST - takes long time and gives warnigs Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "# Takes 4 minutes to run\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = 'Constant_weighted'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=1, variables=None, missing_values='raise'))])\n",
    "\n",
    "                     \n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None,sampled_weights=True, transform = True)\n",
    "# apply_model_transform(dataset,'Original', pipe, models[1],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None,sampled_weights=True, transform = True)\n",
    "\n",
    "dataset = 'Constant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=1, variables=None, missing_values='raise'))])\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=False, transform = True)\n",
    "# apply_model_transform(dataset,'Original', pipe, models[1],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=False, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>43%</td>\n",
       "      <td>78%</td>\n",
       "      <td>55%</td>\n",
       "      <td>49%</td>\n",
       "      <td>51%</td>\n",
       "      <td>58%</td>\n",
       "      <td>129.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50%</td>\n",
       "      <td>13%</td>\n",
       "      <td>21%</td>\n",
       "      <td>92%</td>\n",
       "      <td>8%</td>\n",
       "      <td>63%</td>\n",
       "      <td>25.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38%</td>\n",
       "      <td>37%</td>\n",
       "      <td>37%</td>\n",
       "      <td>73%</td>\n",
       "      <td>27%</td>\n",
       "      <td>62%</td>\n",
       "      <td>57.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>43%</td>\n",
       "      <td>43%</td>\n",
       "      <td>38%</td>\n",
       "      <td>71%</td>\n",
       "      <td>29%</td>\n",
       "      <td>61%</td>\n",
       "      <td>211.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wt_Avg</th>\n",
       "      <td>44%</td>\n",
       "      <td>42%</td>\n",
       "      <td>37%</td>\n",
       "      <td>72%</td>\n",
       "      <td>28%</td>\n",
       "      <td>61%</td>\n",
       "      <td>211.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision recall fscore specificity  fpr accuracy     tp     tn     fp  \\\n",
       "-1           43%    78%    55%         49%  51%      58%  129.0  165.0  174.0   \n",
       "0            50%    13%    21%         92%   8%      63%   25.0  294.0   25.0   \n",
       "1            38%    37%    37%         73%  27%      62%   57.0  257.0   95.0   \n",
       "macro        43%    43%    38%         71%  29%      61%  211.0  716.0  294.0   \n",
       "Wt_Avg       44%    42%    37%         72%  28%      61%  211.0  716.0  294.0   \n",
       "\n",
       "           fn  support  \n",
       "-1       37.0    166.0  \n",
       "0       161.0    186.0  \n",
       "1        96.0    153.0  \n",
       "macro   294.0    505.0  \n",
       "Wt_Avg  294.0    505.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.loc[('RandomForestClassifier','Constant_weighted'),'ClassDf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1 Model with 1 Feature only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Kappa Score for both these models - one with sampled weights and other without**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_dataset = 'Original'\n",
    "# dataset = 'Enginered'\n",
    "# model = models[0]\n",
    "# feats_to_keep_list = ['BasisbyExpiry','YahooIndex']\n",
    "# # insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined')\n",
    "# apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = feats_to_keep_list, sampled_weights=True, transform = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_dataset = 'Original'\n",
    "# dataset = 'Enginered_No_weights'\n",
    "# model = models[0]\n",
    "# feats_to_keep_list = ['BasisbyExpiry','YahooIndex']\n",
    "# apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = feats_to_keep_list, sampled_weights=False, transform = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.loc[('RandomForestClassifier','Enginered')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.loc[('RandomForestClassifier','Enginered')].loc['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: QuasiConstant\n",
      "# Features before: 725\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: QuasiConstant\n",
      "X_train Shape (1259, 677)\n",
      "X_test Shape (1260, 677)\n",
      "X_val Shape (156, 677)\n",
      "QuasiConstant : 48\n",
      "Total removed: 48\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'QuasiConstant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=0.95, variables=None, missing_values='raise'))])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=True, transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Duplicated\n",
      "# Features before: 725\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Duplicated\n",
      "X_train Shape (1259, 626)\n",
      "X_test Shape (1260, 626)\n",
      "X_val Shape (156, 626)\n",
      "Duplicated : 99\n",
      "Total removed: 99\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'Duplicated'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined', sampled_weights=True, transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated & Quasi Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Dupl&QConstant\n",
      "# Features before: 677\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Dupl&QConstant\n",
      "X_train Shape (1259, 615)\n",
      "X_test Shape (1260, 615)\n",
      "X_val Shape (156, 615)\n",
      "Dupl&QConstant : 62\n",
      "Total removed: 62\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'Dupl&QConstant'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_model_transform(dataset,'QuasiConstant', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Correlated\n",
      "# Features before: 725\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Correlated\n",
      "X_train Shape (1259, 471)\n",
      "X_test Shape (1260, 471)\n",
      "X_val Shape (156, 471)\n",
      "Correlated : 254\n",
      "Total removed: 254\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Correlated'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test,set='combined', sampled_weights=True, transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated, Quasi Constant & Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Clean\n",
      "# Features before: 615\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Clean\n",
      "X_train Shape (1259, 423)\n",
      "X_test Shape (1260, 423)\n",
      "X_val Shape (156, 423)\n",
      "Clean : 192\n",
      "Total removed: 192\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_model_transform(dataset,'Dupl&QConstant', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list=None, sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean1 - Drop constant, quasi Constant, duplicated and correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Clean1\n",
      "# Features before: 725\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n",
      "\n",
      "Inserting Pipeline for dataset: Clean1\n",
      "X_train Shape (1259, 423)\n",
      "X_test Shape (1260, 423)\n",
      "X_val Shape (156, 423)\n",
      "constant : 43\n",
      "quasiConstant : 5\n",
      "duplicated : 62\n",
      "correlation : 192\n",
      "Total removed: 302\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Takes 9 minutes to run\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean1'\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.95, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict,X_test_dict,y_train,y_test, set='combined',manual_list=None, sampled_weights=True, transform = True)\n",
    "\n",
    "# apply_model_transform(dataset,'Original', pipe, models[1],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list=None, sampled_weights=False, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Num_Features</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <th>roc_auc_ovo_weighted</th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>pnl</th>\n",
       "      <th>sharpe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>725</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.118409</td>\n",
       "      <td>0.052694</td>\n",
       "      <td>0.176334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>725</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>-0.228879</td>\n",
       "      <td>-0.716967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>Constant_weighted</th>\n",
       "      <td>682</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.138185</td>\n",
       "      <td>0.137425</td>\n",
       "      <td>0.468989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constant</th>\n",
       "      <td>682</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.133566</td>\n",
       "      <td>-0.163136</td>\n",
       "      <td>-0.556928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuasiConstant</th>\n",
       "      <td>677</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.138789</td>\n",
       "      <td>-0.113017</td>\n",
       "      <td>-0.384452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duplicated</th>\n",
       "      <td>626</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.143069</td>\n",
       "      <td>0.311375</td>\n",
       "      <td>1.056483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dupl&amp;QConstant</th>\n",
       "      <td>615</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.116531</td>\n",
       "      <td>0.266383</td>\n",
       "      <td>0.893443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated</th>\n",
       "      <td>471</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.135501</td>\n",
       "      <td>0.147301</td>\n",
       "      <td>0.502719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean</th>\n",
       "      <td>423</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.155693</td>\n",
       "      <td>0.221785</td>\n",
       "      <td>0.757301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean1</th>\n",
       "      <td>423</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.169703</td>\n",
       "      <td>0.469264</td>\n",
       "      <td>1.606382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Num_Features balanced_accuracy  \\\n",
       "Model                  Dataset                                            \n",
       "RandomForestClassifier Original                   725              0.35   \n",
       "XGBClassifier          Original                   725              0.34   \n",
       "RandomForestClassifier Constant_weighted          682              0.34   \n",
       "                       Constant                   682              0.35   \n",
       "                       QuasiConstant              677              0.34   \n",
       "                       Duplicated                 626              0.34   \n",
       "                       Dupl&QConstant             615              0.34   \n",
       "                       Correlated                 471              0.34   \n",
       "                       Clean                      423              0.34   \n",
       "                       Clean1                     423              0.34   \n",
       "\n",
       "                                         precision_weighted recall_weighted  \\\n",
       "Model                  Dataset                                                \n",
       "RandomForestClassifier Original                         0.3            0.42   \n",
       "XGBClassifier          Original                        0.38            0.38   \n",
       "RandomForestClassifier Constant_weighted               0.25            0.41   \n",
       "                       Constant                        0.23            0.42   \n",
       "                       QuasiConstant                   0.23            0.42   \n",
       "                       Duplicated                      0.27            0.42   \n",
       "                       Dupl&QConstant                  0.21            0.42   \n",
       "                       Correlated                      0.26            0.42   \n",
       "                       Clean                           0.22            0.42   \n",
       "                       Clean1                          0.26            0.43   \n",
       "\n",
       "                                         f1_weighted roc_auc_ovr_weighted  \\\n",
       "Model                  Dataset                                              \n",
       "RandomForestClassifier Original                 0.28                 0.56   \n",
       "XGBClassifier          Original                 0.33                 0.53   \n",
       "RandomForestClassifier Constant_weighted        0.28                 0.56   \n",
       "                       Constant                 0.29                 0.56   \n",
       "                       QuasiConstant            0.28                 0.54   \n",
       "                       Duplicated               0.28                 0.55   \n",
       "                       Dupl&QConstant           0.29                 0.56   \n",
       "                       Correlated               0.27                 0.57   \n",
       "                       Clean                    0.28                 0.55   \n",
       "                       Clean1                   0.28                 0.55   \n",
       "\n",
       "                                         roc_auc_ovo_weighted neg_log_loss  \\\n",
       "Model                  Dataset                                               \n",
       "RandomForestClassifier Original                          0.53        -1.06   \n",
       "XGBClassifier          Original                          0.53        -1.55   \n",
       "RandomForestClassifier Constant_weighted                 0.56        -1.06   \n",
       "                       Constant                          0.57        -1.06   \n",
       "                       QuasiConstant                     0.55        -1.05   \n",
       "                       Duplicated                        0.56        -1.06   \n",
       "                       Dupl&QConstant                    0.55        -1.06   \n",
       "                       Correlated                        0.56        -1.06   \n",
       "                       Clean                             0.57        -1.06   \n",
       "                       Clean1                            0.55        -1.06   \n",
       "\n",
       "                                             Kappa       pnl    sharpe  \n",
       "Model                  Dataset                                          \n",
       "RandomForestClassifier Original           0.118409  0.052694  0.176334  \n",
       "XGBClassifier          Original           0.073308 -0.228879 -0.716967  \n",
       "RandomForestClassifier Constant_weighted  0.138185  0.137425  0.468989  \n",
       "                       Constant           0.133566 -0.163136 -0.556928  \n",
       "                       QuasiConstant      0.138789 -0.113017 -0.384452  \n",
       "                       Duplicated         0.143069  0.311375  1.056483  \n",
       "                       Dupl&QConstant     0.116531  0.266383  0.893443  \n",
       "                       Correlated         0.135501  0.147301  0.502719  \n",
       "                       Clean              0.155693  0.221785  0.757301  \n",
       "                       Clean1             0.169703  0.469264  1.606382  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1).loc[[('RandomForestClassifier','emginereed_list_noweights'),('RandomForestClassifier','emginereed_list_weights'),('RandomForestClassifier','Clean'),('RandomForestClassifier','Original')]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECTED ENGINEERED Feature List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NET SPEC Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserting Pipeline for dataset: emginereed_list_noweights\n",
      "X_train Shape (1259, 8)\n",
      "X_test Shape (1260, 8)\n",
      "X_val Shape (156, 8)\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'emginereed_list_noweights'\n",
    "manual_list = emginereed_list\n",
    "pipe =  None\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, sampled_weights=False, transform = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: emginereed_list_weights\n",
      "# Features before: 8\n",
      "Labels\n",
      " 0        907\n",
      " 1        827\n",
      "-1        785\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\model_building\\feat_select.ipynb Cell 82\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39memginereed_list_weights\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m apply_model_transform(dataset,\u001b[39m'\u001b[39;49m\u001b[39mOriginal\u001b[39;49m\u001b[39m'\u001b[39;49m, pipe, models[\u001b[39m0\u001b[39;49m],X_train_dict\u001b[39m=\u001b[39;49mX_train_dict,X_test_dict\u001b[39m=\u001b[39;49mX_test_dict,y_train\u001b[39m=\u001b[39;49my_train,y_test\u001b[39m=\u001b[39;49my_test, \u001b[39mset\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcombined\u001b[39;49m\u001b[39m'\u001b[39;49m,manual_list \u001b[39m=\u001b[39;49m manual_list, sampled_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\model_building\\feat_select.ipynb Cell 82\u001b[0m in \u001b[0;36mapply_model_transform\u001b[1;34m(dataset, original_dataset, pipe, model, X_train_dict, X_test_dict, y_train, y_test, set, manual_list, sampled_weights, transform)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_model_transform\u001b[39m(dataset,original_dataset, pipe, model,X_train_dict,X_test_dict,y_train,y_test, \u001b[39mset\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcombined\u001b[39m\u001b[39m'\u001b[39m,manual_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, sampled_weights\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, transform \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     fill_with_dataset(dataset,manual_list,original_dataset)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m transform: transform_features_space(dataset,pipe,sampled_weights)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     insert_and_print(model,dataset,pipe, manual_list)    \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     add_metrics(model,dataset,X_train_dict,X_test_dict,y_train,y_test,\u001b[39mset\u001b[39m, sampled_weights)\n",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\model_building\\feat_select.ipynb Cell 82\u001b[0m in \u001b[0;36mtransform_features_space\u001b[1;34m(dataset, pipe, sampled_weights)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Since this is not working sampled_weights True is same as False\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m sampled_weights:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# NOT WORKING\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# parameters = {pipe.steps[i][0] + \"__sample_weight\": y.iloc[train_idx].sample_weights.values for i in range(len(pipe.steps))}\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# pipe.fit(X.iloc[train_idx], **parameters)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     pipe\u001b[39m.\u001b[39;49mfit(X\u001b[39m.\u001b[39miloc[train_idx])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select.ipynb#Y144sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     pipe\u001b[39m.\u001b[39mfit(X\u001b[39m.\u001b[39miloc[train_idx])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = 'emginereed_list_weights'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1).loc[[('RandomForestClassifier','emginereed_list_noweights'),('RandomForestClassifier','emginereed_list_weights'),('RandomForestClassifier','Clean'),('RandomForestClassifier','Original')]].T\n",
    "# .loc[('RandomForestClassifier','Clean1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#do code to support model\n",
    "#\"data\" is the X dataframe and model is the SKlearn object\n",
    "\n",
    "dataset = 'emginereed_list_noweights'\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_dict[dataset], y_train.Labels)\n",
    "\n",
    "data = X_train_dict[dataset]\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(data.columns, model.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances= importances.sort_values(by='Gini-importance')[-15:]\n",
    "importances.plot(figsize=(18,6) ,kind='bar', rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var1 = \"LumberBasis basis\"\n",
    "# var2 = \"LumberExpiry Daystoexpiry\"\n",
    "# feat_name = 'BasisbyExpiry'\n",
    "\n",
    "# #inplace operation  \n",
    "# Variables = add_engineered_variables(Variables,var1,var2,func=np.divide,new_name=feat_name)\n",
    "\n",
    "# # When Daystoexpiry equals 0, the value of BasisbyExpiry will be inf. so made it nan\n",
    "# Variables.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "\n",
    "# def get_rolling_corr(df1,var1,window):\n",
    "#     df = df1.copy(deep=True)\n",
    "#     df.sort_index(ascending=True,inplace=True)\n",
    "#     df =  df[var1].rolling(window=window).corr(Response['Close_2'])\n",
    "#     return df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def add_yahoo_index(df1,yahoo_list,var2):\n",
    "#     Variables.sort_index(ascending=False, inplace=True)\n",
    "#     Response.sort_index(ascending=False, inplace=True)\n",
    "#     final_df = Variables[yahoo_list].copy(deep=True)\n",
    "#     price_corr = {}\n",
    "#     for var1 in yahoo_list:\n",
    "#         price_corr[var1] = Variables[var1].corr(Response[var2])\n",
    "#         # print(var1,\":\",Variables[var1].corr(Response[var2]))\n",
    "#     CorrwithLumber_df = pd.DataFrame.from_dict(price_corr, orient='index', columns=['CorrwithLumberPrice']).sort_values(by='CorrwithLumberPrice',ascending=False)\n",
    "\n",
    "#     final_variable_list = CorrwithLumber_df[CorrwithLumber_df.CorrwithLumberPrice > 0.70].CorrwithLumberPrice.index.tolist()\n",
    "#     final_df = Variables[final_variable_list].copy(deep=True)\n",
    "\n",
    "#     rolling_df = pd.DataFrame(index = Variables.index)\n",
    "#     for var in final_variable_list:\n",
    "#         feat_name = var+\"_ret\"\n",
    "#         rolling_df = pd.concat([rolling_df,pd.DataFrame(get_rolling_corr(final_df,var,5), columns=[var])],axis=1)\n",
    "        \n",
    "#     # Need to add both identical lines - else doesn't work?\n",
    "#     rolling_df = rolling_df.replace([np.inf, -np.inf], np.nan).fillna(rolling_df.median())\n",
    "#     rolling_df = rolling_df.replace([np.inf, -np.inf], np.nan).fillna(rolling_df.median())\n",
    "\n",
    "\n",
    "#     pacf_dict = {}\n",
    "#     for var in final_variable_list:\n",
    "#         data = rolling_df[var].dropna().values\n",
    "#         acf, ci = sm.tsa.acf(data, alpha=0.05)\n",
    "#         pacf, ci = sm.tsa.pacf(data, alpha=0.05)\n",
    "#         pacf_dict[var] = pacf[1]   \n",
    "#         # pacf_dict[var] = acf[1]\n",
    "\n",
    "#     pacf_df = pd.DataFrame.from_dict(pacf_dict, orient='index', columns=['PACF'])\n",
    "\n",
    "#     rolling_df_auto = rolling_df.copy(deep=True)\n",
    "#     for var in final_variable_list:\n",
    "#         rolling_df[var] = rolling_df[var] * pacf_df.loc[var].values[0]\n",
    "\n",
    "#     returns_df = pd.DataFrame(index = Variables.index)\n",
    "#     for var in final_variable_list:\n",
    "        \n",
    "#         feat_name = var+\"_ret\"\n",
    "#         returns_df = pd.concat([returns_df,pd.DataFrame((np.log(Variables) - np.log(Variables.shift(-1)))[var])],axis=1)\n",
    "\n",
    "#     # Dropping Yahoo LBSF from both\n",
    "#     rolling_df_auto.drop(rolling_df_auto.columns[0],axis=1, inplace=True)\n",
    "#     returns_df.drop(returns_df.columns[0],axis=1, inplace=True)\n",
    "\n",
    "#     YahooIndex = pd.DataFrame(data= np.diag(returns_df.dot(rolling_df_auto.T)), index = returns_df.index,columns = ['YahooIndex'])\n",
    "#     df = df1.copy(deep=True)\n",
    "#     df['YahooIndex'] = YahooIndex['YahooIndex']\n",
    "\n",
    "#     return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yahoo_list = ['Yahoo GSPC','Yahoo XHB','Yahoo XTN','Yahoo USDCADX','Yahoo GCF','Yahoo HGF','Yahoo CLF','Yahoo GCCIX','Yahoo LBSF','Yahoo RFP','Yahoo WFG','Yahoo IFPTO','Yahoo WY','Yahoo CFPTO']\n",
    "# var2 = \"Close_2\"\n",
    "\n",
    "# # Variables = add_yahoo_index(Variables,yahoo_list,'Close_2')\n",
    "# Variables.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'f1_weighted', 'neg_log_loss', 'cohen_kappa_score', 'precision_weighted','roc_auc_ovr_weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.sort_values(by=['pnl','f1_weighted','recall_weighted','precision_weighted'],ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do\n",
    "\n",
    "**Engineered**\n",
    "1. LB_High - LB_Low\n",
    "2. Get Other Basis\n",
    "3. Use some techincal Indicators\n",
    "\n",
    "**Raw**\n",
    "1. LB_Volume\t\n",
    "2. LB_openInterest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(Variables.columns.tolist()).to_csv('Variable_columns_names.csv',index=False)\n",
    "\n",
    "manual_list = pd.read_excel('C:/source/2x4-data/app/model_building/ManualSelectList.xlsx',sheet_name='Variables', index_col=0)\n",
    "manual_list = manual_list[manual_list.index == 1]\n",
    "manual_list = manual_list.values.tolist()\n",
    "manual_list = [x for xs in manual_list for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "original_dataset='Original'\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.90, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"precision_weighted\",cv=btscv,)),])\n",
    "\n",
    "dataset='ManualSelection_Weighted_Transformed'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, sampled_weights=True, transform = True)\n",
    "\n",
    "dataset='ManualSelection'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, sampled_weights=False, transform = False)\n",
    "\n",
    "dataset='ManualSelection_Transformed'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='ManualSelection_Try_1'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict,X_test_dict,y_train,y_test, set='combined',manual_list = manual_list, sampled_weights=False, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1).loc[('RandomForestClassifier','ManualSelection_Weighted_Transformed')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information BY COHORT & Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Original'\n",
    "X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "X.columns = Variables_midx.columns\n",
    "train_idx  = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['train']\n",
    "test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['test']\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train1 = y.iloc[train_idx]\n",
    "\n",
    "\n",
    "top_cohort_variable = pd.DataFrame(index = Variables_midx.columns.get_level_values(0).unique(), columns=['Variable','Score','Col_name'])\n",
    "for outer_col in Variables_midx.columns.get_level_values(0).unique():\n",
    "    \n",
    "    sel_  = SelectKBest(mutual_info_classif, k=1).fit(X_train.loc[:,(outer_col,)], y_train1.Labels)\n",
    "    \n",
    "    selected_col = [x for x,y in zip(pd.DataFrame(X_train.loc[:,(outer_col,)]).columns,sel_.get_support()) if y]\n",
    "    # col_name = tuple(outer_col+','+selected_col[0])\n",
    "\n",
    "    selected_col_score = [x for x,y in zip(sel_.scores_,sel_.get_support()) if y]\n",
    "    # top_cohort_variable[outer_col] = [selected_col[0],selected_col_score[0]]\n",
    "    # cols = pd.MultiIndex.from_product([[outer_col], (selected_col[0])])\n",
    "    top_cohort_variable.loc[outer_col,'Variable'] = selected_col[0]\n",
    "    top_cohort_variable.loc[outer_col,'Score'] = selected_col_score[0]\n",
    "\n",
    "    try:\n",
    "        top_cohort_variable.loc[outer_col,'Col_name'] = outer_col+\" \"+selected_col[0]\n",
    "    except:\n",
    "        print(outer_col, selected_col[0])\n",
    "\n",
    "    # inner_cols = [x for x in pd.DataFrame(X_train.loc[:,(outer_col,)]).columns]    \n",
    "    # print(sel_.scores_)\n",
    "    # print(sel_.get_support())\n",
    "    # print(outer_col,selected_col[0])\n",
    "    # print(selected_col_score)\n",
    "    # print(top_cohort_variable[outer_col])\n",
    "    # print('\\n')\n",
    "\n",
    "    # TA_df.columns = [('TA_',x) for x in TA_df.columns]\n",
    "    \n",
    "# Make column names same as Variables\n",
    "for col in top_cohort_variable.Col_name:\n",
    "    top_cohort_variable.loc[top_cohort_variable['Col_name'] == col, 'Col_name'] = str(col).translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip()\n",
    "\n",
    "\n",
    "# Keeping only top 95% percentile of variables in terms of mutual info score - Enter 1- percentile value in the below line\n",
    "top_cohort_variable = top_cohort_variable[top_cohort_variable.Score > top_cohort_variable.Score.quantile(.05)]\n",
    "\n",
    "top_cohort_variable.sort_values(by=['Score'],ascending=False, inplace=True)\n",
    "\n",
    "top_cohort_variable.plot(x='Variable',y='Score',kind='bar', figsize=(20,10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "base_estimator = RandomForestClassifier(n_estimators=1, criterion='entropy', bootstrap=False)\n",
    "model = BaggingClassifier(base_estimator=base_estimator, n_estimators=100, max_features=1.0)\n",
    "dataset='Top_K_Cohort_MI_Weighted_Transformed_50%PERCENTILE'\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.90, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"precision_weighted\",cv=btscv,)),])\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = top_cohort_variable.Col_name.values.tolist(), sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE BY COHORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Original'\n",
    "X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "X.columns = Variables_midx.columns\n",
    "train_idx  = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['train']\n",
    "test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['test']\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train1 = y.iloc[train_idx]\n",
    "\n",
    "\n",
    "top_cohort_variable = pd.DataFrame(index = Variables_midx.columns.get_level_values(0).unique(), columns=['Variable','Score','Col_name'])\n",
    "for outer_col in Variables_midx.columns.get_level_values(0).unique():\n",
    "    \n",
    "\n",
    "    sel_ = SelectFromModel(RandomForestClassifier(n_estimators=10, random_state=10))\n",
    "\n",
    "    sel_.fit(X_train.loc[:,(outer_col,)], y_train1.Labels)\n",
    "\n",
    "    \n",
    "    sel_  = SelectKBest(mutual_info_classif, k=1).fit(X_train.loc[:,(outer_col,)], y_train1.Labels)\n",
    "    \n",
    "    selected_col = [x for x,y in zip(pd.DataFrame(X_train.loc[:,(outer_col,)]).columns,sel_.get_support()) if y]\n",
    "    # col_name = tuple(outer_col+','+selected_col[0])\n",
    "\n",
    "    selected_col_score = [x for x,y in zip(sel_.scores_,sel_.get_support()) if y]\n",
    "    # top_cohort_variable[outer_col] = [selected_col[0],selected_col_score[0]]\n",
    "    # cols = pd.MultiIndex.from_product([[outer_col], (selected_col[0])])\n",
    "    top_cohort_variable.loc[outer_col,'Variable'] = selected_col[0]\n",
    "    top_cohort_variable.loc[outer_col,'Score'] = selected_col_score[0]\n",
    "\n",
    "    try:\n",
    "        top_cohort_variable.loc[outer_col,'Col_name'] = outer_col+\" \"+selected_col[0]\n",
    "    except:\n",
    "        print(outer_col, selected_col[0])\n",
    "\n",
    "    # inner_cols = [x for x in pd.DataFrame(X_train.loc[:,(outer_col,)]).columns]    \n",
    "    # print(sel_.scores_)\n",
    "    # print(sel_.get_support())\n",
    "    # print(outer_col,selected_col[0])\n",
    "    # print(selected_col_score)\n",
    "    # print(top_cohort_variable[outer_col])\n",
    "    # print('\\n')\n",
    "\n",
    "    # TA_df.columns = [('TA_',x) for x in TA_df.columns]\n",
    "    \n",
    "# Make column names same as Variables\n",
    "for col in top_cohort_variable.Col_name:\n",
    "    top_cohort_variable.loc[top_cohort_variable['Col_name'] == col, 'Col_name'] = str(col).translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip()\n",
    "\n",
    "\n",
    "# Keeping only top 95% percentile of variables in terms of mutual info score - Enter 1- percentile value in the below line\n",
    "top_cohort_variable = top_cohort_variable[top_cohort_variable.Score > top_cohort_variable.Score.quantile(.5)] #0.05\n",
    "\n",
    "top_cohort_variable.sort_values(by=['Score'],ascending=False, inplace=True)\n",
    "\n",
    "top_cohort_variable.plot(x='Variable',y='Score',kind='bar', figsize=(20,10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = models[1]\n",
    "dataset='Top_K_Cohort_FeatImp_Weighted_Transformed_50%PERCENTILE'\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"f1_weighted\",cv=btscv,)),])\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = top_cohort_variable.Col_name.values.tolist(), sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_  = SelectKBest(mutual_info_classif, k=20).fit(X_train, y_train1.Labels)\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the mutual information\n",
    "\n",
    "# mi = mutual_info_classif(X_train, y_train1.Labels)\n",
    "# mi = pd.Series(mi)\n",
    "# mi.index = X_train.columns\n",
    "# mi.sort_values(ascending=False).plot.bar(figsize=(20, 6))\n",
    "# plt.ylabel('Mutual Information')\n",
    "\n",
    "t = SelectKBest(mutual_info_classif).fit(X_train, y_train1.Labels)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.scores_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data = [t.scores_.tolist(),X_train.columns], columns = ['Score','Selected']).sort_values(by=['Score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yellowbricks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ManualSelection'\n",
    "X,y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "train_idx =  get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits, flatten=True)['train']\n",
    "test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits, flatten=True)['test']\n",
    "X_train  = X.iloc[train_idx]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "y_test = y.iloc[test_idx]\n",
    "\n",
    "from yellowbrick.classifier import (ClassificationReport,  DiscriminationThreshold,)\n",
    "rf = RandomForestClassifier(max_depth=4, n_estimators=20, n_jobs=-1)\n",
    "visualizer = ClassificationReport(rf, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train.Labels)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test , y_test.Labels)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ManualSelection'\n",
    "X,y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "rf = RandomForestClassifier(max_depth=4, n_estimators=20, n_jobs=-1)\n",
    "original, predicted = predictions_from_custom_cross_val(rf,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=True)\n",
    "# cm = pd.DataFrame(confusion_matrix(original, predicted), index=Response['Labels'].unique(), columns=Response['Labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_dict['ManualSelection']), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\n",
    "\n",
    "# The ConfusionMatrix visualizer taxes a model\n",
    "cm = ConfusionMatrix(model, classes=[-1,-0,1])\n",
    "\n",
    "# Fit fits the passed model. This is unnecessary if you pass the visualizer a pre-fitted model\n",
    "cm.fit(X_train, y_train)\n",
    "\n",
    "# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n",
    "# and then creates the confusion_matrix from scikit-learn.\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "# How did we do?\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1).loc[('RandomForestClassifier','ManualSelection')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict['Original'],X_test_dict['Original']],axis=0)\n",
    "y = pd.concat([y_train,y_test],axis=0)\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com1_original, com1_predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=False)\n",
    "com2_original, com2_predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=True)\n",
    "com1_original == com2_original, com1_predicted == com2_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(data = [pd.Series(com1_predicted).value_counts().sort_index(), pd.Series(com1_original).value_counts().sort_index()], index = ['predicted','original']).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = [pd.Series(com2_predicted).value_counts().sort_index(), pd.Series(com2_original).value_counts().sort_index()], index = ['predicted','original']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight='balanced'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",classes= lab, y = y.Labels)\n",
    "computed_sample_weights = compute_sample_weight('balanced', y.Labels)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame(data = [computed_sample_weights, y.Labels], index = ['computed_sample_weights','Labels']).T\n",
    "group_df\n",
    "group_df.groupby('Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Response[['Labels','sample_weights']].groupby('Labels').sum()\n",
    "# Response[['Labels','sample_weights']].groupby('Labels').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_bins_data(Response,'sample_weights',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','ManualSelection')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Clean1')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond','lumbermovingaverages MA200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = 'Original'\n",
    "dataset = 'Spread_1-2_wts'\n",
    "model = models[0]\n",
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond','lumbermovingaverages MA200']\n",
    "# insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined', sampled_weights= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "all_class_metric = metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_wts')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_MA200')]['ClassDf'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_MA200')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict[dataset].iloc[:, : 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'log_loss'\n",
    "\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "sfs = SFS(model, \n",
    "           k_features=6, # the more features we want, the longer it will take to run\n",
    "           forward=True, \n",
    "           floating=True, # see the docs for more details in this parameter\n",
    "           verbose=2, # this indicates how much to print out intermediate steps\n",
    "           scoring='f1_weighted', \n",
    "           cv=btscv,\n",
    "           n_jobs=-1,\n",
    "            \n",
    "         )\n",
    "\n",
    "weights = np.abs(y.Adj_ret_3.values)\n",
    "\n",
    "sfs = sfs.fit(X, y.Labels,sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST \n",
    "dataset = 'Original'\n",
    "X = X_train_dict[dataset].sort_index()\n",
    "y = y_train.sort_index() \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1, max_depth=1, n_jobs=-1)\n",
    "  \n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1,\n",
    "           max_features=1,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=btscv)\n",
    "\n",
    "efs1 = efs1.fit(X, y.Labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Clean1'\n",
    "model = RandomForestClassifier(n_estimators=5, max_depth=2, n_jobs=-1)\n",
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index()    \n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1,\n",
    "           max_features=2,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=btscv)\n",
    "\n",
    "efs1 = efs1.fit(X, y.Labels)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(efs1.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "plot_confusion_matrix(model, X_test_dict['Clean1'], y_test.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since it takes > 1 min\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "xgb.fit(X_train_dict['Clean1'], y_train.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = xgb.predict(X_test_dict['Clean1'])\n",
    "df1 = pd.DataFrame(np.transpose(precision_recall_fscore_support(y_test.Labels, y_pred, average=None)),columns=['precision', 'recall', 'fscore', 'support'], index=lab)\n",
    "df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "y_pred = model.predict(X_test_dict['Clean1'])\n",
    "\n",
    "# y_pred = cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv=5)\n",
    "# y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since takes ~ 1.30 minute\n",
    "# model = models[1]\n",
    "# model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# y_pred = model.predict(X_test_dict['Clean1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = models[0]\n",
    "\n",
    "X = X_test_dict['Clean1'].sort_index()\n",
    "y = y_test.sort_index()  \n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "280/1386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original), y_test.Labels.shape, len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_metric = metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))\n",
    "all_class_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(original, predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(original, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the dataframe in a cell in features_df\n",
    "# features_df['to_delete'] = None\n",
    "# features_df['to_delete'].astype(object)\n",
    "# features_df.loc[('RandomForestClassifier','Original'),'to_delete'] =  [all_class_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.loc[('RandomForestClassifier','Original'),'to_delete'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy - Negative Log Liklehood or Log Loss - Custom Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower The Better\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Original'], y_train.Labels)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "\n",
    "# This line required to convert for custom implementation from normal labels to indexed labels\n",
    "y_actuals = y_test.Labels.replace(to_replace=sorted(y_test.Labels.unique()), value=list(range(len(y_test.Labels.unique())))).values\n",
    "\n",
    "# Custom function to compute negative log loss\n",
    "nll = np.mean([-np.log(y_prob[i,j]) for i,j in zip(range(y_prob.shape[0]),y_actuals)])\n",
    "print(nll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1).loc[('RandomForestClassifier',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(y_actuals, y_prob))\n",
    "print(log_loss(y_test.Labels, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "model = models[0]\n",
    "dataset = 'Clean'\n",
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "scores = cross_val_score(model, X, y.Labels, cv=btscv, scoring=LogLoss)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogLoss._select_proba_binary(predicted,y_test.Labels.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probabilities_from_custom_cross_val(model,X, y, custom_cv = btscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# proba = cross_val_predict(model, X, y, cv=btscv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection Methods - Mostly just examine linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "# Plot\n",
    "# mi.plot.bar(figsize=(20, 6))\n",
    "# plt.ylabel('Mutual Information')\n",
    "\n",
    "# select features\n",
    "sel_ = SelectKBest(mutual_info_classif, k=15).fit(X_train, y_train)\n",
    "\n",
    "# display features\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-square Statistic - only suited for classification!                                         \n",
    "https://www.udemy.com/course/feature-selection-for-machine-learning/learn/lecture/22495182#questions\n",
    "https://github.com/solegalli/feature-selection-for-machine-learning/blob/main/05-Filter-Statistical-Tests/05.2-Fisher-score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the chi2 p_value between each of the variables and the target\n",
    "# chi2 returns 2 arrays, one contains the F-Scores which are then evaluated against the chi2 distribution to obtain the pvalue. The pvalues are in the second array\n",
    "\n",
    "# Input X must be non-negative\n",
    "X_train_non_negative = X_train[X_train.columns[((X_train < 0).sum(axis=0) == 0).values]]\n",
    "f_score = chi2(X_train_non_negative.fillna(0), y_train)\n",
    "pvalues = pd.Series(f_score[1])\n",
    "pvalues.index = X_train_non_negative.columns\n",
    "pvalues.sort_values(ascending=True, inplace = True)\n",
    "extremely_low_p_values = len(pvalues[pvalues < 1e-100])\n",
    "sel_ = SelectKBest(chi2, k= extremely_low_p_values).fit(X_train_non_negative, y_train)\n",
    "X_train_non_negative.columns[sel_.get_support()] # display features\n",
    "\n",
    "# X_train = sel_.transform(X_train)\n",
    "# X_test = sel_.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anova - tests 2 samples have same mean\n",
    "\n",
    "Assumptions:\n",
    "Sample are independant & normally distributed, homegeneity of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the univariate statistical measure between each of the variables and the target\n",
    "# similarly to chi2, the output is one array with f-scores and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=True, inplace = True) # The smaller the p_value the more predictive the feature is\n",
    "\n",
    "pvalue_above_5_percent = len(univariate[univariate < 0.05])\n",
    "sel_ = SelectKBest(f_classif, k=pvalue_above_5_percent).fit(X_train, y_train)\n",
    "features_to_keep = sel_.get_feature_names_out()\n",
    "features_to_keep\n",
    "\n",
    "# select features\n",
    "# X_train_anova = sel_.transform(X_train)\n",
    "# X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# # numpy array to dataframe\n",
    "# X_train_anova = pd.DataFrame(X_train_anova)\n",
    "# X_train_anova.columns = features_to_keep\n",
    "\n",
    "# X_test_anova = pd.DataFrame(X_test_anova)\n",
    "# X_test_anova.columns = features_to_keep\n",
    "\n",
    "# X_train_anova.shape, X_test_anova.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects features whose importance is greater than the threshold. - Thershold is the mean importance of all features\n",
    "sel_ = SelectFromModel(RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "TopNFeatures = pd.DataFrame(index = sel_.estimator_.feature_names_in_.tolist(),data = sel_.estimator_.feature_importances_, columns = ['Imp']).sort_values(by='Imp',ascending=False).head(20).index.tolist()\n",
    "pd.Series(sel_.estimator_.feature_importances_.ravel()).hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopNFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance Recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1:44 mins to run\n",
    "sel_ = RFE(RandomForestClassifier(n_estimators=100,  max_depth=3, n_jobs=-1), n_features_to_select=30).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "rf.fit(X_train[selected_features].fillna(0), y_train)\n",
    "y_pred = rf.predict(X_test[selected_features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[selected_features].fillna(0))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val.fillna(0), y_valid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set')\n",
    "pred = rf.predict_proba(X_train[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "print('Test set')\n",
    "pred = rf.predict_proba(X_test[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "print('Validation set')\n",
    "pred = rf.predict_proba(X_val[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_val, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Random Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1 min to run - You can use this procedure with any machine learning algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=2, n_jobs=-1)\n",
    "\n",
    "sel = SelectByShuffling(\n",
    "    variables=None, # automatically examine all numerical variables\n",
    "    estimator=rf, # the ML model\n",
    "    scoring='roc_auc', # the metric to evaluate\n",
    "    threshold=0,# the maximum performance drop allowed to select the feature\n",
    "    cv=btscv, # cross validation\n",
    ")\n",
    "\n",
    "sel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_ # performance of model trained with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(sel.performance_drifts_).sort_values(ascending=False).plot.bar(figsize=(16,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that will be removed\n",
    "\n",
    "print(len(sel.features_to_drop_))\n",
    "# remove features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "X_val = sel.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print( 'train auc score: ',roc_auc_score(y_train, (rf.predict_proba(X_train))[:,1]))\n",
    "print('test auc score: ', roc_auc_score(y_test, (rf.predict_proba(X_test))[:, 1]))\n",
    "print('Validation auc score: ', roc_auc_score(y_val, (rf.predict_proba(X_val))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "\n",
    "sel = RecursiveFeatureElimination(\n",
    "    variables=None, # automatically evaluate all numerical variables\n",
    "    estimator = model, # the ML model\n",
    "    scoring = 'roc_auc', # the metric we want to evalute\n",
    "    threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "    cv=btscv, # cross-validation\n",
    ")\n",
    "\n",
    "# this may take quite a while, because\n",
    "# we are building a lot of models with cross-validation\n",
    "# sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of model trained using all features\n",
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of all features based of initial model\n",
    "sel.feature_importances_.plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sel.performance_drifts_).plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Performance change when feature was added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features that will be removed\n",
    "\n",
    "len(sel.features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "y_pred = rf.predict(X_test[features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[features].fillna(0))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val .fillna(0), y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance in machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_basic_filter.shape, X_test_basic_filter.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter methods - basic\n",
    "run_randomForests(X_train_basic_filter,X_test_basic_filter,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression and compare performance in train and test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "run_logistic(scaler.transform(X_train),\n",
    "             scaler.transform(X_test),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>Pipelines:</b> Final Code will look like this but for now work through issues above \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.9, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.9,missing_values=\"raise\",selection_method=\"variance\",estimator=rf,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# remove features\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)\n",
    "X_val = pipe.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pipe.named_steps['constant'].features_to_drop_))\n",
    "pipe.named_steps['duplicated'].features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT USING - for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Brute Force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        \n",
    "        for j in range(i):\n",
    "            \n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "             \n",
    "                print(abs(corr_matrix.iloc[i, j]),\":\", corr_matrix.columns[i], \"<< - >>\", corr_matrix.columns[j])\n",
    "                colname = corr_matrix.columns[j]\n",
    "                \n",
    "                # and add it to our correlated set\n",
    "                col_corr.add(colname)\n",
    "                \n",
    "    return col_corr\n",
    "\n",
    "# corr_features = correlation(X_train, 0.9)\n",
    "# len(set(corr_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_features = correlation(X_train, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.9]\n",
    "corrmat = corrmat[corrmat < 1] # Not Interested in the correlation with 1 since will be with the same variable\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    \n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group in correlated_groups:\n",
    "#     print(group)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Group Index\n",
    "group_index = 1\n",
    "\n",
    "group = correlated_groups[group_index]\n",
    "var = group.feature1.unique()[0]\n",
    "\n",
    "# add all features of the group to a list\n",
    "features = list(group['feature2'].unique())+[var]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "\n",
    "print(var)\n",
    "importance.sort_values(by='importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in group['feature2']:\n",
    "#     plt.scatter(X_train[var], X_train[feature])\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.ylabel(var)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just an example to show one group of how smart correlation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "group = sel.correlated_feature_sets_[0]\n",
    "\n",
    "# build random forest with cross validation for each feature\n",
    "for f in group:\n",
    "    \n",
    "    model = cross_validate(\n",
    "        rf,\n",
    "        X_train[f].to_frame(),\n",
    "        y_train,\n",
    "        cv=btscv,\n",
    "        return_estimator=False,\n",
    "        scoring='accuracy',\n",
    "    )\n",
    "\n",
    "#  scoring='roc_auc' does not support categorical data.\n",
    "\n",
    "    print(f, model[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation metrics\n",
    "1. cross_val_score\n",
    "2. Area under the ROC Curve\n",
    "3. Confusion Matrix\n",
    "4. Confusion Report\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "cross_val_score(model, Variables, Response.Close_Up_Down, cv = 2, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Original'], y_train.Labels, cv = 5,scoring='roc_auc_ovo_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv = 5,scoring='roc_auc_ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "\n",
    "for p in [0.475,0.5,0.525]:\n",
    "    \n",
    "    y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "    print(\"tpr:\",tpr)\n",
    "    print(\"fpr:\",fpr)\n",
    "    print(\"threshold:\",threshold)\n",
    "    print(p,\": \",roc_auc_score(y_test.Close_Up_Down, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/45715018/scikit-learn-how-to-plot-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "plt.figure(figsize=(12,5))\n",
    "prediction = clf.predict_proba(X_test_dict['Clean'])[:,1]\n",
    "plt.hist(prediction[y_test.Close_Up_Down==-1], bins=100, label='Negatives')\n",
    "plt.hist(prediction[y_test.Close_Up_Down==1], bins=100, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Probability of being Positive Class', fontsize=10)\n",
    "plt.ylabel('Number of records in each bucket', fontsize=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=25, pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(y_test, model_set, model):\n",
    "    model.fit(X_train_dict[model_set], y_train.Close_Up_Down)\n",
    "    y_prob_positive = model.predict_proba(X_test_dict[model_set])[:,1]\n",
    "    print(f\"ROC_AUC_SCORE: {roc_auc_score(y_test.Close_Up_Down, y_prob_positive):.2f}%\")\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_prob_positive,)\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "\n",
    "plot_roc_auc_curve(y_test, 'Original', model)\n",
    "# plot_roc_auc_curve(y_test, 'Original', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred == [-1 if x[0] > 0.5 else 1 for x in y_prob]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took 5:20 mins\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "# cross_val_score(model, Variables, Response.Close_Up_Down, cv = 5).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "conf_mat = confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "sns.heatmap(pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted']), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues');\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_val_dict['Clean'], y_val.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Close_Up_Down, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report['-1.0']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, det_curve\n",
    "precision_score(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44a86d6b397dbc6b70abfa92d378adf5d728e5b92754036aace887a2a3f0f490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
