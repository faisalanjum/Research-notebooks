{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "0. For Feature Selection, we fit only on X and it fits only on Train Data - The scoring functions are however based on Time Series CV splits (which first fits the data on Train indices and then scores on Test Indices)\n",
    "1. sample_weights - If we want to use strategy P&L as score, we can't assign maximum weights to \"0\" values in sample_weights\n",
    "2. Outlier Detection & removal\n",
    "3. Imputation\n",
    "4. Create Score function - P&L - Based on Long Short position, position size and % return\n",
    "5. Rectify Class Imbalance \n",
    "6. F1_score weighted looks odd - even when both precision_weighted and recall_weighted is lower, f1_weighed is higher?\n",
    "7. Check each number in features_df!\n",
    "8. If we put returns as Sample weights, he model will ignore all rows where returns equals 0 and that class will be under represented - Look at class_weight and sample_weight - However, if we do # 1, then sample_weights no longer reflect P&L and we want our score function to represent that\n",
    "\n",
    "\n",
    "** Not able to pass sample_weight to transformation fit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**autoreload script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import _model_build_func\n",
    "# import importlib\n",
    "# importlib.reload(_model_build_func)\n",
    "# from _model_build_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions List**\n",
    "1. metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))  - return df          \n",
    "2. predictions_from_custom_cross_val(model,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=False) - returns original, predicted\n",
    "3. probabilities_from_custom_cross_val(model,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=False) - returns original, predicted_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting data from CWP database & excel files::  33%|███▎      | 1/3 [00:03<00:07,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken for Contract:1 00:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting data from CWP database & excel files::  67%|██████▋   | 2/3 [00:07<00:03,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken for Contract:2 00:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting data from CWP database & excel files:: 100%|██████████| 3/3 [00:10<00:00,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken for Contract:3 00:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Takes 2.10 minutes to run\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from support._model_build_func import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in Getting Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Raw data from Excel\n",
    "2. Imputing Values for missing values - Backfilling and then frontfilling Variables DataFrame, and filling zeros with Median? - Check if it makes sense\n",
    "3. Adding Date Features\n",
    "4. Adding Technical Indicator Features\n",
    "5. Replacing punctuation strings in column names\n",
    "6. Finding Last Available Date for each column\n",
    "7. For now using custom based method - but change it eventually with KNN (or Multivariate) Imputation etc.- # Takes 35 secounds to run\n",
    "8. Remove Variables with all NaNs\n",
    "9. Change Bool cols (mostly date columns such as Is_year_end etc.) to int columns\n",
    "10. Winsorzing/Capping ['Adj_ret_2', 'Close_ret'] - **Instead of capping Adj_ret_2/Close_ret - try to figure out why we see abnormal returns such as -40% and +27%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2665, 2665, (2665, 783), (2665, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables = Variables_.copy(deep=True)\n",
    "Response = Response_.copy(deep=True)\n",
    "Variables_midx = Variables_midx_.copy(deep=True)\n",
    "last_valid_loc = last_valid_loc_.copy(deep=True)\n",
    "Variables_with_nans = Variables_with_nans_\n",
    "\n",
    "len(Variables), len(Response), Variables.shape, Response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiClassification Targets - Choose between 3 or 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      " 0        932\n",
      " 1        886\n",
      "-1        847\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pv_1 = 0.0025 # higher and lower than 0.25% return\n",
    "pv_2 = 0.0075 # higher and lower than 1% return\n",
    "col = 'Adj_ret_2' # Can also be 'Close_ret'\n",
    "\n",
    "num_classes = 3 # Choose 3 or 5\n",
    "Response = get_multiclass_labels(num_classes,pv_1,pv_2, Response,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      " 0        932\n",
      " 1        886\n",
      "-1        847\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pv_1 = 0.0025 # higher and lower than 0.25% return\n",
    "pv_2 = 0.0075 # higher and lower than 1% return\n",
    "col = 'Adj_ret_2' # Can also be 'Close_ret'\n",
    "\n",
    "num_classes = 3 # Choose 3 or 5\n",
    "Response = get_multiclass_labels(num_classes,pv_1,pv_2, Response,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset in 3 Dictionaries of Training, Testing & Validation & Initiating features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: If metric calculations in add_metric function is calculated on Data which has even one class missing from y_predictions, it will throw an error (when error='raise' used), or it will be NaN for (roc_auc_ovr_weighted & roc_auc_ovo_weighted) if this option is not used in cross_val_score..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict, X_test_dict, X_val_dict, y_train, y_test, y_val, sample_weights_train, sample_weights_test, sample_weights_val \\\n",
    "    = ttv_split(Variables, Response, test_size=0.50, Validation_date_start = '2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>End_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lumber_Track_north_american_production</th>\n",
       "      <th>Prairies_And_Eastern_Canada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_North_America</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lumber_Track_north_american_shipment</th>\n",
       "      <th>Prairies_And_Eastern_Canada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_North_America</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CFTC_legacy</th>\n",
       "      <th>Total_Reportable_Positions_Long_All</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration_Gross_LT_4_TDR_Short_Ol</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             End_Dt\n",
       "Lumber_Track_north_american_production Prairies_And_Eastern_Canada              NaT\n",
       "                                       Total_North_America                      NaT\n",
       "Lumber_Track_north_american_shipment   Prairies_And_Eastern_Canada              NaT\n",
       "                                       Total_North_America                      NaT\n",
       "CFTC_legacy                            Total_Reportable_Positions_Long_All      NaT\n",
       "                                       Concentration_Gross_LT_4_TDR_Short_Ol    NaT"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_valid_loc[last_valid_loc.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why these variables have NaNs\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Variables_with_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CFTC_legacy', 'Concentration_Gross_LT_4_TDR_Short_Ol'),\n",
       " ('CFTC_legacy', 'Total_Reportable_Positions_Long_All'),\n",
       " ('Date_', 'CFTC_disaggregated'),\n",
       " ('Date_', 'CFTC_legacy'),\n",
       " ('Date_', 'CP_Terminal_Dwell'),\n",
       " ('Date_', 'CP_Train_Speed'),\n",
       " ('Date_', 'Canada Rail Lumber & Wood Prods'),\n",
       " ('Date_', 'Canadian_National_Railway'),\n",
       " ('Date_', 'Canadian_Pacific'),\n",
       " ('Date_', 'Construction Spending'),\n",
       " ('Date_', 'FEA_Lumber_Advisor_value'),\n",
       " ('Date_', 'FRED_Daily'),\n",
       " ('Date_', 'FRED_Daily, 7-Day'),\n",
       " ('Date_', 'FRED_Daily, Close'),\n",
       " ('Date_', 'FRED_Monthly'),\n",
       " ('Date_', 'FRED_Quarterly'),\n",
       " ('Date_', 'FRED_Weekly, As of Wednesday'),\n",
       " ('Date_', 'FRED_Weekly, Ending Monday'),\n",
       " ('Date_', 'FRED_Weekly, Ending Saturday'),\n",
       " ('Date_', 'FRED_Weekly, Ending Thursday'),\n",
       " ('Date_', 'FRED_Weekly, Ending Wednesday'),\n",
       " ('Date_', 'FTR'),\n",
       " ('Date_', 'GSCPI'),\n",
       " ('Date_', 'Investingdotcom'),\n",
       " ('Date_', 'Lumber_Adjusted_dfs'),\n",
       " ('Date_', 'Lumber_Contract_Spreads'),\n",
       " ('Date_', 'Lumber_OHLCV'),\n",
       " ('Date_', 'Lumber_Track_consumption_lumber_canada'),\n",
       " ('Date_', 'Lumber_Track_consumption_lumber_us'),\n",
       " ('Date_', 'Lumber_Track_inventory_canada'),\n",
       " ('Date_', 'Lumber_Track_inventory_us'),\n",
       " ('Date_', 'Lumber_Track_log_export_us'),\n",
       " ('Date_', 'Lumber_Track_log_import_us'),\n",
       " ('Date_', 'Lumber_Track_lumber_export_canada'),\n",
       " ('Date_', 'Lumber_Track_lumber_export_us'),\n",
       " ('Date_', 'Lumber_Track_lumber_import_us'),\n",
       " ('Date_', 'Lumber_Track_north_american_inventory'),\n",
       " ('Date_', 'Lumber_Track_north_american_order'),\n",
       " ('Date_', 'Lumber_Track_north_american_production'),\n",
       " ('Date_', 'Lumber_Track_north_american_shipment'),\n",
       " ('Date_', 'Lumber_Track_north_american_unfilled_order'),\n",
       " ('Date_', 'Lumber_Track_orders_us'),\n",
       " ('Date_', 'Lumber_Track_pppc'),\n",
       " ('Date_', 'Lumber_Track_production_canada'),\n",
       " ('Date_', 'Lumber_Track_production_us'),\n",
       " ('Date_', 'Lumber_Track_shipment_canada'),\n",
       " ('Date_', 'Lumber_Track_shipment_us'),\n",
       " ('Date_', 'Lumber_Track_unfilledorders_us'),\n",
       " ('Date_', 'Monthly Wholesale Trade: Sales and Inventories'),\n",
       " ('Date_', 'New Home Sales'),\n",
       " ('Date_', 'New Residential Construction'),\n",
       " ('Date_', 'OverNight_Rates'),\n",
       " ('Date_', 'TA_'),\n",
       " ('Date_', 'Treasury_Terms'),\n",
       " ('Date_', 'Weekly Economic Index'),\n",
       " ('Date_', 'Weekly_realtor'),\n",
       " ('Date_', 'Wells Fargo Housing Market Index'),\n",
       " ('Date_', 'Western_Lumber_average_price_coastal'),\n",
       " ('Date_', 'Western_Lumber_average_price_coastal_douglus'),\n",
       " ('Date_', 'Western_Lumber_average_price_coastal_himfir'),\n",
       " ('Date_', 'Western_Lumber_average_price_island'),\n",
       " ('Date_', 'Western_Lumber_average_price_island_douglas'),\n",
       " ('Date_', 'Western_Lumber_average_price_ponderaso_pine'),\n",
       " ('Date_', 'Western_Lumber_average_price_white_woods'),\n",
       " ('Date_', 'Western_Lumber_inventory_western'),\n",
       " ('Date_', 'Western_Lumber_orders_western'),\n",
       " ('Date_', 'Western_Lumber_pppc_western'),\n",
       " ('Date_', 'Western_Lumber_production_western'),\n",
       " ('Date_', 'Western_Lumber_shipment_coastal'),\n",
       " ('Date_', 'Western_Lumber_shipment_inland'),\n",
       " ('Date_', 'Western_Lumber_shipment_western'),\n",
       " ('Date_', 'Western_Lumber_unfilled_order_western'),\n",
       " ('Date_', 'Y_curve'),\n",
       " ('Date_', 'Yahoo'),\n",
       " ('Date_', 'barometer_coast'),\n",
       " ('Date_', 'barometer_finished_inventories'),\n",
       " ('Date_', 'barometer_inland'),\n",
       " ('Date_', 'barometer_western'),\n",
       " ('Date_', 'lumber_moving_averages'),\n",
       " ('Date_', 'monthly_realtor'),\n",
       " ('Lumber_Track_north_american_production', 'Prairies_And_Eastern_Canada'),\n",
       " ('Lumber_Track_north_american_production', 'Total_North_America'),\n",
       " ('Lumber_Track_north_american_shipment', 'Prairies_And_Eastern_Canada'),\n",
       " ('Lumber_Track_north_american_shipment', 'Total_North_America')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables_with_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Types\n",
      "float64    764\n",
      "int64       10\n",
      "int32        7\n",
      "object       2\n",
      "dtype: int64\n",
      "Total Variables: 783\n",
      "\n",
      "\n",
      "Response Types\n",
      "float64    10\n",
      "int32       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Variable Types\")\n",
    "print(pd.Series(Variables.dtypes.values).value_counts())\n",
    "print(\"Total Variables:\",pd.Series(Variables.dtypes.values).value_counts().sum())\n",
    "\n",
    "print('\\n')\n",
    "print(\"Response Types\")\n",
    "print(pd.Series(Response.dtypes.values).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample weights - Removed Outliers from Response by replacing with IQR*1.5 upper and lower limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.1024453116726735\n",
      "Min: -0.1387440497997851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.14, -0.112]         0.11\n",
       "(-0.112, -0.0851]       0.00\n",
       "(-0.0851, -0.0583]      0.90\n",
       "(-0.0583, -0.0315]      4.62\n",
       "(-0.0315, -0.00475]    31.52\n",
       "(-0.00475, 0.022]      47.95\n",
       "(0.022, 0.0488]        13.10\n",
       "(0.0488, 0.0756]        1.61\n",
       "(0.0756, 0.102]         0.19\n",
       "Name: Adj_ret_2, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Adj_ret_2'\n",
    "create_bins_data(Response, col, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagnostic_plots(Response, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sample_weights\n",
      "Labels                \n",
      "-1          865.544398\n",
      " 0          934.890245\n",
      " 1          906.603256\n",
      "        sample_weights\n",
      "Labels                \n",
      "-1            1.021894\n",
      " 0            1.003101\n",
      " 1            1.023254\n"
     ]
    }
   ],
   "source": [
    "# print(winsoriser.left_tail_caps_)\n",
    "# print(winsoriser.right_tail_caps_)\n",
    "\n",
    "print(Response[['Labels','sample_weights']].groupby('Labels').sum())\n",
    "print(Response[['Labels','sample_weights']].groupby('Labels').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1.1387440497997852\n",
      "Min: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.999, 1.015]    59.21\n",
       "(1.015, 1.031]    27.20\n",
       "(1.031, 1.046]     9.12\n",
       "(1.046, 1.062]     2.81\n",
       "(1.062, 1.077]     1.20\n",
       "(1.077, 1.092]     0.30\n",
       "(1.092, 1.108]     0.04\n",
       "(1.108, 1.123]     0.00\n",
       "(1.123, 1.139]     0.11\n",
       "Name: sample_weights, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bins_data(Response, 'sample_weights', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION METRICS & generate_sample_confusion_matrix\n",
    "    1. Recall/Sensitivity/TPR: tp / (tp + fn) - **%age of a TRUE/Positives class correctly identified/ ability to find all the positive samples**. This deciedes how many times we trade since its the propotion of actual positives we are able to detect.\n",
    "    2. Specificity (TNR) is tn / (tn + fp) - %age of a FALSE/Negatives class correctly identified\n",
    "    3. False Positive Rate (FPR) = 1 - Specificity or fp / (tn + fp). \n",
    "    4. Accuracy is TP/ entire matrix sum ???\n",
    "    5. Precision is tp / (tp + fp) - the ability not to label a negative sample as positive. This deciedes our PROFITABILITY since we don't want FALSE Positives\n",
    "    6. Support is the number of occurrences of each class  - sum of respective row\n",
    "    7. Macro - unweighted mean. This does not take label imbalance into account.\n",
    "    8. Wt_Avg - average weighted by support\n",
    "    9. Micro - same as accuracy - sum of diagnols/ sum of all matrix\n",
    "\n",
    "**True/False (Positives/Negatives) means if a sample belongs/doesn't belong to a class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8b909_row0_col0, #T_8b909_row0_col1, #T_8b909_row1_col0, #T_8b909_row1_col1 {\n",
       "  color: red;\n",
       "}\n",
       "#T_8b909_row0_col2, #T_8b909_row1_col2 {\n",
       "  color: orange;\n",
       "}\n",
       "#T_8b909_row2_col0, #T_8b909_row2_col1 {\n",
       "  color: blue;\n",
       "}\n",
       "#T_8b909_row2_col2 {\n",
       "  color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8b909\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8b909_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_8b909_level1_col0\" class=\"col_heading level1 col0\" >-1</th>\n",
       "      <th id=\"T_8b909_level1_col1\" class=\"col_heading level1 col1\" >0</th>\n",
       "      <th id=\"T_8b909_level1_col2\" class=\"col_heading level1 col2\" >1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8b909_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">Actual</th>\n",
       "      <th id=\"T_8b909_level1_row0\" class=\"row_heading level1 row0\" >-1</th>\n",
       "      <td id=\"T_8b909_row0_col0\" class=\"data row0 col0\" >True Negative</td>\n",
       "      <td id=\"T_8b909_row0_col1\" class=\"data row0 col1\" >True Negative</td>\n",
       "      <td id=\"T_8b909_row0_col2\" class=\"data row0 col2\" >False Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b909_level1_row1\" class=\"row_heading level1 row1\" >0</th>\n",
       "      <td id=\"T_8b909_row1_col0\" class=\"data row1 col0\" >True Negative</td>\n",
       "      <td id=\"T_8b909_row1_col1\" class=\"data row1 col1\" >True Negative</td>\n",
       "      <td id=\"T_8b909_row1_col2\" class=\"data row1 col2\" >False Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b909_level1_row2\" class=\"row_heading level1 row2\" >1</th>\n",
       "      <td id=\"T_8b909_row2_col0\" class=\"data row2 col0\" >False Negative</td>\n",
       "      <td id=\"T_8b909_row2_col1\" class=\"data row2 col1\" >False Negative</td>\n",
       "      <td id=\"T_8b909_row2_col2\" class=\"data row2 col2\" >True Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2cd0f622f80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = Response.Labels.unique()\n",
    "lab.sort()\n",
    "\n",
    "generate_sample_confusion_matrix(1,lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocked Time Series cross-validation\n",
    "https://goldinlocks.github.io/Time-Series-Cross-Validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "btscv = BlockingTimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics from Confusion Matrix Custom Func - These metrics (weighted & average) do NOT exactly match the output of features_df metrics** \n",
    "** Also note that the weighted average results are not based on sample_weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAJA \n",
    "\n",
    "# X = pd.concat([X_train_dict['Original'], X_test_dict['Original']], axis=0)\n",
    "# y = pd.concat([y_train, y_test], axis=0)\n",
    "# X.shape, y.shape\n",
    "# model = models[0]\n",
    "# train_idx  = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = False)['train']\n",
    "# test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = False)['test']\n",
    "\n",
    "# # Issue with shape - need to correct \n",
    "# predicted_proba1 = []\n",
    "# for i in range(len(train_idx)):\n",
    "#     model.fit(X.iloc[train_idx[i]], y.Labels.iloc[train_idx[i]])\n",
    "#     predicted_proba1.append(model.predict_proba(X.iloc[test_idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This func is only to initialize the X variables with some features set - typically, we use 'Original' if not passed in\n",
    "def fill_with_dataset(dataset,manual_list, original_dataset = 'Original'):\n",
    "    if manual_list:\n",
    "        X_train_dict[dataset] = X_train_dict[original_dataset][manual_list]\n",
    "        X_test_dict[dataset] = X_test_dict[original_dataset][manual_list]\n",
    "        X_val_dict[dataset] = X_val_dict[original_dataset][manual_list]\n",
    "        \n",
    "    else:\n",
    "        X_train_dict[dataset] = X_train_dict[original_dataset]\n",
    "        X_test_dict[dataset] = X_test_dict[original_dataset]\n",
    "        X_val_dict[dataset] = X_val_dict[original_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this func first fits the transformation to all indices of X_train from cv (btscv), then transforms the features from X_train, X_test and X_val\n",
    "# For each pipeline trasnformation, we are using same sample_weights_train - Not working\n",
    "def transform_features_space(dataset,pipe,sampled_weights=False):\n",
    "    print(\"\\nRemoving Features for dataset:\",dataset)\n",
    "    print(\"# Features before:\",len(X_train_dict[dataset].columns.to_list()))\n",
    "    \n",
    "\n",
    "    X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test,set='combined')\n",
    "    train_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['train']\n",
    "    \n",
    "    # Since this is not working sampled_weights True is same as False\n",
    "    if sampled_weights:\n",
    "\n",
    "        # NOT WORKING\n",
    "        # parameters = {pipe.steps[i][0] + \"__sample_weight\": y.iloc[train_idx].sample_weights.values for i in range(len(pipe.steps))}\n",
    "        # pipe.fit(X.iloc[train_idx], **parameters)\n",
    "        pipe.fit(X.iloc[train_idx])\n",
    "    else:\n",
    "        pipe.fit(X.iloc[train_idx])\n",
    "        \n",
    "    X_train_dict[dataset] = pipe.transform(X_train_dict[dataset])\n",
    "    X_test_dict[dataset] = pipe.transform(X_test_dict[dataset])\n",
    "    X_val_dict[dataset] = pipe.transform(X_val_dict[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# BAJA\n",
    "\n",
    "\n",
    "# len(features_df.drop(['Model_Details','Features_List'],axis=1).loc[('RandomForestClassifier','ManualSelection_Weighted_Transformed')]['Removed_Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_features_df(model,dataset):\n",
    "    model_name = type(model).__name__\n",
    "    features_df.loc[(model_name, dataset),'Num_Features'] = len(X_train_dict[dataset].columns) # so can store list of features\n",
    "    features_df.loc[(model_name, dataset),'Features_List'] = X_train_dict[dataset].columns.to_list()\n",
    "\n",
    "    original_list = set(features_df.loc[(model_name, 'Original'),'Features_List'])\n",
    "    dataset_list = set(features_df.loc[(model_name, dataset),'Features_List'])\n",
    "    removed_list = list(sorted(original_list - dataset_list))\n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Removed_Features'] = removed_list\n",
    "    features_df.loc[(model_name, dataset),'Model_Details'] = model\n",
    "\n",
    "def get_shapes(dataset):\n",
    "    # print(\"\\nShapes for dataset:\",dataset)\n",
    "    print(\"X_train Shape\",X_train_dict[dataset].shape)\n",
    "    print(\"X_test Shape\",X_test_dict[dataset].shape)\n",
    "    print(\"X_val Shape\",X_val_dict[dataset].shape)\n",
    "    # print(\"y_train Shape\",y_train.shape)\n",
    "    # print(\"y_test Shape\",y_test.shape)\n",
    "    # print(\"y_val Shape\",y_val.shape)\n",
    "\n",
    "def print_pipe_removed(pipe):\n",
    "    total_removed = 0\n",
    "    # print(\"\\nRemoved Features for Pipeline:\",pipe)\n",
    "    for i in range(len(pipe.steps)):\n",
    "        step_name = pipe.steps[i][0]\n",
    "        total_removed += len(pipe.named_steps[step_name].features_to_drop_)\n",
    "        print(step_name, \":\",len(pipe.named_steps[step_name].features_to_drop_))\n",
    "    print(\"Total removed:\",total_removed)\n",
    "\n",
    "# Calls all the above 3 functions\n",
    "def insert_and_print(model,dataset,pipe, manual_list):\n",
    "    print(\"\\nInserting Pipeline for dataset:\",dataset)\n",
    "\n",
    "    # This code INSERTS model's basic data into features_df\n",
    "    add_to_features_df(model,dataset)\n",
    "\n",
    "    # This code PRINTS X variables Shape\n",
    "    get_shapes(dataset)\n",
    "\n",
    "    # This code prints the features removed for each pipe step\n",
    "    if not manual_list: print_pipe_removed(pipe)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response['Labels'].unique()\n",
    "lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*****Change between Labels & Close_Up_Down columns for y_combined to make it either a Multiclass (5) or (3)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **cross_val_score - accuracy_score**                                                      \n",
    "# scoring https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\n",
    "\n",
    "def add_metrics(model,dataset,X_train_dict,X_test_dict,y_train,y_test,set='combined', sampled_weights=False):\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    metrics_list = ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted','neg_log_loss']\n",
    "\n",
    "    # Using BlockedTimeSeriesSplit cross val to calculate metrics\n",
    "    X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "\n",
    "    for metric in metrics_list:\n",
    "\n",
    "        if sampled_weights:\n",
    "        # cross_val_score with SAMPLE_WEIGHTS\n",
    "            score = cross_val_score(model, X, y.Labels, cv=btscv, scoring = str(metric),fit_params={'sample_weight':y.sample_weights.values}) #,error_score=\"raise\"\n",
    "        else:\n",
    "            score = cross_val_score(model, X, y.Labels, cv=btscv, scoring = str(metric)) #,error_score=\"raise\"\n",
    "            \n",
    "        features_df.loc[(model_name, dataset),metric]= round(np.mean(score),2)\n",
    "\n",
    "    # Calculating Class Wise Metrics - although predictions_from_custom_cross_val uses sample_weights to fit & predict but the metrics_from_cm doesn't use sample_weights\n",
    "    original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=sampled_weights)\n",
    "    cm = pd.DataFrame(confusion_matrix(original, predicted), index=Response['Labels'].unique(), columns=Response['Labels'].unique())\n",
    "    all_class_metric = metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))\n",
    "\n",
    "    # Calculating pnl_score & sharpe - Adj_ret_2 is Log Returns so can simply add them after multiplying with predictions\n",
    "    Test_adj_returns = y.Adj_ret_2.iloc[get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5)['test']].values.tolist()\n",
    "    return_list = [a*b for a,b in zip(Test_adj_returns,predicted)]\n",
    "    return_std = np.std(return_list)\n",
    "    pnl_score = np.sum(return_list)\n",
    "    sharpe_ratio = (pnl_score - 0.0)/return_std\n",
    "    features_df.loc[(model_name, dataset),'pnl'] = pnl_score\n",
    "    features_df.loc[(model_name, dataset),'sharpe'] = sharpe_ratio * np.sqrt(252) # Annualized\n",
    "\n",
    "\n",
    "    # Calculating Kappa Score \n",
    "    if sampled_weights:\n",
    "    # Kappa with SAMPLE_WEIGHTS\n",
    "        sample_weights = y.sample_weights.iloc[get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5)['test']].values.tolist()\n",
    "        kappa_score = cohen_kappa_score(original, predicted, sample_weight=sample_weights)\n",
    "    else:\n",
    "        kappa_score = cohen_kappa_score(original, predicted)\n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Kappa']= kappa_score\n",
    "    \n",
    "    # Insert the dataframe in a cell in features_df\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'] = np.array([])\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'].astype(object)\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'] =  [all_class_metric]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Transformation Func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTE THE MODEL PIPELINES ARE BEING CHECKED/FITTED TO TRAINING DATA WHILE THE METRICS ARE calculated ON Set option in func argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the following steps:\n",
    "# 1. Fill the dataset with passed X Variables\n",
    "# 2. If transform = True is passed, it fits and transforms the X variable. If sampled_weights equals True, it provides test sample weights to the fitting transformation\n",
    "# 3. Inserts model's basic data (length of features etc) into features_df, PRINTS X variables Shape & the features removed for each pipe step\n",
    "# 4. Add metrics to features_df using Blocked Time Series Cross Validation with TEST set\n",
    "\n",
    "def apply_model_transform(dataset,original_dataset, pipe, model,X_train_dict,X_test_dict,y_train,y_test, set='combined',manual_list = None, sampled_weights=False, transform = False):\n",
    "    fill_with_dataset(dataset,manual_list,original_dataset)\n",
    "    if transform: transform_features_space(dataset,pipe,sampled_weights)\n",
    "    insert_and_print(model,dataset,pipe, manual_list)    \n",
    "    add_metrics(model,dataset,X_train_dict,X_test_dict,y_train,y_test,set, sampled_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Models for both Classifiers & Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using xgb_clf for now because it is too slow\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "\n",
    "models = [rf_clf,xgb_clf]\n",
    "# models = [rf_clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe to Store Model Features & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [type(m).__name__ for m in models]\n",
    "dataset = 'Original'\n",
    "multilevel_index = pd.MultiIndex.from_product([model_names,[dataset]],names=['Model', 'Dataset'])\n",
    "cols_names = ['Model_Details','Num_Features','Features_List','Removed_Features'] + ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted','neg_log_loss','Kappa','pnl','sharpe','ClassDf']\n",
    "features_df = pd.DataFrame(columns=cols_names, index=multilevel_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initaiaze Dataset 'Original' as well as features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      " 0        911\n",
      " 1        828\n",
      "-1        780\n",
      "dtype: int64\n",
      "Labels\n",
      " 0        911\n",
      " 1        828\n",
      "-1        780\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty data passed with indices specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\model_building\\feat_select_WIP.ipynb Cell 47\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=2'>3</a>\u001b[0m     add_to_features_df(m,dataset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOriginal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=3'>4</a>\u001b[0m     add_metrics(model\u001b[39m=\u001b[39;49mm,dataset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mOriginal\u001b[39;49m\u001b[39m'\u001b[39;49m,X_train_dict\u001b[39m=\u001b[39;49mX_train_dict,X_test_dict\u001b[39m=\u001b[39;49mX_test_dict,y_train\u001b[39m=\u001b[39;49my_train,y_test\u001b[39m=\u001b[39;49my_test,\u001b[39mset\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcombined\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=5'>6</a>\u001b[0m \u001b[39m# Shapes\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=6'>7</a>\u001b[0m get_shapes(dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mOriginal\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\model_building\\feat_select_WIP.ipynb Cell 47\u001b[0m in \u001b[0;36madd_metrics\u001b[1;34m(model, dataset, X_train_dict, X_test_dict, y_train, y_test, set, sampled_weights)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=21'>22</a>\u001b[0m \u001b[39m# Calculating Class Wise Metrics - although predictions_from_custom_cross_val uses sample_weights to fit & predict but the metrics_from_cm doesn't use sample_weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=22'>23</a>\u001b[0m original, predicted \u001b[39m=\u001b[39m predictions_from_custom_cross_val(model,X, y, custom_cv \u001b[39m=\u001b[39m btscv, sampled_weights\u001b[39m=\u001b[39msampled_weights)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=23'>24</a>\u001b[0m cm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(confusion_matrix(original, predicted), index\u001b[39m=\u001b[39;49mResponse[\u001b[39m'\u001b[39;49m\u001b[39mLabels\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique(), columns\u001b[39m=\u001b[39;49mResponse[\u001b[39m'\u001b[39;49m\u001b[39mLabels\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=24'>25</a>\u001b[0m all_class_metric \u001b[39m=\u001b[39m metrics_from_cm(cm, lab \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(Response[\u001b[39m'\u001b[39m\u001b[39mLabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/model_building/feat_select_WIP.ipynb#ch0000053?line=26'>27</a>\u001b[0m \u001b[39m# Calculating pnl_score & sharpe - Adj_ret_2 is Log Returns so can simply add them after multiplying with predictions\u001b[39;00m\n",
      "File \u001b[1;32mC:\\source\\2x4-data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    695\u001b[0m             data,\n\u001b[0;32m    696\u001b[0m             index,\n\u001b[0;32m    697\u001b[0m             columns,\n\u001b[0;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    701\u001b[0m         )\n\u001b[0;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mC:\\source\\2x4-data\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    353\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mC:\\source\\2x4-data\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:418\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(columns) \u001b[39mor\u001b[39;00m values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m    415\u001b[0m     \u001b[39m# Could let this raise in Block constructor, but we get a more\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     \u001b[39m#  helpful exception message this way.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 418\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEmpty data passed with indices specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    420\u001b[0m     passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m     implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n",
      "\u001b[1;31mValueError\u001b[0m: Empty data passed with indices specified."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Takes 2 mins to run\n",
    "for m in models:\n",
    "    add_to_features_df(m,dataset='Original')\n",
    "    add_metrics(model=m,dataset='Original',X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test,set='combined')\n",
    "    \n",
    "# Shapes\n",
    "get_shapes(dataset = 'Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Functions to plot Blocked TimeSeries Split****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_splits = 5\n",
    "cv = BlockingTimeSeriesSplit\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "print(\"The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\")\n",
    "plot_timeseries_split(np.array(X_train_dict['Original']),np.array(y_train.Labels),n_splits,cmap_cv,cmap_data,cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all constant Variables\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why the following features have only one value\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue with using XGBOOST - takes long time and gives warnigs Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "# Takes 4 minutes to run\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = 'Constant_weighted'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=1, variables=None, missing_values='raise'))])\n",
    "\n",
    "                     \n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None,sampled_weights=True, transform = True)\n",
    "apply_model_transform(dataset,'Original', pipe, models[1],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None,sampled_weights=True, transform = True)\n",
    "\n",
    "dataset = 'Constant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=1, variables=None, missing_values='raise'))])\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=False, transform = True)\n",
    "# apply_model_transform(dataset,'Original', pipe, models[1],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=False, transform = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1 Model with 1 Feature only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Kappa Score for both these models - one with sampled weights and other without**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = 'Original'\n",
    "dataset = 'Spread_1-2'\n",
    "model = models[0]\n",
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond']\n",
    "# insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined')\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = feats_to_keep_list, sampled_weights=True, transform = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = 'Original'\n",
    "dataset = 'Spread_1-2_No_weights'\n",
    "model = models[0]\n",
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond']\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = feats_to_keep_list, sampled_weights=False, transform = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'QuasiConstant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=0.95, variables=None, missing_values='raise'))])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=True, transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Duplicated'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined', sampled_weights=True, transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated & Quasi Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Dupl&QConstant'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_model_transform(dataset,'QuasiConstant', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = None, sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Correlated'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test,set='combined', sampled_weights=True, transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated, Quasi Constant & Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_model_transform(dataset,'Dupl&QConstant', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list=None, sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean1 - Drop constant, quasi Constant, duplicated and correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 2 minutes to run\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean1'\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.95, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict,X_test_dict,y_train,y_test, set='combined',manual_list=None, sampled_weights=True, transform = True)\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[1],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list=None, sampled_weights=False, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1).loc[('RandomForestClassifier','Spread_1-2_No_weights')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'f1_weighted', 'neg_log_loss', 'cohen_kappa_score', 'precision_weighted','roc_auc_ovr_weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.sort_values(by=['pnl','f1_weighted','recall_weighted','precision_weighted'],ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do\n",
    "\n",
    "**Engineered**\n",
    "1. LB_High - LB_Low\n",
    "2. Get Other Basis\n",
    "3. Use some techincal Indicators\n",
    "\n",
    "**Raw**\n",
    "1. LB_Volume\t\n",
    "2. LB_openInterest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(Variables.columns.tolist()).to_csv('Variable_columns_names.csv',index=False)\n",
    "\n",
    "manual_list = pd.read_excel('C:/source/2x4-data/app/model_building/ManualSelectList.xlsx',sheet_name='Variables', index_col=0)\n",
    "manual_list = manual_list[manual_list.index == 1]\n",
    "manual_list = manual_list.values.tolist()\n",
    "manual_list = [x for xs in manual_list for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "original_dataset='Original'\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.90, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"precision_weighted\",cv=btscv,)),])\n",
    "\n",
    "dataset='ManualSelection_Weighted_Transformed'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, sampled_weights=True, transform = True)\n",
    "\n",
    "dataset='ManualSelection'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, sampled_weights=False, transform = False)\n",
    "\n",
    "dataset='ManualSelection_Transformed'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = manual_list, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features_df.drop(['Model_Details','Removed_Features','ClassDf'],axis=1).loc[('RandomForestClassifier','ManualSelection_Transformed')]['Features_List']).to_csv('C:/source/2x4-data/app/model_building/delete.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='ManualSelection_Try_1'\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict,X_test_dict,y_train,y_test, set='combined',manual_list = manual_list, sampled_weights=False, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1).loc[('RandomForestClassifier','ManualSelection_Weighted_Transformed')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information BY COHORT & Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Original'\n",
    "X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "X.columns = Variables_midx.columns\n",
    "train_idx  = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['train']\n",
    "test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['test']\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train1 = y.iloc[train_idx]\n",
    "\n",
    "\n",
    "top_cohort_variable = pd.DataFrame(index = Variables_midx.columns.get_level_values(0).unique(), columns=['Variable','Score','Col_name'])\n",
    "for outer_col in Variables_midx.columns.get_level_values(0).unique():\n",
    "    \n",
    "    sel_  = SelectKBest(mutual_info_classif, k=1).fit(X_train.loc[:,(outer_col,)], y_train1.Labels)\n",
    "    \n",
    "    selected_col = [x for x,y in zip(pd.DataFrame(X_train.loc[:,(outer_col,)]).columns,sel_.get_support()) if y]\n",
    "    # col_name = tuple(outer_col+','+selected_col[0])\n",
    "\n",
    "    selected_col_score = [x for x,y in zip(sel_.scores_,sel_.get_support()) if y]\n",
    "    # top_cohort_variable[outer_col] = [selected_col[0],selected_col_score[0]]\n",
    "    # cols = pd.MultiIndex.from_product([[outer_col], (selected_col[0])])\n",
    "    top_cohort_variable.loc[outer_col,'Variable'] = selected_col[0]\n",
    "    top_cohort_variable.loc[outer_col,'Score'] = selected_col_score[0]\n",
    "\n",
    "    try:\n",
    "        top_cohort_variable.loc[outer_col,'Col_name'] = outer_col+\" \"+selected_col[0]\n",
    "    except:\n",
    "        print(outer_col, selected_col[0])\n",
    "\n",
    "    # inner_cols = [x for x in pd.DataFrame(X_train.loc[:,(outer_col,)]).columns]    \n",
    "    # print(sel_.scores_)\n",
    "    # print(sel_.get_support())\n",
    "    # print(outer_col,selected_col[0])\n",
    "    # print(selected_col_score)\n",
    "    # print(top_cohort_variable[outer_col])\n",
    "    # print('\\n')\n",
    "\n",
    "    # TA_df.columns = [('TA_',x) for x in TA_df.columns]\n",
    "    \n",
    "# Make column names same as Variables\n",
    "for col in top_cohort_variable.Col_name:\n",
    "    top_cohort_variable.loc[top_cohort_variable['Col_name'] == col, 'Col_name'] = str(col).translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip()\n",
    "\n",
    "\n",
    "# Keeping only top 95% percentile of variables in terms of mutual info score - Enter 1- percentile value in the below line\n",
    "top_cohort_variable = top_cohort_variable[top_cohort_variable.Score > top_cohort_variable.Score.quantile(.05)]\n",
    "\n",
    "top_cohort_variable.sort_values(by=['Score'],ascending=False, inplace=True)\n",
    "\n",
    "top_cohort_variable.plot(x='Variable',y='Score',kind='bar', figsize=(20,10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "base_estimator = RandomForestClassifier(n_estimators=1, criterion='entropy', bootstrap=False)\n",
    "model = BaggingClassifier(base_estimator=base_estimator, n_estimators=100, max_features=1.0)\n",
    "dataset='Top_K_Cohort_MI_Weighted_Transformed_50%PERCENTILE'\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.90, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"precision_weighted\",cv=btscv,)),])\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = top_cohort_variable.Col_name.values.tolist(), sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(features_df.drop(['Model_Details','Removed_Features','ClassDf'],axis=1).loc[('RandomForestClassifier','Top_K_Cohort_MI_Weighted_Transformed_50%PERCENTILE')]['Features_List']).to_csv('Top_variable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_cohort_variable['Col_name'].to_csv('top_cohort_variable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE BY COHORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Original'\n",
    "X, y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "X.columns = Variables_midx.columns\n",
    "train_idx  = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['train']\n",
    "test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5, flatten = True)['test']\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train1 = y.iloc[train_idx]\n",
    "\n",
    "\n",
    "top_cohort_variable = pd.DataFrame(index = Variables_midx.columns.get_level_values(0).unique(), columns=['Variable','Score','Col_name'])\n",
    "for outer_col in Variables_midx.columns.get_level_values(0).unique():\n",
    "    \n",
    "\n",
    "    sel_ = SelectFromModel(RandomForestClassifier(n_estimators=10, random_state=10))\n",
    "\n",
    "    sel_.fit(X_train.loc[:,(outer_col,)], y_train1.Labels)\n",
    "\n",
    "    \n",
    "    sel_  = SelectKBest(mutual_info_classif, k=1).fit(X_train.loc[:,(outer_col,)], y_train1.Labels)\n",
    "    \n",
    "    selected_col = [x for x,y in zip(pd.DataFrame(X_train.loc[:,(outer_col,)]).columns,sel_.get_support()) if y]\n",
    "    # col_name = tuple(outer_col+','+selected_col[0])\n",
    "\n",
    "    selected_col_score = [x for x,y in zip(sel_.scores_,sel_.get_support()) if y]\n",
    "    # top_cohort_variable[outer_col] = [selected_col[0],selected_col_score[0]]\n",
    "    # cols = pd.MultiIndex.from_product([[outer_col], (selected_col[0])])\n",
    "    top_cohort_variable.loc[outer_col,'Variable'] = selected_col[0]\n",
    "    top_cohort_variable.loc[outer_col,'Score'] = selected_col_score[0]\n",
    "\n",
    "    try:\n",
    "        top_cohort_variable.loc[outer_col,'Col_name'] = outer_col+\" \"+selected_col[0]\n",
    "    except:\n",
    "        print(outer_col, selected_col[0])\n",
    "\n",
    "    # inner_cols = [x for x in pd.DataFrame(X_train.loc[:,(outer_col,)]).columns]    \n",
    "    # print(sel_.scores_)\n",
    "    # print(sel_.get_support())\n",
    "    # print(outer_col,selected_col[0])\n",
    "    # print(selected_col_score)\n",
    "    # print(top_cohort_variable[outer_col])\n",
    "    # print('\\n')\n",
    "\n",
    "    # TA_df.columns = [('TA_',x) for x in TA_df.columns]\n",
    "    \n",
    "# Make column names same as Variables\n",
    "for col in top_cohort_variable.Col_name:\n",
    "    top_cohort_variable.loc[top_cohort_variable['Col_name'] == col, 'Col_name'] = str(col).translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip()\n",
    "\n",
    "\n",
    "# Keeping only top 95% percentile of variables in terms of mutual info score - Enter 1- percentile value in the below line\n",
    "top_cohort_variable = top_cohort_variable[top_cohort_variable.Score > top_cohort_variable.Score.quantile(.5)] #0.05\n",
    "\n",
    "top_cohort_variable.sort_values(by=['Score'],ascending=False, inplace=True)\n",
    "\n",
    "top_cohort_variable.plot(x='Variable',y='Score',kind='bar', figsize=(20,10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cohort_variable['Col_name'].to_csv('top_cohort_variable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_cohort_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = models[1]\n",
    "dataset='Top_K_Cohort_FeatImp_Weighted_Transformed_50%PERCENTILE'\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"f1_weighted\",cv=btscv,)),])\n",
    "\n",
    "apply_model_transform(dataset,'Original', pipe, models[0],X_train_dict=X_train_dict,X_test_dict=X_test_dict,y_train=y_train,y_test=y_test, set='combined',manual_list = top_cohort_variable.Col_name.values.tolist(), sampled_weights=True, transform = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset in 3 Dictionaries of Training, Testing & Validation & Initiating features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: If metric calculations in add_metric function is calculated on Data which has even one class missing from y_predictions, it will throw an error (when error='raise' used), or it will be NaN for (roc_auc_ovr_weighted & roc_auc_ovo_weighted) if this option is not used in cross_val_score..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_  = SelectKBest(mutual_info_classif, k=20).fit(X_train, y_train1.Labels)\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the mutual information\n",
    "\n",
    "# mi = mutual_info_classif(X_train, y_train1.Labels)\n",
    "# mi = pd.Series(mi)\n",
    "# mi.index = X_train.columns\n",
    "# mi.sort_values(ascending=False).plot.bar(figsize=(20, 6))\n",
    "# plt.ylabel('Mutual Information')\n",
    "\n",
    "t = SelectKBest(mutual_info_classif).fit(X_train, y_train1.Labels)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.scores_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data = [t.scores_.tolist(),X_train.columns], columns = ['Score','Selected']).sort_values(by=['Score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yellowbricks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ManualSelection'\n",
    "X,y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "train_idx =  get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits, flatten=True)['train']\n",
    "test_idx = get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits, flatten=True)['test']\n",
    "X_train  = X.iloc[train_idx]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "y_test = y.iloc[test_idx]\n",
    "\n",
    "from yellowbrick.classifier import (ClassificationReport,  DiscriminationThreshold,)\n",
    "rf = RandomForestClassifier(max_depth=4, n_estimators=20, n_jobs=-1)\n",
    "visualizer = ClassificationReport(rf, support=True)\n",
    "\n",
    "visualizer.fit(X_train, y_train.Labels)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test , y_test.Labels)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and show the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ManualSelection'\n",
    "X,y = get_x_y_sets(dataset,X_train_dict,X_test_dict,y_train,y_test, set='combined')\n",
    "rf = RandomForestClassifier(max_depth=4, n_estimators=20, n_jobs=-1)\n",
    "original, predicted = predictions_from_custom_cross_val(rf,X, y, custom_cv = BlockingTimeSeriesSplit(n_splits=5), sampled_weights=True)\n",
    "# cm = pd.DataFrame(confusion_matrix(original, predicted), index=Response['Labels'].unique(), columns=Response['Labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_dict['ManualSelection']), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\n",
    "\n",
    "# The ConfusionMatrix visualizer taxes a model\n",
    "cm = ConfusionMatrix(model, classes=[-1,-0,1])\n",
    "\n",
    "# Fit fits the passed model. This is unnecessary if you pass the visualizer a pre-fitted model\n",
    "cm.fit(X_train, y_train)\n",
    "\n",
    "# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n",
    "# and then creates the confusion_matrix from scikit-learn.\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "# How did we do?\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1).loc[('RandomForestClassifier','ManualSelection')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict['Original'],X_test_dict['Original']],axis=0)\n",
    "y = pd.concat([y_train,y_test],axis=0)\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com1_original, com1_predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=False)\n",
    "com2_original, com2_predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=True)\n",
    "com1_original == com2_original, com1_predicted == com2_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(data = [pd.Series(com1_predicted).value_counts().sort_index(), pd.Series(com1_original).value_counts().sort_index()], index = ['predicted','original']).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = [pd.Series(com2_predicted).value_counts().sort_index(), pd.Series(com2_original).value_counts().sort_index()], index = ['predicted','original']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight='balanced'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",classes= lab, y = y.Labels)\n",
    "computed_sample_weights = compute_sample_weight('balanced', y.Labels)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame(data = [computed_sample_weights, y.Labels], index = ['computed_sample_weights','Labels']).T\n",
    "group_df\n",
    "group_df.groupby('Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Response[['Labels','sample_weights']].groupby('Labels').sum()\n",
    "# Response[['Labels','sample_weights']].groupby('Labels').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_bins_data(Response,'sample_weights',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','ManualSelection')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Clean1')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond','lumbermovingaverages MA200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = 'Original'\n",
    "dataset = 'Spread_1-2_wts'\n",
    "model = models[0]\n",
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond','lumbermovingaverages MA200']\n",
    "# insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined', sampled_weights= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "all_class_metric = metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_wts')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_MA200')]['ClassDf'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_MA200')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict[dataset].iloc[:, : 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'log_loss'\n",
    "\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "sfs = SFS(model, \n",
    "           k_features=6, # the more features we want, the longer it will take to run\n",
    "           forward=True, \n",
    "           floating=True, # see the docs for more details in this parameter\n",
    "           verbose=2, # this indicates how much to print out intermediate steps\n",
    "           scoring='f1_weighted', \n",
    "           cv=btscv,\n",
    "           n_jobs=-1,\n",
    "            \n",
    "         )\n",
    "\n",
    "weights = np.abs(y.Adj_ret_2.values)\n",
    "\n",
    "sfs = sfs.fit(X, y.Labels,sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST \n",
    "dataset = 'Original'\n",
    "X = X_train_dict[dataset].sort_index()\n",
    "y = y_train.sort_index() \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1, max_depth=1, n_jobs=-1)\n",
    "  \n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1,\n",
    "           max_features=1,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=btscv)\n",
    "\n",
    "efs1 = efs1.fit(X, y.Labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Clean1'\n",
    "model = RandomForestClassifier(n_estimators=5, max_depth=2, n_jobs=-1)\n",
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index()    \n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1,\n",
    "           max_features=2,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=btscv)\n",
    "\n",
    "efs1 = efs1.fit(X, y.Labels)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(efs1.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "plot_confusion_matrix(model, X_test_dict['Clean1'], y_test.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since it takes > 1 min\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "xgb.fit(X_train_dict['Clean1'], y_train.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = xgb.predict(X_test_dict['Clean1'])\n",
    "df1 = pd.DataFrame(np.transpose(precision_recall_fscore_support(y_test.Labels, y_pred, average=None)),columns=['precision', 'recall', 'fscore', 'support'], index=lab)\n",
    "df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "y_pred = model.predict(X_test_dict['Clean1'])\n",
    "\n",
    "# y_pred = cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv=5)\n",
    "# y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since takes ~ 1.30 minute\n",
    "# model = models[1]\n",
    "# model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# y_pred = model.predict(X_test_dict['Clean1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = models[0]\n",
    "\n",
    "X = X_test_dict['Clean1'].sort_index()\n",
    "y = y_test.sort_index()  \n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "280/1386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original), y_test.Labels.shape, len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_metric = metrics_from_cm(cm, lab = sorted(Response['Labels'].unique()))\n",
    "all_class_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(original, predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(original, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the dataframe in a cell in features_df\n",
    "# features_df['to_delete'] = None\n",
    "# features_df['to_delete'].astype(object)\n",
    "# features_df.loc[('RandomForestClassifier','Original'),'to_delete'] =  [all_class_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.loc[('RandomForestClassifier','Original'),'to_delete'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy - Negative Log Liklehood or Log Loss - Custom Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower The Better\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Original'], y_train.Labels)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "\n",
    "# This line required to convert for custom implementation from normal labels to indexed labels\n",
    "y_actuals = y_test.Labels.replace(to_replace=sorted(y_test.Labels.unique()), value=list(range(len(y_test.Labels.unique())))).values\n",
    "\n",
    "# Custom function to compute negative log loss\n",
    "nll = np.mean([-np.log(y_prob[i,j]) for i,j in zip(range(y_prob.shape[0]),y_actuals)])\n",
    "print(nll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1).loc[('RandomForestClassifier',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(y_actuals, y_prob))\n",
    "print(log_loss(y_test.Labels, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "model = models[0]\n",
    "dataset = 'Clean'\n",
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "scores = cross_val_score(model, X, y.Labels, cv=btscv, scoring=LogLoss)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogLoss._select_proba_binary(predicted,y_test.Labels.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probabilities_from_custom_cross_val(model,X, y, custom_cv = btscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# proba = cross_val_predict(model, X, y, cv=btscv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection Methods - Mostly just examine linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "# Plot\n",
    "# mi.plot.bar(figsize=(20, 6))\n",
    "# plt.ylabel('Mutual Information')\n",
    "\n",
    "# select features\n",
    "sel_ = SelectKBest(mutual_info_classif, k=15).fit(X_train, y_train)\n",
    "\n",
    "# display features\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-square Statistic - only suited for classification!                                         \n",
    "https://www.udemy.com/course/feature-selection-for-machine-learning/learn/lecture/22495182#questions\n",
    "https://github.com/solegalli/feature-selection-for-machine-learning/blob/main/05-Filter-Statistical-Tests/05.2-Fisher-score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the chi2 p_value between each of the variables and the target\n",
    "# chi2 returns 2 arrays, one contains the F-Scores which are then evaluated against the chi2 distribution to obtain the pvalue. The pvalues are in the second array\n",
    "\n",
    "# Input X must be non-negative\n",
    "X_train_non_negative = X_train[X_train.columns[((X_train < 0).sum(axis=0) == 0).values]]\n",
    "f_score = chi2(X_train_non_negative.fillna(0), y_train)\n",
    "pvalues = pd.Series(f_score[1])\n",
    "pvalues.index = X_train_non_negative.columns\n",
    "pvalues.sort_values(ascending=True, inplace = True)\n",
    "extremely_low_p_values = len(pvalues[pvalues < 1e-100])\n",
    "sel_ = SelectKBest(chi2, k= extremely_low_p_values).fit(X_train_non_negative, y_train)\n",
    "X_train_non_negative.columns[sel_.get_support()] # display features\n",
    "\n",
    "# X_train = sel_.transform(X_train)\n",
    "# X_test = sel_.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anova - tests 2 samples have same mean\n",
    "\n",
    "Assumptions:\n",
    "Sample are independant & normally distributed, homegeneity of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the univariate statistical measure between each of the variables and the target\n",
    "# similarly to chi2, the output is one array with f-scores and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=True, inplace = True) # The smaller the p_value the more predictive the feature is\n",
    "\n",
    "pvalue_above_5_percent = len(univariate[univariate < 0.05])\n",
    "sel_ = SelectKBest(f_classif, k=pvalue_above_5_percent).fit(X_train, y_train)\n",
    "features_to_keep = sel_.get_feature_names_out()\n",
    "features_to_keep\n",
    "\n",
    "# select features\n",
    "# X_train_anova = sel_.transform(X_train)\n",
    "# X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# # numpy array to dataframe\n",
    "# X_train_anova = pd.DataFrame(X_train_anova)\n",
    "# X_train_anova.columns = features_to_keep\n",
    "\n",
    "# X_test_anova = pd.DataFrame(X_test_anova)\n",
    "# X_test_anova.columns = features_to_keep\n",
    "\n",
    "# X_train_anova.shape, X_test_anova.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects features whose importance is greater than the threshold. - Thershold is the mean importance of all features\n",
    "sel_ = SelectFromModel(RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "TopNFeatures = pd.DataFrame(index = sel_.estimator_.feature_names_in_.tolist(),data = sel_.estimator_.feature_importances_, columns = ['Imp']).sort_values(by='Imp',ascending=False).head(20).index.tolist()\n",
    "pd.Series(sel_.estimator_.feature_importances_.ravel()).hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopNFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance Recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1:44 mins to run\n",
    "sel_ = RFE(RandomForestClassifier(n_estimators=100,  max_depth=3, n_jobs=-1), n_features_to_select=30).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "rf.fit(X_train[selected_features].fillna(0), y_train)\n",
    "y_pred = rf.predict(X_test[selected_features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[selected_features].fillna(0))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val.fillna(0), y_valid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set')\n",
    "pred = rf.predict_proba(X_train[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "print('Test set')\n",
    "pred = rf.predict_proba(X_test[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "print('Validation set')\n",
    "pred = rf.predict_proba(X_val[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_val, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Random Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1 min to run - You can use this procedure with any machine learning algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=2, n_jobs=-1)\n",
    "\n",
    "sel = SelectByShuffling(\n",
    "    variables=None, # automatically examine all numerical variables\n",
    "    estimator=rf, # the ML model\n",
    "    scoring='roc_auc', # the metric to evaluate\n",
    "    threshold=0,# the maximum performance drop allowed to select the feature\n",
    "    cv=btscv, # cross validation\n",
    ")\n",
    "\n",
    "sel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_ # performance of model trained with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(sel.performance_drifts_).sort_values(ascending=False).plot.bar(figsize=(16,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that will be removed\n",
    "\n",
    "print(len(sel.features_to_drop_))\n",
    "# remove features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "X_val = sel.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print( 'train auc score: ',roc_auc_score(y_train, (rf.predict_proba(X_train))[:,1]))\n",
    "print('test auc score: ', roc_auc_score(y_test, (rf.predict_proba(X_test))[:, 1]))\n",
    "print('Validation auc score: ', roc_auc_score(y_val, (rf.predict_proba(X_val))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "\n",
    "sel = RecursiveFeatureElimination(\n",
    "    variables=None, # automatically evaluate all numerical variables\n",
    "    estimator = model, # the ML model\n",
    "    scoring = 'roc_auc', # the metric we want to evalute\n",
    "    threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "    cv=btscv, # cross-validation\n",
    ")\n",
    "\n",
    "# this may take quite a while, because\n",
    "# we are building a lot of models with cross-validation\n",
    "# sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of model trained using all features\n",
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of all features based of initial model\n",
    "sel.feature_importances_.plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sel.performance_drifts_).plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Performance change when feature was added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features that will be removed\n",
    "\n",
    "len(sel.features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "y_pred = rf.predict(X_test[features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[features].fillna(0))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val .fillna(0), y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance in machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_basic_filter.shape, X_test_basic_filter.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter methods - basic\n",
    "run_randomForests(X_train_basic_filter,X_test_basic_filter,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression and compare performance in train and test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "run_logistic(scaler.transform(X_train),\n",
    "             scaler.transform(X_test),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>Pipelines:</b> Final Code will look like this but for now work through issues above \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.9, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.9,missing_values=\"raise\",selection_method=\"variance\",estimator=rf,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# remove features\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)\n",
    "X_val = pipe.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pipe.named_steps['constant'].features_to_drop_))\n",
    "pipe.named_steps['duplicated'].features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT USING - for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Brute Force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        \n",
    "        for j in range(i):\n",
    "            \n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "             \n",
    "                print(abs(corr_matrix.iloc[i, j]),\":\", corr_matrix.columns[i], \"<< - >>\", corr_matrix.columns[j])\n",
    "                colname = corr_matrix.columns[j]\n",
    "                \n",
    "                # and add it to our correlated set\n",
    "                col_corr.add(colname)\n",
    "                \n",
    "    return col_corr\n",
    "\n",
    "# corr_features = correlation(X_train, 0.9)\n",
    "# len(set(corr_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_features = correlation(X_train, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.9]\n",
    "corrmat = corrmat[corrmat < 1] # Not Interested in the correlation with 1 since will be with the same variable\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    \n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group in correlated_groups:\n",
    "#     print(group)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Group Index\n",
    "group_index = 1\n",
    "\n",
    "group = correlated_groups[group_index]\n",
    "var = group.feature1.unique()[0]\n",
    "\n",
    "# add all features of the group to a list\n",
    "features = list(group['feature2'].unique())+[var]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "\n",
    "print(var)\n",
    "importance.sort_values(by='importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in group['feature2']:\n",
    "#     plt.scatter(X_train[var], X_train[feature])\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.ylabel(var)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just an example to show one group of how smart correlation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "group = sel.correlated_feature_sets_[0]\n",
    "\n",
    "# build random forest with cross validation for each feature\n",
    "for f in group:\n",
    "    \n",
    "    model = cross_validate(\n",
    "        rf,\n",
    "        X_train[f].to_frame(),\n",
    "        y_train,\n",
    "        cv=btscv,\n",
    "        return_estimator=False,\n",
    "        scoring='accuracy',\n",
    "    )\n",
    "\n",
    "#  scoring='roc_auc' does not support categorical data.\n",
    "\n",
    "    print(f, model[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation metrics\n",
    "1. cross_val_score\n",
    "2. Area under the ROC Curve\n",
    "3. Confusion Matrix\n",
    "4. Confusion Report\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "cross_val_score(model, Variables, Response.Close_Up_Down, cv = 2, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Original'], y_train.Labels, cv = 5,scoring='roc_auc_ovo_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv = 5,scoring='roc_auc_ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "\n",
    "for p in [0.475,0.5,0.525]:\n",
    "    \n",
    "    y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "    print(\"tpr:\",tpr)\n",
    "    print(\"fpr:\",fpr)\n",
    "    print(\"threshold:\",threshold)\n",
    "    print(p,\": \",roc_auc_score(y_test.Close_Up_Down, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/45715018/scikit-learn-how-to-plot-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "plt.figure(figsize=(12,5))\n",
    "prediction = clf.predict_proba(X_test_dict['Clean'])[:,1]\n",
    "plt.hist(prediction[y_test.Close_Up_Down==-1], bins=100, label='Negatives')\n",
    "plt.hist(prediction[y_test.Close_Up_Down==1], bins=100, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Probability of being Positive Class', fontsize=10)\n",
    "plt.ylabel('Number of records in each bucket', fontsize=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=25, pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(y_test, model_set, model):\n",
    "    model.fit(X_train_dict[model_set], y_train.Close_Up_Down)\n",
    "    y_prob_positive = model.predict_proba(X_test_dict[model_set])[:,1]\n",
    "    print(f\"ROC_AUC_SCORE: {roc_auc_score(y_test.Close_Up_Down, y_prob_positive):.2f}%\")\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_prob_positive,)\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "\n",
    "plot_roc_auc_curve(y_test, 'Original', model)\n",
    "# plot_roc_auc_curve(y_test, 'Original', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred == [-1 if x[0] > 0.5 else 1 for x in y_prob]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took 5:20 mins\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "# cross_val_score(model, Variables, Response.Close_Up_Down, cv = 5).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "conf_mat = confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "sns.heatmap(pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted']), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues');\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_val_dict['Clean'], y_val.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Close_Up_Down, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report['-1.0']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, det_curve\n",
    "precision_score(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44a86d6b397dbc6b70abfa92d378adf5d728e5b92754036aace887a2a3f0f490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
