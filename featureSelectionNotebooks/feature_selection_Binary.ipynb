{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\\\VSYS-P-GW01.cloud.vsys.ca\\RDFolderRedirect$\\fanjum_cwp\\Desktop\\Python\\2x4\\venv\\Lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, \\\n",
    "plot_confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score, make_scorer, log_loss, cohen_kappa_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "\n",
    "\n",
    "# to determine the p-values with anova\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# to select features\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE # Recursive Feature Elimination\n",
    "\n",
    "from feature_engine.selection import DropDuplicateFeatures, DropConstantFeatures, SmartCorrelatedSelection, SelectByShuffling, RecursiveFeatureElimination\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas_market_calendars as mcal\n",
    "import warnings\n",
    "\n",
    "\n",
    "from support._model_build_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from Excel daily_dataframe_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1 min 40 secs to run\n",
    "Variables = pd.read_excel('daily_dataframe_main.xlsx', header=[0,1], sheet_name='Variables',index_col=0)\n",
    "Response = pd.read_excel('daily_dataframe_main.xlsx',sheet_name= 'Response' ,index_col=0)\n",
    "\n",
    "# Just using Unadjusted data for now\n",
    "# Response = Response[['LB_Close','Close_ret','Close_Up_Down']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Values\n",
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>Check:</b> Backfilling and then frontfilling Variables DataFrame, and filling zeros with Median? - Check if it makes sense\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables.fillna(method='bfill', inplace=True)\n",
    "# Variables.fillna(method='ffill', inplace=True)\n",
    "# Replacing 0 with Median Values\n",
    "# Variables.replace(to_replace=0, method='bfill', inplace=True) \n",
    "# Variables.replace(to_replace=0, method=Variables.median(), inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "Variables = add_date_features(Variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# TA_df = Variables[['LumberOHLCV LBHigh','LumberOHLCV LBLow','LumberOHLCV LBClose','LumberOHLCV LBVolume','LumberOHLCV LBopenInterest']]\n",
    "TA_df = Variables.loc[:,('Lumber_OHLCV',)][['LB_High','LB_Low','LB_Close','LB_Volume','LB_openInterest']]\n",
    "\n",
    "TA_df.columns = ['High','Low','Close','Volume','OpenInterest']\n",
    "TA_df['Open'] = TA_df['Close'].shift(-1)\n",
    "\n",
    "# TA_df['weekday'] = Variables.index.weekday\n",
    "# TA_df = TA_df[~TA_df.weekday.isin([5,6])]\n",
    "# TA_df = TA_df.drop(['weekday'],axis=1)\n",
    "\n",
    "TA_df = dropna(TA_df)\n",
    "TA_df.sort_index(ascending=True, inplace=True)\n",
    "TA_df = add_all_ta_features(TA_df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "TA_df.sort_index(ascending=False, inplace=True)\n",
    "TA_df.drop(['Open','High','Low','Close','Volume','OpenInterest'],axis=1,inplace=True)\n",
    "TA_df.columns = [str('TA_') + TA_df.columns]\n",
    "TA_df = TA_df.replace([np.inf, -np.inf], np.nan).fillna(TA_df.mean())\n",
    "Variables = pd.concat([Variables,TA_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing punctuation strings in column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [str(w).translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip() for w in Variables.columns]\n",
    "Variables.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Last Available Date for each Variable in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LumberOHLCV LBHigh</th>\n",
       "      <td>2022-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy ChangeinNoncommercialLongAll</th>\n",
       "      <td>2022-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy NoncommercialPositionsShortOther</th>\n",
       "      <td>2022-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy NoncommercialPositionsSpreadingOther</th>\n",
       "      <td>2022-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy CommercialPositionsLongOther</th>\n",
       "      <td>2022-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanproduction TotalNorthAmerica</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanshipment PrairiesAndEasternCanada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanshipment TotalNorthAmerica</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy TotalReportablePositionsLongAll</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy ConcentrationGrossLT4TDRShortOl</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       End_Dt\n",
       "LumberOHLCV LBHigh                                 2022-07-12\n",
       "CFTClegacy ChangeinNoncommercialLongAll            2022-07-12\n",
       "CFTClegacy NoncommercialPositionsShortOther        2022-07-12\n",
       "CFTClegacy NoncommercialPositionsSpreadingOther    2022-07-12\n",
       "CFTClegacy CommercialPositionsLongOther            2022-07-12\n",
       "...                                                       ...\n",
       "LumberTracknorthamericanproduction TotalNorthAm...        NaT\n",
       "LumberTracknorthamericanshipment PrairiesAndEas...        NaT\n",
       "LumberTracknorthamericanshipment TotalNorthAmerica        NaT\n",
       "CFTClegacy TotalReportablePositionsLongAll                NaT\n",
       "CFTClegacy ConcentrationGrossLT4TDRShortOl                NaT\n",
       "\n",
       "[769 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_valid_loc = pd.DataFrame(data=Variables.apply(lambda col: col.last_valid_index()), columns = ['End_Dt'])\n",
    "last_valid_loc.sort_values(by='End_Dt', ascending=False ,inplace=True)\n",
    "# last_valid_loc = last_valid_loc[last_valid_loc.End_Dt.notna()]\n",
    "last_valid_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LumberTracklumberexportus TotalLumberExports</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanproduction PrairiesAndEasternCanada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanproduction TotalNorthAmerica</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanshipment PrairiesAndEasternCanada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanshipment TotalNorthAmerica</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy TotalReportablePositionsLongAll</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy ConcentrationGrossLT4TDRShortOl</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   End_Dt\n",
       "LumberTracklumberexportus TotalLumberExports          NaT\n",
       "LumberTracknorthamericanproduction PrairiesAndE...    NaT\n",
       "LumberTracknorthamericanproduction TotalNorthAm...    NaT\n",
       "LumberTracknorthamericanshipment PrairiesAndEas...    NaT\n",
       "LumberTracknorthamericanshipment TotalNorthAmerica    NaT\n",
       "CFTClegacy TotalReportablePositionsLongAll            NaT\n",
       "CFTClegacy ConcentrationGrossLT4TDRShortOl            NaT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_valid_loc[last_valid_loc.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> For now using custom based method - but change it eventually with KNN (or Multivariate) Imputation etc.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 35 secounds to run\n",
    "Variables = DataFrameImputer().fit_transform(Variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Days and after 2011\n",
    "<div style=\"color: Red; font-size:22px;\" class=\"alert alert-block alert-warning\">  Restricting the dataset since 2011 only trading days for cme agriculture - ideally should be for CME Lumber!!\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Issues is we have some forward fills which doesn't represent data correctly\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2903, 2903)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables.sort_index(ascending = False, inplace = True)\n",
    "Response.sort_index(ascending = False, inplace = True)\n",
    "\n",
    "cme = mcal.get_calendar(\"CME_Agriculture\")\n",
    "cme_trading_days = cme.schedule(start_date=Variables.index[-1].date(), end_date=Variables.index[0].date()).index\n",
    "cme_trading_days = cme_trading_days.sort_values(ascending=False)\n",
    "cme_trading_days = pd.DatetimeIndex(cme_trading_days)\n",
    "\n",
    "Variables = Variables[Variables.index > '2011-01-01']\n",
    "Variables = Variables[Variables.index.isin(cme_trading_days)]\n",
    "\n",
    "Response = Response[Response.index > '2011-01-01']\n",
    "Response = Response[Response.index.isin(cme_trading_days)]\n",
    "# Response = Response[(Response.Close_Up_Down == 1) | (Response.Close_Up_Down == -1)]\n",
    "\n",
    "Variables.index = pd.DatetimeIndex(Variables.index)\n",
    "Response.index = pd.DatetimeIndex(Response.index)\n",
    "Variables = Variables.reindex(Response.index)\n",
    "\n",
    "len(Variables), len(Response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiClassification Targets - Choose between 3 or 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      " 1        1055\n",
      "-1        1030\n",
      " 0         818\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pv_1 = 0.005 # higher and lower than 0.5% return\n",
    "pv_2 = 0.015 # higher and lower than 1.5% return\n",
    "col = 'Close_ret' # Can also be 'Adj_close_ret'\n",
    "\n",
    "num_classes = 3 # Choose 3 or 5\n",
    "\n",
    "if num_classes == 3:\n",
    "\n",
    "    mutli_class_buckets = Response[col].value_counts(bins = [Response[col].min(),-pv_2, pv_2,Response[col].max()])\n",
    "    mutli_class_buckets.sort_index(ascending=True, inplace=True)\n",
    "    mutli_class_buckets.index = ['Down','Neutral','Up']\n",
    "    mutli_class_buckets.plot(kind='bar');\n",
    "\n",
    "    Neutral = ((Response[col] > -pv_2) & (Response[col] < pv_2))\n",
    "    Down = (Response[col] < -pv_2) \n",
    "    Up = (Response[col] > pv_2)\n",
    "\n",
    "    conditions = [Down, Neutral, Up]\n",
    "    choices = [-1, 0, 1]\n",
    "    multi_class = np.select(conditions, choices, default=0)\n",
    "\n",
    "    Target = pd.DataFrame(index = Response.index, data = multi_class)\n",
    "    Target.columns = ['Labels']\n",
    "    Response['Labels'] = Target.Labels.values\n",
    "    print(Target.value_counts())\n",
    "\n",
    "elif num_classes == 5:\n",
    "    mutli_class_buckets = Response[col].value_counts(bins = [Response[col].min(),-pv_2, -pv_1,pv_1, pv_2,Response[col].max()])\n",
    "    mutli_class_buckets.sort_index(ascending=True, inplace=True)\n",
    "    mutli_class_buckets.index = ['Strong_Down','Down','Neutral','Up','Strong_Up']\n",
    "    mutli_class_buckets.plot(kind='bar');\n",
    "\n",
    "    Neutral = ((Response[col] > -pv_1) & (Response[col] < pv_1))\n",
    "    Down = ((Response[col] > -pv_2) & (Response[col] < -pv_1))\n",
    "    Up = ((Response[col] > pv_1) & (Response[col] < pv_2))\n",
    "    Strong_Down = (Response[col] < -pv_2) \n",
    "    Strong_Up = (Response[col] > pv_2)\n",
    "\n",
    "    conditions = [Strong_Down, Down, Neutral, Up, Strong_Up]\n",
    "    choices = [-2, -1, 0, 1, 2]\n",
    "    multi_class = np.select(conditions, choices, default=0)\n",
    "\n",
    "    Target = pd.DataFrame(index = Response.index, data = multi_class)\n",
    "    Target.columns = ['Labels']\n",
    "    Response['Labels'] = Target.Labels.values\n",
    "    print(Target.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -- Choose Response Variable here - LB_Close, Close_ret, Close_Up_Down, OR Adjusted Data from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Variables with all NaNs\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why these variables have NaNs\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CFTClegacy ConcentrationGrossLT4TDRShortOl',\n",
       " 'CFTClegacy TotalReportablePositionsLongAll',\n",
       " 'LumberTracklumberexportus TotalLumberExports',\n",
       " 'LumberTracknorthamericanproduction PrairiesAndEasternCanada',\n",
       " 'LumberTracknorthamericanproduction TotalNorthAmerica',\n",
       " 'LumberTracknorthamericanshipment PrairiesAndEasternCanada',\n",
       " 'LumberTracknorthamericanshipment TotalNorthAmerica'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables_with_nans = set(Variables.columns) - set(Variables.drop(Variables.columns[Variables.isna().all()].to_list(), axis=1).columns)\n",
    "Variables_with_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    744\n",
      "int64       11\n",
      "bool         7\n",
      "dtype: int64\n",
      "Total Variables Left: 762\n"
     ]
    }
   ],
   "source": [
    "Variables.drop(Variables.columns[Variables.isna().all()].to_list(), axis=1, inplace=True)\n",
    "Variables.drop(Variables.columns[Variables.isnull().all()].to_list(), axis=1, inplace=True)\n",
    "print(pd.Series(Variables.dtypes.values).value_counts())\n",
    "print(\"Total Variables Left:\",pd.Series(Variables.dtypes.values).value_counts().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    6\n",
       "int32      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Response.drop(Response.columns[Response.isna().all()].to_list(), axis=1, inplace=True)\n",
    "Response.drop(Response.columns[Response.isnull().all()].to_list(), axis=1, inplace=True)\n",
    "pd.Series(Response.dtypes.values).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Bool cols (mostly date columns such as Is_year_end etc.) to int columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_bool_cols = Variables.columns[Variables.dtypes.values == 'bool'].to_list()\n",
    "list_of_bool_cols_response = Response.columns[Response.dtypes.values == 'bool'].to_list()\n",
    "\n",
    "for col in list_of_bool_cols:\n",
    "    Variables[col] = Variables[col].astype(int)\n",
    "\n",
    "for col in list_of_bool_cols_response:\n",
    "    Response[col] = Response[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample weights - Removed Outliers from Response by replacing with IQR*1.5 upper and lower limits\n",
    "\n",
    "**TODO** - \n",
    "1. If we put returns as Sample weights, he model will ignore all rows where returns equals 0 and that class will be under represented - Look at class_weight and sample_weight\n",
    "2. sample_weight for fit method is clear but what does it mean to pass sample_weight to sklearn score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.2677330876148725\n",
      "Min: -0.4076413875307594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.409, -0.333]      0.03\n",
       "(-0.333, -0.258]      0.00\n",
       "(-0.258, -0.183]      0.07\n",
       "(-0.183, -0.107]      0.38\n",
       "(-0.107, -0.0324]     6.65\n",
       "(-0.0324, 0.0426]    89.05\n",
       "(0.0426, 0.118]       3.62\n",
       "(0.118, 0.193]        0.14\n",
       "(0.193, 0.268]        0.07\n",
       "Name: Adj_Close_ret, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Adj_Close_ret'\n",
    "create_bins_data(Response, col, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagnostic_plots(Response, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adj_Close_ret': -0.053331250947187936, 'Close_ret': -0.12778431181013916}\n",
      "{'Adj_Close_ret': 0.054557283268807044, 'Close_ret': 0.12813728261815127}\n",
      "        sample_weights\n",
      "Labels                \n",
      "-1           29.987036\n",
      " 0           21.428891\n",
      " 1           30.112441\n",
      "        sample_weights\n",
      "Labels                \n",
      "-1            0.029114\n",
      " 0            0.026197\n",
      " 1            0.028543\n"
     ]
    }
   ],
   "source": [
    "cols_to_winsorize = ['Adj_Close_ret', 'Close_ret']\n",
    "\n",
    "# Feature engine WINSORIZER\n",
    "winsoriser = Winsorizer(capping_method='iqr', # choose iqr for IQR rule boundaries or gaussian for mean and std\n",
    "                          tail='both', # cap left, right or both tails \n",
    "                          fold=1.5, # This is the in\n",
    "                          variables=cols_to_winsorize)\n",
    "\n",
    "winsoriser.fit(Response)\n",
    "Response = winsoriser.transform(Response)\n",
    "print(winsoriser.left_tail_caps_)\n",
    "print(winsoriser.right_tail_caps_)\n",
    "\n",
    "sample_weights = np.abs(Response['Adj_Close_ret'].values)\n",
    "Response['sample_weights'] = sample_weights\n",
    "\n",
    "# Since we are weighing each sample by returns, samples with return zero will be ignored by the model so need to increase its weight to maximum\n",
    "Response.loc[Response['sample_weights'] < 0.005, 'sample_weights'] = sample_weights.max()\n",
    "\n",
    "\n",
    "print(Response[['Labels','sample_weights']].groupby('Labels').sum())\n",
    "print(Response[['Labels','sample_weights']].groupby('Labels').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.054557283268807044\n",
      "Min: 0.005034412378459585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00403, 0.0105]    19.91\n",
       "(0.0105, 0.016]      16.05\n",
       "(0.016, 0.0215]      12.99\n",
       "(0.0215, 0.027]       8.27\n",
       "(0.027, 0.0325]       6.68\n",
       "(0.0325, 0.038]       5.06\n",
       "(0.038, 0.0436]       3.03\n",
       "(0.0436, 0.0491]      2.14\n",
       "(0.0491, 0.0546]     25.87\n",
       "Name: sample_weights, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bins_data(Response, 'sample_weights', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION METRICS & generate_sample_confusion_matrix\n",
    "    1. Recall/Sensitivity/TPR: tp / (tp + fn) - **%age of a TRUE/Positives class correctly identified/ ability to find all the positive samples**. This deciedes how many times we trade since its the propotion of actual positives we are able to detect.\n",
    "    2. Specificity (TNR) is tn / (tn + fp) - %age of a FALSE/Negatives class correctly identified\n",
    "    3. False Positive Rate (FPR) = 1 - Specificity or fp / (tn + fp). \n",
    "    4. Accuracy is TP/ entire matrix sum ???\n",
    "    5. Precision is tp / (tp + fp) - the ability not to label a negative sample as positive. This deciedes our PROFITABILITY since we don't want FALSE Positives\n",
    "    6. Support is the number of occurrences of each class  - sum of respective row\n",
    "    7. Macro - unweighted mean. This does not take label imbalance into account.\n",
    "    8. Wt_Avg - average weighted by support\n",
    "    9. Micro - same as accuracy - sum of diagnols/ sum of all matrix\n",
    "\n",
    "**True/False (Positives/Negatives) means if a sample belongs/doesn't belong to a class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_69d05_row0_col0 {\n",
       "  color: green;\n",
       "}\n",
       "#T_69d05_row0_col1, #T_69d05_row0_col2 {\n",
       "  color: blue;\n",
       "}\n",
       "#T_69d05_row1_col0, #T_69d05_row2_col0 {\n",
       "  color: orange;\n",
       "}\n",
       "#T_69d05_row1_col1, #T_69d05_row1_col2, #T_69d05_row2_col1, #T_69d05_row2_col2 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_69d05\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_69d05_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_69d05_level1_col0\" class=\"col_heading level1 col0\" >-1</th>\n",
       "      <th id=\"T_69d05_level1_col1\" class=\"col_heading level1 col1\" >0</th>\n",
       "      <th id=\"T_69d05_level1_col2\" class=\"col_heading level1 col2\" >1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_69d05_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">Actual</th>\n",
       "      <th id=\"T_69d05_level1_row0\" class=\"row_heading level1 row0\" >-1</th>\n",
       "      <td id=\"T_69d05_row0_col0\" class=\"data row0 col0\" >True Positive</td>\n",
       "      <td id=\"T_69d05_row0_col1\" class=\"data row0 col1\" >False Negative</td>\n",
       "      <td id=\"T_69d05_row0_col2\" class=\"data row0 col2\" >False Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d05_level1_row1\" class=\"row_heading level1 row1\" >0</th>\n",
       "      <td id=\"T_69d05_row1_col0\" class=\"data row1 col0\" >False Positive</td>\n",
       "      <td id=\"T_69d05_row1_col1\" class=\"data row1 col1\" >True Negative</td>\n",
       "      <td id=\"T_69d05_row1_col2\" class=\"data row1 col2\" >True Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d05_level1_row2\" class=\"row_heading level1 row2\" >1</th>\n",
       "      <td id=\"T_69d05_row2_col0\" class=\"data row2 col0\" >False Positive</td>\n",
       "      <td id=\"T_69d05_row2_col1\" class=\"data row2 col1\" >True Negative</td>\n",
       "      <td id=\"T_69d05_row2_col2\" class=\"data row2 col2\" >True Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c726a52920>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = Response.Labels.unique()\n",
    "lab.sort()\n",
    "\n",
    "generate_sample_confusion_matrix(-1,lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocked Time Series cross-validation\n",
    "https://goldinlocks.github.io/Time-Series-Cross-Validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "btscv = BlockingTimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These metrics (weighted & average) do NOT exactly match the output of features_df metrics** \n",
    "** Also note that the weighted average results are not based on sample_weights for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics from Confusion Matrix Custom Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_from_cm(cm, lab = sorted(Response['Labels'].unique())):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    pre = {}\n",
    "    rec = {}\n",
    "    tp = {}\n",
    "    tn = {}\n",
    "    fp = {}\n",
    "    fn = {}\n",
    "    weighted_average = {}\n",
    "    for cat in lab:\n",
    "        pre[cat] = np.nan_to_num(cm.loc[cat,cat]/cm.sum(axis=0).loc[cat], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        rec[cat] = np.nan_to_num(cm.loc[cat,cat]/cm.sum(axis=1).loc[cat], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        tp[cat] = cm.loc[cat, cat]\n",
    "        tn[cat] = cm.drop(cat,axis=1).drop(cat,axis=0).sum().sum()\n",
    "        fp[cat] = cm[cat].drop(cat).sum()\n",
    "        fn[cat] = cm.loc[cat].drop(cat).sum()\n",
    "\n",
    "    df = pd.concat([pd.DataFrame.from_dict(pre,orient='index', columns=['precision']),pd.DataFrame.from_dict(rec,orient='index', columns=['recall'])], axis=1)\n",
    "    df['fscore'] = (2 * ((df.precision * df.recall) / (df.precision + df.recall))).fillna(0)\n",
    "    df['tp'] = pd.Series(tp)\n",
    "    df['tn'] = pd.Series(tn)\n",
    "    df['fp'] = pd.Series(fp)\n",
    "    df['fn'] = pd.Series(fn)\n",
    "\n",
    "    df['specificity'] =  pd.Series(df.tn / (df.tn + df.fp))\n",
    "    df['fpr'] = pd.Series(df.fp / (df.tn + df.fp))\n",
    "    df['accuracy'] = (df.tp + df.tn) / (df.tp + df.tn + df.fp + df.fn)\n",
    "    df['support'] = cm.sum(axis=1)\n",
    "\n",
    "    main_metrics_list = ['precision', 'recall', 'fscore', 'specificity','fpr', 'accuracy']\n",
    "    df_perc = df[main_metrics_list]\n",
    "    df = pd.concat([df_perc,df.tp,df.tn,df.fp,df.fn,df.support], axis=1)\n",
    "\n",
    "    # Weighted average\n",
    "    for cols in df.columns:\n",
    "        if cols in main_metrics_list:\n",
    "            weighted_average[cols] = df[cols].dot(df.support)/df.support.sum()\n",
    "        else:\n",
    "            weighted_average[cols] = None\n",
    "\n",
    "    df.loc['macro',main_metrics_list] = df[main_metrics_list].mean()\n",
    "\n",
    "    weight_df = pd.DataFrame.from_dict(weighted_average,orient='index', columns=['Wt_Avg']).T\n",
    "    df = pd.concat([df, weight_df], axis=0)\n",
    "\n",
    "    # % Formatting\n",
    "    for col in main_metrics_list:\n",
    "        try:\n",
    "            df[col] = df[col].mul(100).round(0).astype(int).astype(str).add('%')\n",
    "        except:\n",
    "            pass\n",
    "    other_list = ['tp', 'tn', 'fp', 'fn', 'support']\n",
    "\n",
    "    df.loc['macro', other_list] = df.loc[lab, other_list] .sum()\n",
    "    df.loc['Wt_Avg', other_list] = df.loc[lab, other_list] .sum()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42562146/classification-report-with-nested-cross-validation-in-sklearn-average-individua\n",
    "def predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=False):    \n",
    "    # Variables to store original and predicted values\n",
    "    original = []\n",
    "    predicted = []\n",
    "\n",
    "    def score_func(y_true, y_pred):\n",
    "        original.extend(y_true)\n",
    "        predicted.extend(y_pred)\n",
    "\n",
    "    if sampled_weights:\n",
    "    # Cross Val Score with SAMPLE WeIGHTS        \n",
    "        scores = cross_val_score(model, X, y.Labels, cv=btscv, scoring=make_scorer(score_func),fit_params={'sample_weight':np.abs(y.sample_weights.values)} ) #,error_score=\"raise\"\n",
    "    else:\n",
    "        scores = cross_val_score(model, X, y.Labels, cv=btscv, scoring=make_scorer(score_func) ) #,error_score=\"raise\"\n",
    "    return original, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_dataset(new_dataset,original_dataset):\n",
    "    X_train_dict[new_dataset] = X_train_dict[original_dataset]\n",
    "    X_test_dict[new_dataset] = X_test_dict[original_dataset]\n",
    "    X_val_dict[new_dataset] = X_val_dict[original_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_features_df(model,dataset):\n",
    "    model_name = type(model).__name__\n",
    "    features_df.loc[(model_name, dataset),'Num_Features'] = len(X_train_dict[dataset].columns) # so can store list of features\n",
    "    features_df.loc[(model_name, dataset),'Features_List'] = X_train_dict[dataset].columns.to_list()\n",
    "\n",
    "    original_list = set(features_df.loc[(model_name, 'Original'),'Features_List'])\n",
    "    dataset_list = set(features_df.loc[(model_name, dataset),'Features_List'])\n",
    "    removed_list = list(sorted(original_list - dataset_list))\n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Removed_Features'] = removed_list\n",
    "    features_df.loc[(model_name, dataset),'Model_Details'] = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(dataset):\n",
    "    print(\"\\nShapes for dataset:\",dataset)\n",
    "    print(\"X_train Shape\",X_train_dict[dataset].shape)\n",
    "    print(\"X_test Shape\",X_test_dict[dataset].shape)\n",
    "    print(\"X_val Shape\",X_val_dict[dataset].shape)\n",
    "    # print(\"y_train Shape\",y_train.shape)\n",
    "    # print(\"y_test Shape\",y_test.shape)\n",
    "    # print(\"y_val Shape\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pipe_removed(pipe):\n",
    "    total_removed = 0\n",
    "    print(\"\\nRemoved Features for Pipeline:\",pipe)\n",
    "    for i in range(len(pipe.steps)):\n",
    "        step_name = pipe.steps[i][0]\n",
    "        total_removed += len(pipe.named_steps[step_name].features_to_drop_)\n",
    "        print(step_name, \":\",len(pipe.named_steps[step_name].features_to_drop_))\n",
    "    print(\"Total removed:\",total_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(dataset,pipe):\n",
    "    print(\"\\nRemoving Features for dataset:\",dataset)\n",
    "    print(\"# Features before:\",len(X_train_dict[dataset].columns.to_list()))\n",
    "    X_train_dict[dataset] = pipe.transform(X_train_dict[dataset])\n",
    "    X_test_dict[dataset] = pipe.transform(X_test_dict[dataset])\n",
    "    X_val_dict[dataset] = pipe.transform(X_val_dict[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_features(dataset,feats_to_keep_list):\n",
    "    print(\"\\nRemoving Features for dataset:\",dataset)\n",
    "    print(\"# Features before:\",len(X_train_dict[dataset].columns.to_list()))\n",
    "    X_train_dict[dataset] = X_train_dict[dataset][feats_to_keep_list]\n",
    "    X_test_dict[dataset] = X_test_dict[dataset][feats_to_keep_list]\n",
    "    X_val_dict[dataset] = X_val_dict[dataset][feats_to_keep_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*****Change between Labels & Close_Up_Down columns for y_combined to make it either a Multiclass (5) or (3)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **cross_val_score - accuracy_score**                                                      \n",
    "# scoring https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\n",
    "\n",
    "def add_metrics(model,dataset,set='combined', sampled_weights=False):\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    metrics_list = ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted','neg_log_loss']\n",
    "\n",
    "    # Using BlockedTimeSeriesSplit cross val to calculate metrics\n",
    "    if set == 'train':\n",
    "        X = X_train_dict[dataset].sort_index()\n",
    "        y = y_train.sort_index() \n",
    "    elif set == 'test':\n",
    "        X = X_test_dict[dataset].sort_index()\n",
    "        y = y_test.sort_index() \n",
    "    elif set == 'combined':\n",
    "        X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "        y = pd.concat([y_train,y_test]).sort_index()    \n",
    "\n",
    "    for metric in metrics_list:\n",
    "\n",
    "        if sampled_weights:\n",
    "        # cross_val_score with SAMPLE_WEIGHTS\n",
    "            score = cross_val_score(model, X, y.Labels, cv=btscv, scoring = str(metric),fit_params={'sample_weight':np.abs(y.sample_weights.values)}) #,error_score=\"raise\"\n",
    "        else:\n",
    "            score = cross_val_score(model, X, y.Labels, cv=btscv, scoring = str(metric)) #,error_score=\"raise\"\n",
    "            \n",
    "        features_df.loc[(model_name, dataset),metric]= round(np.mean(score),2)\n",
    "\n",
    "    # Calculating Class Wise Metrics\n",
    "    original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=sampled_weights)\n",
    "    cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "    all_class_metric = metrics_from_cm(cm)\n",
    "\n",
    "    # Calculating Kappa Score \n",
    "\n",
    "    if sampled_weights:\n",
    "    # Kappa with SAMPLE_WEIGHTS\n",
    "        sample_weights = y.sample_weights.iloc[get_cv_indices(BlockingTimeSeriesSplit, X, y, n_splits= 5)['test']].values.tolist()\n",
    "        kappa_score = cohen_kappa_score(original, predicted, sample_weight=sample_weights)\n",
    "    else:\n",
    "        kappa_score = cohen_kappa_score(original, predicted)\n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Kappa']= kappa_score\n",
    "    \n",
    "    # Insert the dataframe in a cell in features_df\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'] = np.array([])\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'].astype(object)\n",
    "    features_df.loc[(model_name, dataset),'ClassDf'] =  [all_class_metric]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Model Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTE THE MODEL PIPELINES ARE BEING CHECKED/FITTED TO TRAINING DATA WHILE THE METRICS ARE calculated ON Set option in func argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the following steps:\n",
    "# 1. Fill the dataset with passed X Variables\n",
    "# 2. Fit Pipeline function\n",
    "# 3. Remove features/Transform train, test, val\n",
    "# 4. Add features to features_df\n",
    "# 5. Print_pipe_removed\n",
    "# 6. Get Shapes\n",
    "# 7. Add metrics to features_df using Blocked Time Series Cross Validation with TEST set\n",
    "\n",
    "#  = DropConstantFeatures(tol=1, variables=None, missing_values='raise')\n",
    "def apply_pipe_transform(dataset,original_dataset, pipe, model, set='combined'):\n",
    "    fill_with_dataset(dataset,original_dataset)\n",
    "    # named_step_sample_weight=np.abs(y_train.Adj_Close_ret.values)\n",
    "    pipe = pipe.fit(X_train_dict[dataset])\n",
    "    remove_features(dataset,pipe)\n",
    "    add_to_features_df(model,dataset)\n",
    "    print_pipe_removed(pipe)\n",
    "    get_shapes(dataset)\n",
    "    add_metrics(model, dataset, set='combined')\n",
    "\n",
    "\n",
    "def insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined', sampled_weights=False):\n",
    "    fill_with_dataset(dataset,original_dataset)\n",
    "    keep_features(dataset,feats_to_keep_list)\n",
    "    model.fit(X_train_dict[dataset][feats_to_keep_list], y_train.Labels)\n",
    "    add_to_features_df(model,dataset)\n",
    "    get_shapes(dataset)\n",
    "    add_metrics(model, dataset, set='combined', sampled_weights=sampled_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Models for both Classifiers & Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using xgb_clf for now because it is too slow\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "\n",
    "\n",
    "models = [rf_clf,xgb_clf]\n",
    "# models = [rf_clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe to Store Model Features & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [type(m).__name__ for m in models]\n",
    "dataset = 'Original'\n",
    "multilevel_index = pd.MultiIndex.from_product([model_names,[dataset]],names=['Model', 'Dataset'])\n",
    "cols_names = ['Model_Details','Num_Features','Features_List','Removed_Features'] + ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted','neg_log_loss','Kappa','ClassDf']\n",
    "features_df = pd.DataFrame(columns=cols_names, index=multilevel_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset in 3 Dictionaries of Training, Testing & Validation & Initiating features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: If metric calculations in add_metric function is calculated on Data which has even one class missing from y_predictions, it will throw an error (when error='raise' used), or it will be NaN for (roc_auc_ovr_weighted & roc_auc_ovo_weighted) if this option is not used in cross_val_score..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes for dataset: Original\n",
      "X_train Shape (1385, 762)\n",
      "X_test Shape (1386, 762)\n",
      "X_val Shape (132, 762)\n"
     ]
    }
   ],
   "source": [
    "X_train_dict = {}\n",
    "X_test_dict = {}\n",
    "X_val_dict = {}\n",
    "\n",
    "# To make sure test is the most recent\n",
    "Variables.sort_index(ascending = True, inplace = True) \n",
    "Response.sort_index(ascending = True, inplace = True)\n",
    "\n",
    "Validation_date_start = '2022-01-01'\n",
    "X_val_dict['Original'] = Variables[Variables.index >= Validation_date_start]\n",
    "y_val = Response[Response.index >= Validation_date_start]\n",
    "\n",
    "X_train_dict['Original'], X_test_dict['Original'], y_train, y_test = train_test_split(Variables[Variables.index < Validation_date_start],\\\n",
    "     Response[Response.index < Validation_date_start], test_size=0.50, shuffle = False)\n",
    "\n",
    "for m in models:\n",
    "    add_to_features_df(m,dataset='Original')\n",
    "    add_metrics(m,dataset='Original',set='combined')  \n",
    "\n",
    "\n",
    "# Shapes\n",
    "get_shapes(dataset = 'Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Functions to plot Blocked TimeSeries Split****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_splits = 5\n",
    "cv = BlockingTimeSeriesSplit\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "print(\"The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\")\n",
    "plot_timeseries_split(np.array(X_train_dict['Original']),np.array(y_train.Labels),n_splits,cmap_cv,cmap_data,cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all constant Variables\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why the following features have only one value\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Constant\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Constant', DropConstantFeatures())])\n",
      "Constant : 102\n",
      "Total removed: 102\n",
      "\n",
      "Shapes for dataset: Constant\n",
      "X_train Shape (1385, 660)\n",
      "X_test Shape (1386, 660)\n",
      "X_val Shape (132, 660)\n",
      "\n",
      "Removing Features for dataset: Constant\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Constant', DropConstantFeatures())])\n",
      "Constant : 102\n",
      "Total removed: 102\n",
      "\n",
      "Shapes for dataset: Constant\n",
      "X_train Shape (1385, 660)\n",
      "X_test Shape (1386, 660)\n",
      "X_val Shape (132, 660)\n"
     ]
    }
   ],
   "source": [
    "# Issue with using XGBOOST - takes long time and gives warnigs Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = 'Constant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=1, variables=None, missing_values='raise'))])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0], set='combined')\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[1], set='combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1 Model with 1 Feature only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Spread_1-2\n",
      "# Features before: 762\n",
      "\n",
      "Shapes for dataset: Spread_1-2\n",
      "X_train Shape (1385, 1)\n",
      "X_test Shape (1386, 1)\n",
      "X_val Shape (132, 1)\n"
     ]
    }
   ],
   "source": [
    "original_dataset = 'Original'\n",
    "dataset = 'Spread_1-2'\n",
    "model = models[0]\n",
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond']\n",
    "insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "all_class_metric = metrics_from_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    -1   0   1\n",
       "-1  74  39  53\n",
       " 0  81  65  58\n",
       " 1  91  40  54"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>30%</td>\n",
       "      <td>45%</td>\n",
       "      <td>36%</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "      <td>52%</td>\n",
       "      <td>74.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45%</td>\n",
       "      <td>32%</td>\n",
       "      <td>37%</td>\n",
       "      <td>77%</td>\n",
       "      <td>23%</td>\n",
       "      <td>61%</td>\n",
       "      <td>65.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32%</td>\n",
       "      <td>28%</td>\n",
       "      <td>30%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>56%</td>\n",
       "      <td>52.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>36%</td>\n",
       "      <td>35%</td>\n",
       "      <td>34%</td>\n",
       "      <td>68%</td>\n",
       "      <td>32%</td>\n",
       "      <td>56%</td>\n",
       "      <td>191.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wt_Avg</th>\n",
       "      <td>36%</td>\n",
       "      <td>34%</td>\n",
       "      <td>34%</td>\n",
       "      <td>68%</td>\n",
       "      <td>32%</td>\n",
       "      <td>57%</td>\n",
       "      <td>191.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision recall fscore specificity  fpr accuracy     tp     tn     fp  \\\n",
       "-1           30%    45%    36%         55%  45%      52%   74.0  215.0  174.0   \n",
       "0            45%    32%    37%         77%  23%      61%   65.0  272.0   79.0   \n",
       "1            32%    28%    30%         70%  30%      56%   52.0  259.0  111.0   \n",
       "macro        36%    35%    34%         68%  32%      56%  191.0  746.0  364.0   \n",
       "Wt_Avg       36%    34%    34%         68%  32%      57%  191.0  746.0  364.0   \n",
       "\n",
       "           fn  support  \n",
       "-1       92.0    166.0  \n",
       "0       139.0    204.0  \n",
       "1       133.0    185.0  \n",
       "macro   364.0    555.0  \n",
       "Wt_Avg  364.0    555.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_Details           (DecisionTreeClassifier(max_depth=3, max_featu...\n",
       "Num_Features                                                            1\n",
       "Features_List                         [LumberContractSpreads FirstSecond]\n",
       "Removed_Features        [CFTCdisaggregated ChangeinMMoneyLongAll, CFTC...\n",
       "balanced_accuracy                                                    0.34\n",
       "precision_weighted                                                   0.36\n",
       "recall_weighted                                                      0.35\n",
       "f1_weighted                                                          0.28\n",
       "roc_auc_ovr_weighted                                                 0.51\n",
       "roc_auc_ovo_weighted                                                 0.52\n",
       "neg_log_loss                                                        -1.13\n",
       "Kappa                                                            0.025593\n",
       "ClassDf                   [[precision, recall, fscore, specificity, fpr]]\n",
       "Name: (RandomForestClassifier, Spread_1-2), dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: QuasiConstant\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('QuasiConstant', DropConstantFeatures(tol=0.95))])\n",
      "QuasiConstant : 110\n",
      "Total removed: 110\n",
      "\n",
      "Shapes for dataset: QuasiConstant\n",
      "X_train Shape (1385, 652)\n",
      "X_test Shape (1386, 652)\n",
      "X_val Shape (132, 652)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'QuasiConstant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=0.95, variables=None, missing_values='raise'))])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0], set='combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Duplicated\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Duplicated', DropDuplicateFeatures(missing_values='raise'))])\n",
      "Duplicated : 88\n",
      "Total removed: 88\n",
      "\n",
      "Shapes for dataset: Duplicated\n",
      "X_train Shape (1385, 674)\n",
      "X_test Shape (1386, 674)\n",
      "X_val Shape (132, 674)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Duplicated'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0], set='combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated & Quasi Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Dupl&QConstant\n",
      "# Features before: 652\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Dupl&QConstant',\n",
      "                 DropDuplicateFeatures(missing_values='raise'))])\n",
      "Dupl&QConstant : 48\n",
      "Total removed: 48\n",
      "\n",
      "Shapes for dataset: Dupl&QConstant\n",
      "X_train Shape (1385, 604)\n",
      "X_test Shape (1386, 604)\n",
      "X_val Shape (132, 604)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Dupl&QConstant'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_pipe_transform(dataset,'QuasiConstant', pipe, models[0], set='combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Correlated\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Correlated',\n",
      "                 SmartCorrelatedSelection(cv=<support._model_build_func.BlockingTimeSeriesSplit object at 0x000001C7368EA4A0>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_estimators=200,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "Correlated : 248\n",
      "Total removed: 248\n",
      "\n",
      "Shapes for dataset: Correlated\n",
      "X_train Shape (1385, 514)\n",
      "X_test Shape (1386, 514)\n",
      "X_val Shape (132, 514)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Correlated'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0], set='combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated, Quasi Constant & Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Clean\n",
      "# Features before: 604\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Clean',\n",
      "                 SmartCorrelatedSelection(cv=<support._model_build_func.BlockingTimeSeriesSplit object at 0x000001C7368EA4A0>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_estimators=200,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "Clean : 200\n",
      "Total removed: 200\n",
      "\n",
      "Shapes for dataset: Clean\n",
      "X_train Shape (1385, 404)\n",
      "X_test Shape (1386, 404)\n",
      "X_val Shape (132, 404)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_pipe_transform(dataset,'Dupl&QConstant', pipe, models[0], set='combined')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean1 - Drop constant, quasi Constant, duplicated and correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Clean1\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('constant', DropConstantFeatures()),\n",
      "                ('quasiConstant', DropConstantFeatures(tol=0.95)),\n",
      "                ('duplicated', DropDuplicateFeatures(missing_values='raise')),\n",
      "                ('correlation',\n",
      "                 SmartCorrelatedSelection(cv=<support._model_build_func.BlockingTimeSeriesSplit object at 0x000001C7368EA4A0>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_estimators=200,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "constant : 102\n",
      "quasiConstant : 8\n",
      "duplicated : 48\n",
      "correlation : 200\n",
      "Total removed: 358\n",
      "\n",
      "Shapes for dataset: Clean1\n",
      "X_train Shape (1385, 404)\n",
      "X_test Shape (1386, 404)\n",
      "X_val Shape (132, 404)\n",
      "\n",
      "Removing Features for dataset: Clean1\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('constant', DropConstantFeatures()),\n",
      "                ('quasiConstant', DropConstantFeatures(tol=0.95)),\n",
      "                ('duplicated', DropDuplicateFeatures(missing_values='raise')),\n",
      "                ('correlation',\n",
      "                 SmartCorrelatedSelection(cv=<support._model_build_func.BlockingTimeSeriesSplit object at 0x000001C7368EA4A0>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_estimators=200,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "constant : 102\n",
      "quasiConstant : 8\n",
      "duplicated : 48\n",
      "correlation : 200\n",
      "Total removed: 358\n",
      "\n",
      "Shapes for dataset: Clean1\n",
      "X_train Shape (1385, 404)\n",
      "X_test Shape (1386, 404)\n",
      "X_val Shape (132, 404)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean1'\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.95, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0], set='combined')\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[1], set='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Num_Features</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <th>roc_auc_ovo_weighted</th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.135664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.140544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Constant</th>\n",
       "      <td>660</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.135743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Constant</th>\n",
       "      <td>660</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>0.137313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>Spread_1-2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>0.025593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuasiConstant</th>\n",
       "      <td>652</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.124399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duplicated</th>\n",
       "      <td>674</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.129195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dupl&amp;QConstant</th>\n",
       "      <td>604</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.132034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated</th>\n",
       "      <td>514</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.127114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean</th>\n",
       "      <td>404</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.150475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.125264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Clean1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>0.136534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Num_Features balanced_accuracy  \\\n",
       "Model                  Dataset                                         \n",
       "RandomForestClassifier Original                762              0.41   \n",
       "XGBClassifier          Original                762              0.42   \n",
       "RandomForestClassifier Constant                660              0.41   \n",
       "XGBClassifier          Constant                660              0.42   \n",
       "RandomForestClassifier Spread_1-2                1              0.34   \n",
       "                       QuasiConstant           652              0.42   \n",
       "                       Duplicated              674              0.43   \n",
       "                       Dupl&QConstant          604              0.43   \n",
       "                       Correlated              514              0.42   \n",
       "                       Clean                   404              0.41   \n",
       "                       Clean1                  404              0.42   \n",
       "XGBClassifier          Clean1                  404              0.43   \n",
       "\n",
       "                                      precision_weighted recall_weighted  \\\n",
       "Model                  Dataset                                             \n",
       "RandomForestClassifier Original                     0.35            0.42   \n",
       "XGBClassifier          Original                     0.42            0.42   \n",
       "RandomForestClassifier Constant                     0.39            0.42   \n",
       "XGBClassifier          Constant                     0.43            0.42   \n",
       "RandomForestClassifier Spread_1-2                   0.36            0.35   \n",
       "                       QuasiConstant                0.37            0.42   \n",
       "                       Duplicated                   0.36            0.41   \n",
       "                       Dupl&QConstant               0.34            0.41   \n",
       "                       Correlated                   0.35            0.43   \n",
       "                       Clean                        0.36            0.43   \n",
       "                       Clean1                       0.34            0.43   \n",
       "XGBClassifier          Clean1                       0.44            0.42   \n",
       "\n",
       "                                      f1_weighted roc_auc_ovr_weighted  \\\n",
       "Model                  Dataset                                           \n",
       "RandomForestClassifier Original              0.35                 0.62   \n",
       "XGBClassifier          Original              0.38                  0.6   \n",
       "RandomForestClassifier Constant              0.36                 0.62   \n",
       "XGBClassifier          Constant              0.38                  0.6   \n",
       "RandomForestClassifier Spread_1-2            0.28                 0.51   \n",
       "                       QuasiConstant         0.36                 0.62   \n",
       "                       Duplicated            0.36                 0.62   \n",
       "                       Dupl&QConstant        0.36                 0.61   \n",
       "                       Correlated            0.36                 0.62   \n",
       "                       Clean                 0.36                 0.63   \n",
       "                       Clean1                0.36                 0.63   \n",
       "XGBClassifier          Clean1                0.38                  0.6   \n",
       "\n",
       "                                      roc_auc_ovo_weighted neg_log_loss  \\\n",
       "Model                  Dataset                                            \n",
       "RandomForestClassifier Original                       0.63        -1.06   \n",
       "XGBClassifier          Original                       0.61        -1.64   \n",
       "RandomForestClassifier Constant                       0.62        -1.07   \n",
       "XGBClassifier          Constant                        0.6        -1.66   \n",
       "RandomForestClassifier Spread_1-2                     0.52        -1.13   \n",
       "                       QuasiConstant                  0.62        -1.07   \n",
       "                       Duplicated                     0.63        -1.07   \n",
       "                       Dupl&QConstant                 0.61        -1.07   \n",
       "                       Correlated                     0.62        -1.07   \n",
       "                       Clean                          0.63        -1.06   \n",
       "                       Clean1                         0.62        -1.06   \n",
       "XGBClassifier          Clean1                         0.61        -1.72   \n",
       "\n",
       "                                          Kappa  \n",
       "Model                  Dataset                   \n",
       "RandomForestClassifier Original        0.135664  \n",
       "XGBClassifier          Original        0.140544  \n",
       "RandomForestClassifier Constant        0.135743  \n",
       "XGBClassifier          Constant        0.137313  \n",
       "RandomForestClassifier Spread_1-2      0.025593  \n",
       "                       QuasiConstant   0.124399  \n",
       "                       Duplicated      0.129195  \n",
       "                       Dupl&QConstant  0.132034  \n",
       "                       Correlated      0.127114  \n",
       "                       Clean           0.150475  \n",
       "                       Clean1          0.125264  \n",
       "XGBClassifier          Clean1          0.136534  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>36%</td>\n",
       "      <td>43%</td>\n",
       "      <td>39%</td>\n",
       "      <td>67%</td>\n",
       "      <td>33%</td>\n",
       "      <td>60%</td>\n",
       "      <td>72.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45%</td>\n",
       "      <td>34%</td>\n",
       "      <td>39%</td>\n",
       "      <td>75%</td>\n",
       "      <td>25%</td>\n",
       "      <td>60%</td>\n",
       "      <td>70.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44%</td>\n",
       "      <td>48%</td>\n",
       "      <td>46%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>63%</td>\n",
       "      <td>88.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>42%</td>\n",
       "      <td>42%</td>\n",
       "      <td>41%</td>\n",
       "      <td>71%</td>\n",
       "      <td>29%</td>\n",
       "      <td>61%</td>\n",
       "      <td>230.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wt_Avg</th>\n",
       "      <td>42%</td>\n",
       "      <td>41%</td>\n",
       "      <td>41%</td>\n",
       "      <td>71%</td>\n",
       "      <td>29%</td>\n",
       "      <td>61%</td>\n",
       "      <td>230.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision recall fscore specificity  fpr accuracy     tp     tn     fp  \\\n",
       "-1           36%    43%    39%         67%  33%      60%   72.0  260.0  129.0   \n",
       "0            45%    34%    39%         75%  25%      60%   70.0  265.0   86.0   \n",
       "1            44%    48%    46%         70%  30%      63%   88.0  260.0  110.0   \n",
       "macro        42%    42%    41%         71%  29%      61%  230.0  785.0  325.0   \n",
       "Wt_Avg       42%    41%    41%         71%  29%      61%  230.0  785.0  325.0   \n",
       "\n",
       "           fn  support  \n",
       "-1       94.0    166.0  \n",
       "0       134.0    204.0  \n",
       "1        97.0    185.0  \n",
       "macro   325.0    555.0  \n",
       "Wt_Avg  325.0    555.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1).loc[('RandomForestClassifier','Clean1')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('f1_weighted',\n",
       " 'neg_log_loss',\n",
       " 'cohen_kappa_score',\n",
       " 'precision_weighted',\n",
       " 'roc_auc_ovr_weighted')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'f1_weighted', 'neg_log_loss', 'cohen_kappa_score', 'precision_weighted','roc_auc_ovr_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do\n",
    "\n",
    "**Engineered**\n",
    "1. LB_High - LB_Low\n",
    "2. Get Other Basis\n",
    "3. Use some techincal Indicators\n",
    "\n",
    "**Raw**\n",
    "1. LB_Volume\t\n",
    "2. LB_openInterest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(Variables.columns.tolist()).to_csv('Variable_columns_names.csv',index=False)\n",
    "\n",
    "manual_list = pd.read_excel('C:/source/2x4-data/app/feature_selection/ManualSelectList.xlsx', index_col=0)\n",
    "manual_list = manual_list[manual_list.index == 1]\n",
    "manual_list = manual_list.values.tolist()\n",
    "manual_list = [x for xs in manual_list for x in xs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_with_manual_list(new_dataset,manual_list):\n",
    "    X_train_dict[new_dataset] = X_train_dict['Original'][manual_list]\n",
    "    X_test_dict[new_dataset] = X_test_dict['Original'][manual_list]\n",
    "    X_val_dict[new_dataset] = X_val_dict['Original'][manual_list]\n",
    "\n",
    "\n",
    "def apply_pipe_transform_2(dataset,original_dataset, pipe, manual_list, model, sampled_weights, set='combined'):\n",
    "    fill_with_manual_list(dataset, manual_list)\n",
    "    pipe = pipe.fit(X_train_dict[dataset])\n",
    "    remove_features(dataset,pipe)\n",
    "    print_pipe_removed(pipe)\n",
    "    get_shapes(dataset)\n",
    "    add_metrics(model, dataset, set='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: ManualSelection\n",
      "# Features before: 148\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('constant', DropConstantFeatures()),\n",
      "                ('quasiConstant', DropConstantFeatures(tol=0.9)),\n",
      "                ('duplicated', DropDuplicateFeatures(missing_values='raise')),\n",
      "                ('correlation',\n",
      "                 SmartCorrelatedSelection(cv=<support._model_build_func.BlockingTimeSeriesSplit object at 0x000001C7368EA4A0>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_estimators=200,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          scoring='precision_weighted',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "constant : 18\n",
      "quasiConstant : 2\n",
      "duplicated : 1\n",
      "correlation : 21\n",
      "Total removed: 42\n",
      "\n",
      "Shapes for dataset: ManualSelection\n",
      "X_train Shape (1385, 106)\n",
      "X_test Shape (1386, 106)\n",
      "X_val Shape (132, 106)\n",
      "\n",
      "Removing Features for dataset: ManualSelection\n",
      "# Features before: 148\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('constant', DropConstantFeatures()),\n",
      "                ('quasiConstant', DropConstantFeatures(tol=0.9)),\n",
      "                ('duplicated', DropDuplicateFeatures(missing_values='raise')),\n",
      "                ('correlation',\n",
      "                 SmartCorrelatedSelection(cv=<support._model_build_func.BlockingTimeSeriesSplit object at 0x000001C7368EA4A0>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_estimators=200,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          scoring='precision_weighted',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "constant : 18\n",
      "quasiConstant : 2\n",
      "duplicated : 1\n",
      "correlation : 21\n",
      "Total removed: 42\n",
      "\n",
      "Shapes for dataset: ManualSelection\n",
      "X_train Shape (1385, 106)\n",
      "X_test Shape (1386, 106)\n",
      "X_val Shape (132, 106)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset='ManualSelection'\n",
    "original_dataset='Original'\n",
    "feats_to_keep_list=manual_list\n",
    "model=models[0]\n",
    "set='combined'\n",
    "sampled_weights=False\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.90, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=model,scoring=\"precision_weighted\",cv=btscv,)),])\n",
    "apply_pipe_transform_2(dataset,'Original', pipe, manual_list, models[0], set='combined', sampled_weights=True)\n",
    "apply_pipe_transform_2(dataset,'Original', pipe, manual_list, models[1], set='combined', sampled_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict['Original'],X_test_dict['Original']],axis=0)\n",
    "y = pd.concat([y_train,y_test],axis=0)\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com1_original, com1_predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=False)\n",
    "com2_original, com2_predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv, sampled_weights=True)\n",
    "com1_original == com2_original, com1_predicted == com2_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>203</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted  original\n",
       "-1        203       166\n",
       " 0        136       204\n",
       " 1        216       185"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(data = [pd.Series(com1_predicted).value_counts().sort_index(), pd.Series(com1_original).value_counts().sort_index()], index = ['predicted','original']).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>215</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted  original\n",
       "-1        215       166\n",
       " 0        127       204\n",
       " 1        213       185"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = [pd.Series(com2_predicted).value_counts().sort_index(), pd.Series(com2_original).value_counts().sort_index()], index = ['predicted','original']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight='balanced'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94637978, 1.17068019, 0.91815772])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",classes= lab, y = y.Labels)\n",
    "computed_sample_weights = compute_sample_weight('balanced', y.Labels)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91815772, 0.94637978, 1.17068019, ..., 0.94637978, 0.94637978,\n",
       "       1.17068019])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>computed_sample_weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.946380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.170680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.918158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        computed_sample_weights\n",
       "Labels                         \n",
       "-1.0                   0.946380\n",
       " 0.0                   1.170680\n",
       " 1.0                   0.918158"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df = pd.DataFrame(data = [computed_sample_weights, y.Labels], index = ['computed_sample_weights','Labels']).T\n",
    "group_df\n",
    "group_df.groupby('Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>29.987036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.428891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.112441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_weights\n",
       "Labels                \n",
       "-1           29.987036\n",
       " 0           21.428891\n",
       " 1           30.112441"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Response[['Labels','sample_weights']].groupby('Labels').sum()\n",
    "# Response[['Labels','sample_weights']].groupby('Labels').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.054557283268807044\n",
      "Min: 0.005034412378459585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00403, 0.0105]    19.91\n",
       "(0.0105, 0.016]      16.05\n",
       "(0.016, 0.0215]      12.99\n",
       "(0.0215, 0.027]       8.27\n",
       "(0.027, 0.0325]       6.68\n",
       "(0.0325, 0.038]       5.06\n",
       "(0.038, 0.0436]       3.03\n",
       "(0.0436, 0.0491]      2.14\n",
       "(0.0491, 0.0546]     25.87\n",
       "Name: sample_weights, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "create_bins_data(Response,'sample_weights',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Num_Features</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <th>roc_auc_ovo_weighted</th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.135664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.140544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Constant</th>\n",
       "      <td>660</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.135743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Constant</th>\n",
       "      <td>660</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>0.137313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>Spread_1-2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>0.025593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuasiConstant</th>\n",
       "      <td>652</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.124399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duplicated</th>\n",
       "      <td>674</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.129195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dupl&amp;QConstant</th>\n",
       "      <td>604</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.132034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated</th>\n",
       "      <td>514</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>0.127114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean</th>\n",
       "      <td>404</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.150475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.125264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Clean1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>0.136534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>ManualSelection</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.110564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>ManualSelection</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>0.128156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Num_Features balanced_accuracy  \\\n",
       "Model                  Dataset                                          \n",
       "RandomForestClassifier Original                 762              0.41   \n",
       "XGBClassifier          Original                 762              0.42   \n",
       "RandomForestClassifier Constant                 660              0.41   \n",
       "XGBClassifier          Constant                 660              0.42   \n",
       "RandomForestClassifier Spread_1-2                 1              0.34   \n",
       "                       QuasiConstant            652              0.42   \n",
       "                       Duplicated               674              0.43   \n",
       "                       Dupl&QConstant           604              0.43   \n",
       "                       Correlated               514              0.42   \n",
       "                       Clean                    404              0.41   \n",
       "                       Clean1                   404              0.42   \n",
       "XGBClassifier          Clean1                   404              0.43   \n",
       "RandomForestClassifier ManualSelection          NaN              0.41   \n",
       "XGBClassifier          ManualSelection          NaN              0.42   \n",
       "\n",
       "                                       precision_weighted recall_weighted  \\\n",
       "Model                  Dataset                                              \n",
       "RandomForestClassifier Original                      0.35            0.42   \n",
       "XGBClassifier          Original                      0.42            0.42   \n",
       "RandomForestClassifier Constant                      0.39            0.42   \n",
       "XGBClassifier          Constant                      0.43            0.42   \n",
       "RandomForestClassifier Spread_1-2                    0.36            0.35   \n",
       "                       QuasiConstant                 0.37            0.42   \n",
       "                       Duplicated                    0.36            0.41   \n",
       "                       Dupl&QConstant                0.34            0.41   \n",
       "                       Correlated                    0.35            0.43   \n",
       "                       Clean                         0.36            0.43   \n",
       "                       Clean1                        0.34            0.43   \n",
       "XGBClassifier          Clean1                        0.44            0.42   \n",
       "RandomForestClassifier ManualSelection               0.39            0.41   \n",
       "XGBClassifier          ManualSelection               0.44            0.41   \n",
       "\n",
       "                                       f1_weighted roc_auc_ovr_weighted  \\\n",
       "Model                  Dataset                                            \n",
       "RandomForestClassifier Original               0.35                 0.62   \n",
       "XGBClassifier          Original               0.38                  0.6   \n",
       "RandomForestClassifier Constant               0.36                 0.62   \n",
       "XGBClassifier          Constant               0.38                  0.6   \n",
       "RandomForestClassifier Spread_1-2             0.28                 0.51   \n",
       "                       QuasiConstant          0.36                 0.62   \n",
       "                       Duplicated             0.36                 0.62   \n",
       "                       Dupl&QConstant         0.36                 0.61   \n",
       "                       Correlated             0.36                 0.62   \n",
       "                       Clean                  0.36                 0.63   \n",
       "                       Clean1                 0.36                 0.63   \n",
       "XGBClassifier          Clean1                 0.38                  0.6   \n",
       "RandomForestClassifier ManualSelection        0.31                 0.63   \n",
       "XGBClassifier          ManualSelection        0.35                 0.61   \n",
       "\n",
       "                                       roc_auc_ovo_weighted neg_log_loss  \\\n",
       "Model                  Dataset                                             \n",
       "RandomForestClassifier Original                        0.63        -1.06   \n",
       "XGBClassifier          Original                        0.61        -1.64   \n",
       "RandomForestClassifier Constant                        0.62        -1.07   \n",
       "XGBClassifier          Constant                         0.6        -1.66   \n",
       "RandomForestClassifier Spread_1-2                      0.52        -1.13   \n",
       "                       QuasiConstant                   0.62        -1.07   \n",
       "                       Duplicated                      0.63        -1.07   \n",
       "                       Dupl&QConstant                  0.61        -1.07   \n",
       "                       Correlated                      0.62        -1.07   \n",
       "                       Clean                           0.63        -1.06   \n",
       "                       Clean1                          0.62        -1.06   \n",
       "XGBClassifier          Clean1                          0.61        -1.72   \n",
       "RandomForestClassifier ManualSelection                 0.61        -1.08   \n",
       "XGBClassifier          ManualSelection                 0.62        -1.63   \n",
       "\n",
       "                                           Kappa  \n",
       "Model                  Dataset                    \n",
       "RandomForestClassifier Original         0.135664  \n",
       "XGBClassifier          Original         0.140544  \n",
       "RandomForestClassifier Constant         0.135743  \n",
       "XGBClassifier          Constant         0.137313  \n",
       "RandomForestClassifier Spread_1-2       0.025593  \n",
       "                       QuasiConstant    0.124399  \n",
       "                       Duplicated       0.129195  \n",
       "                       Dupl&QConstant   0.132034  \n",
       "                       Correlated       0.127114  \n",
       "                       Clean            0.150475  \n",
       "                       Clean1           0.125264  \n",
       "XGBClassifier          Clean1           0.136534  \n",
       "RandomForestClassifier ManualSelection  0.110564  \n",
       "XGBClassifier          ManualSelection  0.128156  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>36%</td>\n",
       "      <td>40%</td>\n",
       "      <td>38%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>61%</td>\n",
       "      <td>66.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44%</td>\n",
       "      <td>40%</td>\n",
       "      <td>42%</td>\n",
       "      <td>71%</td>\n",
       "      <td>29%</td>\n",
       "      <td>59%</td>\n",
       "      <td>82.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41%</td>\n",
       "      <td>42%</td>\n",
       "      <td>42%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>61%</td>\n",
       "      <td>78.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>41%</td>\n",
       "      <td>41%</td>\n",
       "      <td>41%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>60%</td>\n",
       "      <td>226.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wt_Avg</th>\n",
       "      <td>41%</td>\n",
       "      <td>41%</td>\n",
       "      <td>41%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>60%</td>\n",
       "      <td>226.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision recall fscore specificity  fpr accuracy     tp     tn     fp  \\\n",
       "-1           36%    40%    38%         70%  30%      61%   66.0  273.0  116.0   \n",
       "0            44%    40%    42%         71%  29%      59%   82.0  248.0  103.0   \n",
       "1            41%    42%    42%         70%  30%      61%   78.0  260.0  110.0   \n",
       "macro        41%    41%    41%         70%  30%      60%  226.0  781.0  329.0   \n",
       "Wt_Avg       41%    41%    41%         70%  30%      60%  226.0  781.0  329.0   \n",
       "\n",
       "           fn  support  \n",
       "-1      100.0    166.0  \n",
       "0       122.0    204.0  \n",
       "1       107.0    185.0  \n",
       "macro   329.0    555.0  \n",
       "Wt_Avg  329.0    555.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.loc[('RandomForestClassifier','ManualSelection')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>36%</td>\n",
       "      <td>43%</td>\n",
       "      <td>39%</td>\n",
       "      <td>67%</td>\n",
       "      <td>33%</td>\n",
       "      <td>60%</td>\n",
       "      <td>72.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45%</td>\n",
       "      <td>34%</td>\n",
       "      <td>39%</td>\n",
       "      <td>75%</td>\n",
       "      <td>25%</td>\n",
       "      <td>60%</td>\n",
       "      <td>70.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44%</td>\n",
       "      <td>48%</td>\n",
       "      <td>46%</td>\n",
       "      <td>70%</td>\n",
       "      <td>30%</td>\n",
       "      <td>63%</td>\n",
       "      <td>88.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>42%</td>\n",
       "      <td>42%</td>\n",
       "      <td>41%</td>\n",
       "      <td>71%</td>\n",
       "      <td>29%</td>\n",
       "      <td>61%</td>\n",
       "      <td>230.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wt_Avg</th>\n",
       "      <td>42%</td>\n",
       "      <td>41%</td>\n",
       "      <td>41%</td>\n",
       "      <td>71%</td>\n",
       "      <td>29%</td>\n",
       "      <td>61%</td>\n",
       "      <td>230.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision recall fscore specificity  fpr accuracy     tp     tn     fp  \\\n",
       "-1           36%    43%    39%         67%  33%      60%   72.0  260.0  129.0   \n",
       "0            45%    34%    39%         75%  25%      60%   70.0  265.0   86.0   \n",
       "1            44%    48%    46%         70%  30%      63%   88.0  260.0  110.0   \n",
       "macro        42%    42%    41%         71%  29%      61%  230.0  785.0  325.0   \n",
       "Wt_Avg       42%    41%    41%         71%  29%      61%  230.0  785.0  325.0   \n",
       "\n",
       "           fn  support  \n",
       "-1       94.0    166.0  \n",
       "0       134.0    204.0  \n",
       "1        97.0    185.0  \n",
       "macro   325.0    555.0  \n",
       "Wt_Avg  325.0    555.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.loc[('RandomForestClassifier','Clean1')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond','lumbermovingaverages MA200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Spread_1-2_wts\n",
      "# Features before: 762\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\feature_selection\\feature_selection_Binary.ipynb Cell 110\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m models[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=3'>4</a>\u001b[0m feats_to_keep_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mLumberContractSpreads FirstSecond\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlumbermovingaverages MA200\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=4'>5</a>\u001b[0m insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, \u001b[39mset\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcombined\u001b[39;49m\u001b[39m'\u001b[39;49m, sampled_weights\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\feature_selection\\feature_selection_Binary.ipynb Cell 110\u001b[0m in \u001b[0;36minsert_model_stats\u001b[1;34m(dataset, original_dataset, feats_to_keep_list, model, set, sampled_weights)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=23'>24</a>\u001b[0m keep_features(dataset,feats_to_keep_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=24'>25</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_dict[dataset][feats_to_keep_list], y_train\u001b[39m.\u001b[39mLabels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=25'>26</a>\u001b[0m add_to_features_df(model,dataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=26'>27</a>\u001b[0m get_shapes(dataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=27'>28</a>\u001b[0m add_metrics(model, dataset, \u001b[39mset\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcombined\u001b[39m\u001b[39m'\u001b[39m, sampled_weights\u001b[39m=\u001b[39msampled_weights)\n",
      "\u001b[1;32mc:\\source\\2x4-data\\app\\feature_selection\\feature_selection_Binary.ipynb Cell 110\u001b[0m in \u001b[0;36madd_to_features_df\u001b[1;34m(model, dataset)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=2'>3</a>\u001b[0m features_df\u001b[39m.\u001b[39mloc[(model_name, dataset),\u001b[39m'\u001b[39m\u001b[39mNum_Features\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_train_dict[dataset]\u001b[39m.\u001b[39mcolumns) \u001b[39m# so can store list of features\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=3'>4</a>\u001b[0m features_df\u001b[39m.\u001b[39mloc[(model_name, dataset),\u001b[39m'\u001b[39m\u001b[39mFeatures_List\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X_train_dict[dataset]\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mto_list()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=5'>6</a>\u001b[0m original_list \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(features_df\u001b[39m.\u001b[39;49mloc[(model_name, \u001b[39m'\u001b[39;49m\u001b[39mOriginal\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39m'\u001b[39;49m\u001b[39mFeatures_List\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=6'>7</a>\u001b[0m dataset_list \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(features_df\u001b[39m.\u001b[39mloc[(model_name, dataset),\u001b[39m'\u001b[39m\u001b[39mFeatures_List\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/source/2x4-data/app/feature_selection/feature_selection_Binary.ipynb#ch0000250?line=7'>8</a>\u001b[0m removed_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39msorted\u001b[39m(original_list \u001b[39m-\u001b[39m dataset_list))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "original_dataset = 'Original'\n",
    "dataset = 'Spread_1-2_wts'\n",
    "model = models[0]\n",
    "feats_to_keep_list = ['LumberContractSpreads FirstSecond','lumbermovingaverages MA200']\n",
    "insert_model_stats(dataset,original_dataset, feats_to_keep_list, model, set='combined', sampled_weights= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "all_class_metric = metrics_from_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_wts')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]['ClassDf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_MA200')]['ClassDf'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[('RandomForestClassifier','Spread_1-2_MA200')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict[dataset].iloc[:, : 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'log_loss'\n",
    "\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "sfs = SFS(model, \n",
    "           k_features=6, # the more features we want, the longer it will take to run\n",
    "           forward=True, \n",
    "           floating=True, # see the docs for more details in this parameter\n",
    "           verbose=2, # this indicates how much to print out intermediate steps\n",
    "           scoring='f1_weighted', \n",
    "           cv=btscv,\n",
    "           n_jobs=-1,\n",
    "            \n",
    "         )\n",
    "\n",
    "weights = np.abs(y.Adj_Close_ret.values)\n",
    "\n",
    "sfs = sfs.fit(X, y.Labels,sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST \n",
    "dataset = 'Original'\n",
    "X = X_train_dict[dataset].sort_index()\n",
    "y = y_train.sort_index() \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1, max_depth=1, n_jobs=-1)\n",
    "  \n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1,\n",
    "           max_features=1,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=btscv)\n",
    "\n",
    "efs1 = efs1.fit(X, y.Labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Clean1'\n",
    "model = RandomForestClassifier(n_estimators=5, max_depth=2, n_jobs=-1)\n",
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index()    \n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1,\n",
    "           max_features=2,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=btscv)\n",
    "\n",
    "efs1 = efs1.fit(X, y.Labels)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(efs1.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "plot_confusion_matrix(model, X_test_dict['Clean1'], y_test.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since it takes > 1 min\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "xgb.fit(X_train_dict['Clean1'], y_train.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = xgb.predict(X_test_dict['Clean1'])\n",
    "df1 = pd.DataFrame(np.transpose(precision_recall_fscore_support(y_test.Labels, y_pred, average=None)),columns=['precision', 'recall', 'fscore', 'support'], index=lab)\n",
    "df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "y_pred = model.predict(X_test_dict['Clean1'])\n",
    "\n",
    "# y_pred = cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv=5)\n",
    "# y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since takes ~ 1.30 minute\n",
    "# model = models[1]\n",
    "# model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# y_pred = model.predict(X_test_dict['Clean1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = models[0]\n",
    "\n",
    "X = X_test_dict['Clean1'].sort_index()\n",
    "y = y_test.sort_index()  \n",
    "\n",
    "original, predicted = predictions_from_custom_cross_val(model,X, y, custom_cv = btscv)\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(original, predicted), index=lab, columns=lab)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "280/1386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original), y_test.Labels.shape, len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_metric = metrics_from_cm(cm)\n",
    "all_class_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(original, predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(original, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the dataframe in a cell in features_df\n",
    "# features_df['to_delete'] = None\n",
    "# features_df['to_delete'].astype(object)\n",
    "# features_df.loc[('RandomForestClassifier','Original'),'to_delete'] =  [all_class_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.loc[('RandomForestClassifier','Original'),'to_delete'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy - Negative Log Liklehood or Log Loss - Custom Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower The Better\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Original'], y_train.Labels)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "\n",
    "# This line required to convert for custom implementation from normal labels to indexed labels\n",
    "y_actuals = y_test.Labels.replace(to_replace=sorted(y_test.Labels.unique()), value=list(range(len(y_test.Labels.unique())))).values\n",
    "\n",
    "# Custom function to compute negative log loss\n",
    "nll = np.mean([-np.log(y_prob[i,j]) for i,j in zip(range(y_prob.shape[0]),y_actuals)])\n",
    "print(nll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features','ClassDf'],axis=1).loc[('RandomForestClassifier',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(y_actuals, y_prob))\n",
    "print(log_loss(y_test.Labels, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "model = models[0]\n",
    "dataset = 'Clean'\n",
    "X = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "y = pd.concat([y_train,y_test]).sort_index() \n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "scores = cross_val_score(model, X, y.Labels, cv=btscv, scoring=LogLoss)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogLoss._select_proba_binary(predicted,y_test.Labels.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probabilities_from_custom_cross_val(model,X, y, custom_cv = btscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# proba = cross_val_predict(model, X, y, cv=btscv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection Methods - Mostly just examine linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "# Plot\n",
    "# mi.plot.bar(figsize=(20, 6))\n",
    "# plt.ylabel('Mutual Information')\n",
    "\n",
    "# select features\n",
    "sel_ = SelectKBest(mutual_info_classif, k=15).fit(X_train, y_train)\n",
    "\n",
    "# display features\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-square Statistic - only suited for classification!                                         \n",
    "https://www.udemy.com/course/feature-selection-for-machine-learning/learn/lecture/22495182#questions\n",
    "https://github.com/solegalli/feature-selection-for-machine-learning/blob/main/05-Filter-Statistical-Tests/05.2-Fisher-score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the chi2 p_value between each of the variables and the target\n",
    "# chi2 returns 2 arrays, one contains the F-Scores which are then evaluated against the chi2 distribution to obtain the pvalue. The pvalues are in the second array\n",
    "\n",
    "# Input X must be non-negative\n",
    "X_train_non_negative = X_train[X_train.columns[((X_train < 0).sum(axis=0) == 0).values]]\n",
    "f_score = chi2(X_train_non_negative.fillna(0), y_train)\n",
    "pvalues = pd.Series(f_score[1])\n",
    "pvalues.index = X_train_non_negative.columns\n",
    "pvalues.sort_values(ascending=True, inplace = True)\n",
    "extremely_low_p_values = len(pvalues[pvalues < 1e-100])\n",
    "sel_ = SelectKBest(chi2, k= extremely_low_p_values).fit(X_train_non_negative, y_train)\n",
    "X_train_non_negative.columns[sel_.get_support()] # display features\n",
    "\n",
    "# X_train = sel_.transform(X_train)\n",
    "# X_test = sel_.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anova - tests 2 samples have same mean\n",
    "\n",
    "Assumptions:\n",
    "Sample are independant & normally distributed, homegeneity of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the univariate statistical measure between each of the variables and the target\n",
    "# similarly to chi2, the output is one array with f-scores and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=True, inplace = True) # The smaller the p_value the more predictive the feature is\n",
    "\n",
    "pvalue_above_5_percent = len(univariate[univariate < 0.05])\n",
    "sel_ = SelectKBest(f_classif, k=pvalue_above_5_percent).fit(X_train, y_train)\n",
    "features_to_keep = sel_.get_feature_names_out()\n",
    "features_to_keep\n",
    "\n",
    "# select features\n",
    "# X_train_anova = sel_.transform(X_train)\n",
    "# X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# # numpy array to dataframe\n",
    "# X_train_anova = pd.DataFrame(X_train_anova)\n",
    "# X_train_anova.columns = features_to_keep\n",
    "\n",
    "# X_test_anova = pd.DataFrame(X_test_anova)\n",
    "# X_test_anova.columns = features_to_keep\n",
    "\n",
    "# X_train_anova.shape, X_test_anova.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects features whose importance is greater than the threshold. - Thershold is the mean importance of all features\n",
    "sel_ = SelectFromModel(RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "TopNFeatures = pd.DataFrame(index = sel_.estimator_.feature_names_in_.tolist(),data = sel_.estimator_.feature_importances_, columns = ['Imp']).sort_values(by='Imp',ascending=False).head(20).index.tolist()\n",
    "pd.Series(sel_.estimator_.feature_importances_.ravel()).hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopNFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance Recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1:44 mins to run\n",
    "sel_ = RFE(RandomForestClassifier(n_estimators=100,  max_depth=3, n_jobs=-1), n_features_to_select=30).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "rf.fit(X_train[selected_features].fillna(0), y_train)\n",
    "y_pred = rf.predict(X_test[selected_features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[selected_features].fillna(0))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val.fillna(0), y_valid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set')\n",
    "pred = rf.predict_proba(X_train[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "print('Test set')\n",
    "pred = rf.predict_proba(X_test[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "print('Validation set')\n",
    "pred = rf.predict_proba(X_val[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_val, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Random Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1 min to run - You can use this procedure with any machine learning algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=2, n_jobs=-1)\n",
    "\n",
    "sel = SelectByShuffling(\n",
    "    variables=None, # automatically examine all numerical variables\n",
    "    estimator=rf, # the ML model\n",
    "    scoring='roc_auc', # the metric to evaluate\n",
    "    threshold=0,# the maximum performance drop allowed to select the feature\n",
    "    cv=btscv, # cross validation\n",
    ")\n",
    "\n",
    "sel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_ # performance of model trained with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(sel.performance_drifts_).sort_values(ascending=False).plot.bar(figsize=(16,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that will be removed\n",
    "\n",
    "print(len(sel.features_to_drop_))\n",
    "# remove features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "X_val = sel.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print( 'train auc score: ',roc_auc_score(y_train, (rf.predict_proba(X_train))[:,1]))\n",
    "print('test auc score: ', roc_auc_score(y_test, (rf.predict_proba(X_test))[:, 1]))\n",
    "print('Validation auc score: ', roc_auc_score(y_val, (rf.predict_proba(X_val))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "\n",
    "sel = RecursiveFeatureElimination(\n",
    "    variables=None, # automatically evaluate all numerical variables\n",
    "    estimator = model, # the ML model\n",
    "    scoring = 'roc_auc', # the metric we want to evalute\n",
    "    threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "    cv=btscv, # cross-validation\n",
    ")\n",
    "\n",
    "# this may take quite a while, because\n",
    "# we are building a lot of models with cross-validation\n",
    "# sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of model trained using all features\n",
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of all features based of initial model\n",
    "sel.feature_importances_.plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sel.performance_drifts_).plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Performance change when feature was added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features that will be removed\n",
    "\n",
    "len(sel.features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "y_pred = rf.predict(X_test[features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[features].fillna(0))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val .fillna(0), y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance in machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_basic_filter.shape, X_test_basic_filter.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter methods - basic\n",
    "run_randomForests(X_train_basic_filter,X_test_basic_filter,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression and compare performance in train and test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "run_logistic(scaler.transform(X_train),\n",
    "             scaler.transform(X_test),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>Pipelines:</b> Final Code will look like this but for now work through issues above \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.9, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.9,missing_values=\"raise\",selection_method=\"variance\",estimator=rf,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# remove features\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)\n",
    "X_val = pipe.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pipe.named_steps['constant'].features_to_drop_))\n",
    "pipe.named_steps['duplicated'].features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT USING - for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Brute Force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        \n",
    "        for j in range(i):\n",
    "            \n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "             \n",
    "                print(abs(corr_matrix.iloc[i, j]),\":\", corr_matrix.columns[i], \"<< - >>\", corr_matrix.columns[j])\n",
    "                colname = corr_matrix.columns[j]\n",
    "                \n",
    "                # and add it to our correlated set\n",
    "                col_corr.add(colname)\n",
    "                \n",
    "    return col_corr\n",
    "\n",
    "# corr_features = correlation(X_train, 0.9)\n",
    "# len(set(corr_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_features = correlation(X_train, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.9]\n",
    "corrmat = corrmat[corrmat < 1] # Not Interested in the correlation with 1 since will be with the same variable\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    \n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group in correlated_groups:\n",
    "#     print(group)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Group Index\n",
    "group_index = 1\n",
    "\n",
    "group = correlated_groups[group_index]\n",
    "var = group.feature1.unique()[0]\n",
    "\n",
    "# add all features of the group to a list\n",
    "features = list(group['feature2'].unique())+[var]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "\n",
    "print(var)\n",
    "importance.sort_values(by='importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in group['feature2']:\n",
    "#     plt.scatter(X_train[var], X_train[feature])\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.ylabel(var)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just an example to show one group of how smart correlation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "group = sel.correlated_feature_sets_[0]\n",
    "\n",
    "# build random forest with cross validation for each feature\n",
    "for f in group:\n",
    "    \n",
    "    model = cross_validate(\n",
    "        rf,\n",
    "        X_train[f].to_frame(),\n",
    "        y_train,\n",
    "        cv=btscv,\n",
    "        return_estimator=False,\n",
    "        scoring='accuracy',\n",
    "    )\n",
    "\n",
    "#  scoring='roc_auc' does not support categorical data.\n",
    "\n",
    "    print(f, model[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation metrics\n",
    "1. cross_val_score\n",
    "2. Area under the ROC Curve\n",
    "3. Confusion Matrix\n",
    "4. Confusion Report\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "cross_val_score(model, Variables, Response.Close_Up_Down, cv = 2, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Original'], y_train.Labels, cv = 5,scoring='roc_auc_ovo_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv = 5,scoring='roc_auc_ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "\n",
    "for p in [0.475,0.5,0.525]:\n",
    "    \n",
    "    y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "    print(\"tpr:\",tpr)\n",
    "    print(\"fpr:\",fpr)\n",
    "    print(\"threshold:\",threshold)\n",
    "    print(p,\": \",roc_auc_score(y_test.Close_Up_Down, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/45715018/scikit-learn-how-to-plot-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "plt.figure(figsize=(12,5))\n",
    "prediction = clf.predict_proba(X_test_dict['Clean'])[:,1]\n",
    "plt.hist(prediction[y_test.Close_Up_Down==-1], bins=100, label='Negatives')\n",
    "plt.hist(prediction[y_test.Close_Up_Down==1], bins=100, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Probability of being Positive Class', fontsize=10)\n",
    "plt.ylabel('Number of records in each bucket', fontsize=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=25, pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(y_test, model_set, model):\n",
    "    model.fit(X_train_dict[model_set], y_train.Close_Up_Down)\n",
    "    y_prob_positive = model.predict_proba(X_test_dict[model_set])[:,1]\n",
    "    print(f\"ROC_AUC_SCORE: {roc_auc_score(y_test.Close_Up_Down, y_prob_positive):.2f}%\")\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_prob_positive,)\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "\n",
    "plot_roc_auc_curve(y_test, 'Original', model)\n",
    "# plot_roc_auc_curve(y_test, 'Original', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred == [-1 if x[0] > 0.5 else 1 for x in y_prob]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took 5:20 mins\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "# cross_val_score(model, Variables, Response.Close_Up_Down, cv = 5).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "conf_mat = confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "sns.heatmap(pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted']), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues');\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_val_dict['Clean'], y_val.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Close_Up_Down, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report['-1.0']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, det_curve\n",
    "precision_score(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44a86d6b397dbc6b70abfa92d378adf5d728e5b92754036aace887a2a3f0f490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
