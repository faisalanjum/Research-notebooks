{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\\\VSYS-P-GW01.cloud.vsys.ca\\RDFolderRedirect$\\fanjum_cwp\\Desktop\\Python\\2x4\\venv\\Lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, r2_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression, chi2\n",
    "\n",
    "# to determine the p-values with anova\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "\n",
    "# to select features\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFromModel, RFE # Recursive Feature Elimination\n",
    "\n",
    "from feature_engine.selection import DropDuplicateFeatures, DropConstantFeatures, SmartCorrelatedSelection, SelectByShuffling, RecursiveFeatureElimination\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import pandas_market_calendars as mcal\n",
    "import warnings\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from Excel daily_dataframe_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1 min 40 secs to run\n",
    "Variables = pd.read_excel('daily_dataframe_main.xlsx', header=[0,1], sheet_name='Variables',index_col=0)\n",
    "Response = pd.read_excel('daily_dataframe_main.xlsx',sheet_name= 'Response' ,index_col=0)\n",
    "\n",
    "# Just using Unadjusted data for now\n",
    "# Response = Response[['LB_Close','Close_ret','Close_Up_Down']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Values\n",
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>Check:</b> Backfilling and then frontfilling Variables DataFrame, and filling zeros with Median? - Check if it makes sense\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables.fillna(method='bfill', inplace=True)\n",
    "# Variables.fillna(method='ffill', inplace=True)\n",
    "# Replacing 0 with Median Values\n",
    "# Variables.replace(to_replace=0, method='bfill', inplace=True) \n",
    "# Variables.replace(to_replace=0, method=Variables.median(), inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "Variables['day'] = Variables.index.day\n",
    "Variables['month'] = Variables.index.month\n",
    "Variables['year'] = Variables.index.year\n",
    "Variables['weekday'] = Variables.index.weekday\n",
    "Variables['week'] = Variables.index.week\n",
    "Variables['weekofyear'] = Variables.index.weekofyear\n",
    "Variables['quarter'] = Variables.index.quarter\n",
    "Variables['dayofyear'] = Variables.index.dayofyear\n",
    "Variables['dayofweek'] = Variables.index.dayofweek\n",
    "Variables['is_month_end'] = Variables.index.is_month_end\n",
    "Variables['is_month_start'] = Variables.index.is_month_start\n",
    "Variables['is_quarter_end'] = Variables.index.is_quarter_end\n",
    "Variables['is_quarter_start'] = Variables.index.is_quarter_start\n",
    "Variables['is_year_end'] = Variables.index.is_year_end\n",
    "Variables['is_year_start'] = Variables.index.is_year_start\n",
    "Variables['is_leap_year'] = Variables.index.is_leap_year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# TA_df = Variables[['LumberOHLCV LBHigh','LumberOHLCV LBLow','LumberOHLCV LBClose','LumberOHLCV LBVolume','LumberOHLCV LBopenInterest']]\n",
    "TA_df = Variables.loc[:,('Lumber_OHLCV',)][['LB_High','LB_Low','LB_Close','LB_Volume','LB_openInterest']]\n",
    "\n",
    "TA_df.columns = ['High','Low','Close','Volume','OpenInterest']\n",
    "TA_df['Open'] = TA_df['Close'].shift(-1)\n",
    "\n",
    "# TA_df['weekday'] = Variables.index.weekday\n",
    "# TA_df = TA_df[~TA_df.weekday.isin([5,6])]\n",
    "# TA_df = TA_df.drop(['weekday'],axis=1)\n",
    "\n",
    "TA_df = dropna(TA_df)\n",
    "TA_df.sort_index(ascending=True, inplace=True)\n",
    "TA_df = add_all_ta_features(TA_df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "TA_df.sort_index(ascending=False, inplace=True)\n",
    "TA_df.drop(['Open','High','Low','Close','Volume','OpenInterest'],axis=1,inplace=True)\n",
    "TA_df.columns = [str('TA_') + TA_df.columns]\n",
    "TA_df = TA_df.replace([np.inf, -np.inf], np.nan).fillna(TA_df.mean())\n",
    "Variables = pd.concat([Variables,TA_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing punctuation strings in column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [str(w).translate(str.maketrans('', '', string.punctuation)).lstrip().rstrip() for w in Variables.columns]\n",
    "Variables.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Last Available Date for each Variable in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LumberOHLCV LBHigh</th>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy ChangeinNoncommercialLongAll</th>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy NoncommercialPositionsShortOther</th>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy NoncommercialPositionsSpreadingOther</th>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy CommercialPositionsLongOther</th>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanproduction TotalNorthAmerica</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanshipment PrairiesAndEasternCanada</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LumberTracknorthamericanshipment TotalNorthAmerica</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy TotalReportablePositionsLongAll</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFTClegacy ConcentrationGrossLT4TDRShortOl</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       End_Dt\n",
       "LumberOHLCV LBHigh                                 2022-06-29\n",
       "CFTClegacy ChangeinNoncommercialLongAll            2022-06-29\n",
       "CFTClegacy NoncommercialPositionsShortOther        2022-06-29\n",
       "CFTClegacy NoncommercialPositionsSpreadingOther    2022-06-29\n",
       "CFTClegacy CommercialPositionsLongOther            2022-06-29\n",
       "...                                                       ...\n",
       "LumberTracknorthamericanproduction TotalNorthAm...        NaT\n",
       "LumberTracknorthamericanshipment PrairiesAndEas...        NaT\n",
       "LumberTracknorthamericanshipment TotalNorthAmerica        NaT\n",
       "CFTClegacy TotalReportablePositionsLongAll                NaT\n",
       "CFTClegacy ConcentrationGrossLT4TDRShortOl                NaT\n",
       "\n",
       "[769 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_valid_loc = pd.DataFrame(data=Variables.apply(lambda col: col.last_valid_index()), columns = ['End_Dt'])\n",
    "last_valid_loc.sort_values(by='End_Dt', ascending=False ,inplace=True)\n",
    "# last_valid_loc = last_valid_loc[last_valid_loc.End_Dt.notna()]\n",
    "last_valid_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> For now using custom based method - but change it eventually with Feature-engine etc. Check which method makes more sense\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 35 secounds to run\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "        Columns of dtype object are imputed with the most frequent value in column.\n",
    "        Columns of other types are imputed with median of column.\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "        \n",
    "Variables = DataFrameImputer().fit_transform(Variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Days and after 2011\n",
    "<div style=\"color: Red; font-size:22px;\" class=\"alert alert-block alert-warning\">  Restricting the dataset since 2011 only trading days for cme agriculture - ideally should be for CME Lumber!!\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Issues is we have some forward fills which doesn't represent data correctly\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2895, 2895)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables.sort_index(ascending = False, inplace = True)\n",
    "Response.sort_index(ascending = False, inplace = True)\n",
    "\n",
    "cme = mcal.get_calendar(\"CME_Agriculture\")\n",
    "cme_trading_days = cme.schedule(start_date=Variables.index[-1].date(), end_date=Variables.index[0].date()).index\n",
    "cme_trading_days = cme_trading_days.sort_values(ascending=False)\n",
    "cme_trading_days = pd.DatetimeIndex(cme_trading_days)\n",
    "\n",
    "Variables = Variables[Variables.index > '2011-01-01']\n",
    "Variables = Variables[Variables.index.isin(cme_trading_days)]\n",
    "\n",
    "\n",
    "Response = Response[Response.index > '2011-01-01']\n",
    "Response = Response[Response.index.isin(cme_trading_days)]\n",
    "# Response = Response[(Response.Close_Up_Down == 1) | (Response.Close_Up_Down == -1)]\n",
    "\n",
    "Variables.index = pd.DatetimeIndex(Variables.index)\n",
    "Response.index = pd.DatetimeIndex(Response.index)\n",
    "Variables = Variables.reindex(Response.index)\n",
    "\n",
    "len(Variables), len(Response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiClassification Targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels\n",
       " 2        915\n",
       "-2        894\n",
       " 1        383\n",
       "-1        365\n",
       " 0        338\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pv_1 = 0.005 # higher and lower than 0.5% return\n",
    "pv_2 = 0.02 # higher and lower than 2% return\n",
    "\n",
    "col = 'Close_ret' # Can also be 'Adj_close_ret'\n",
    "mutli_class_buckets = Response[col].value_counts(bins = [Response[col].min(),-pv_2, -pv_1,pv_1, pv_2,Response[col].max()])\n",
    "mutli_class_buckets.sort_index(ascending=True, inplace=True)\n",
    "mutli_class_buckets.index = ['Strong_Down','Down','Neutral','Up','Strong_Up']\n",
    "mutli_class_buckets.plot(kind='bar');\n",
    "\n",
    "Neutral = ((Response[col] > -pv_1) & (Response[col] < pv_1))\n",
    "Down = ((Response[col] > -pv_2) & (Response[col] < -pv_1))\n",
    "Up = ((Response[col] > pv_1) & (Response[col] < pv_2))\n",
    "Strong_Down = (Response[col] < -pv_2) \n",
    "Strong_Up = (Response[col] > pv_2)\n",
    "\n",
    "conditions = [Strong_Down, Down, Neutral, Up, Strong_Up]\n",
    "choices = [-2, -1, 0, 1, 2]\n",
    "multi_class = np.select(conditions, choices, default=0)\n",
    "\n",
    "Target = pd.DataFrame(index = Response.index, data = multi_class)\n",
    "Target.columns = ['Labels']\n",
    "Response['Labels'] = Target.Labels.values\n",
    "Target.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -- Choose Response Variable here - LB_Close, Close_ret, Close_Up_Down, OR Adjusted Data from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Variables with all NaNs\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why these variables have NaNs\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CFTClegacy ConcentrationGrossLT4TDRShortOl',\n",
       " 'CFTClegacy TotalReportablePositionsLongAll',\n",
       " 'LumberTracklumberexportus TotalLumberExports',\n",
       " 'LumberTracknorthamericanproduction PrairiesAndEasternCanada',\n",
       " 'LumberTracknorthamericanproduction TotalNorthAmerica',\n",
       " 'LumberTracknorthamericanshipment PrairiesAndEasternCanada',\n",
       " 'LumberTracknorthamericanshipment TotalNorthAmerica'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variables_with_nans = set(Variables.columns) - set(Variables.drop(Variables.columns[Variables.isna().all()].to_list(), axis=1).columns)\n",
    "Variables_with_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    744\n",
      "int64       11\n",
      "bool         7\n",
      "dtype: int64\n",
      "Total Variables Left: 762\n"
     ]
    }
   ],
   "source": [
    "Variables.drop(Variables.columns[Variables.isna().all()].to_list(), axis=1, inplace=True)\n",
    "Variables.drop(Variables.columns[Variables.isnull().all()].to_list(), axis=1, inplace=True)\n",
    "print(pd.Series(Variables.dtypes.values).value_counts())\n",
    "print(\"Total Variables Left:\",pd.Series(Variables.dtypes.values).value_counts().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    6\n",
       "int32      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Response.drop(Response.columns[Response.isna().all()].to_list(), axis=1, inplace=True)\n",
    "Response.drop(Response.columns[Response.isnull().all()].to_list(), axis=1, inplace=True)\n",
    "pd.Series(Response.dtypes.values).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Bool cols (mostly date columns such as Is_year_end etc.) to int columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_bool_cols = Variables.columns[Variables.dtypes.values == 'bool'].to_list()\n",
    "list_of_bool_cols_response = Response.columns[Response.dtypes.values == 'bool'].to_list()\n",
    "\n",
    "for col in list_of_bool_cols:\n",
    "    Variables[col] = Variables[col].astype(int)\n",
    "\n",
    "for col in list_of_bool_cols_response:\n",
    "    Response[col] = Response[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_dataset(new_dataset,original_dataset):\n",
    "    X_train_dict[new_dataset] = X_train_dict[original_dataset]\n",
    "    X_test_dict[new_dataset] = X_test_dict[original_dataset]\n",
    "    X_val_dict[new_dataset] = X_val_dict[original_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_features_df(model,dataset):\n",
    "    model_name = type(model).__name__\n",
    "    features_df.loc[(model_name, dataset),'Num_Features'] = len(X_train_dict[dataset].columns) # so can store list of features\n",
    "    features_df.loc[(model_name, dataset),'Features_List'] = X_train_dict[dataset].columns.to_list()\n",
    "\n",
    "    original_list = set(features_df.loc[(model_name, 'Original'),'Features_List'])\n",
    "    dataset_list = set(features_df.loc[(model_name, dataset),'Features_List'])\n",
    "    removed_list = list(sorted(original_list - dataset_list))\n",
    "    \n",
    "    features_df.loc[(model_name, dataset),'Removed_Features'] = removed_list\n",
    "    features_df.loc[(model_name, dataset),'Model_Details'] = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(dataset):\n",
    "    print(\"\\nShapes for dataset:\",dataset)\n",
    "    print(\"X_train Shape\",X_train_dict[dataset].shape)\n",
    "    print(\"X_test Shape\",X_test_dict[dataset].shape)\n",
    "    print(\"X_val Shape\",X_val_dict[dataset].shape)\n",
    "    # print(\"y_train Shape\",y_train.shape)\n",
    "    # print(\"y_test Shape\",y_test.shape)\n",
    "    # print(\"y_val Shape\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pipe_removed(pipe):\n",
    "    total_removed = 0\n",
    "    print(\"\\nRemoved Features for Pipeline:\",pipe)\n",
    "    for i in range(len(pipe.steps)):\n",
    "        step_name = pipe.steps[i][0]\n",
    "        total_removed += len(pipe.named_steps[step_name].features_to_drop_)\n",
    "        print(step_name, \":\",len(pipe.named_steps[step_name].features_to_drop_))\n",
    "    print(\"Total removed:\",total_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(dataset,pipe):\n",
    "    print(\"\\nRemoving Features for dataset:\",dataset)\n",
    "    print(\"# Features before:\",len(X_train_dict[dataset].columns.to_list()))\n",
    "    X_train_dict[dataset] = pipe.transform(X_train_dict[dataset])\n",
    "    X_test_dict[dataset] = pipe.transform(X_test_dict[dataset])\n",
    "    X_val_dict[dataset] = pipe.transform(X_val_dict[dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocked cross-validation\n",
    "https://goldinlocks.github.io/Time-Series-Cross-Validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.5 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]\n",
    "\n",
    "btscv = BlockingTimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Change between Labels & Close_Up_Down columns for y_combined to make it either a Multiclass (5) or (3)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **cross_val_score - accuracy_score**                                                      \n",
    "# scoring https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\n",
    "\n",
    "def add_metrics(model,dataset):\n",
    "# Took mins to run\n",
    "# Also put 'roc_auc' in metrics_list\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    metrics_list = ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted']\n",
    "\n",
    "    # X_combined = pd.concat([X_train_dict[dataset],X_test_dict[dataset]]).sort_index()\n",
    "    # y_combined = pd.concat([y_train,y_test]).sort_index()\n",
    "\n",
    "    # Removed training data - but use above commented 2 lines incase you need\n",
    "    X_combined = pd.concat([X_test_dict[dataset]]).sort_index()\n",
    "    y_combined = pd.concat([y_test]).sort_index()\n",
    "        \n",
    "    for metric in metrics_list:\n",
    "        score = cross_val_score(model, X_combined, y_combined.Labels, cv=btscv, scoring = str(metric))\n",
    "        features_df.loc[(model_name, dataset),metric]= round(np.median(score),2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_ovr_weighted nan\n",
      "roc_auc_ovo_weighted nan\n"
     ]
    }
   ],
   "source": [
    "### TO DELETE\n",
    "model = models[0]\n",
    "dataset = 'Original'\n",
    "model_name = type(model).__name__\n",
    "metrics_list = ['roc_auc_ovr_weighted', 'roc_auc_ovo_weighted']\n",
    "X_combined = X_test_dict[dataset].sort_index()\n",
    "y_combined = y_test.sort_index()\n",
    "for metric in metrics_list:\n",
    "    score = cross_val_score(model, X_combined, y_combined.Labels, cv=btscv, scoring = str(metric))\n",
    "    print(metric, round(np.median(score),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LumberOHLCV LBHigh</th>\n",
       "      <th>LumberOHLCV LBLow</th>\n",
       "      <th>LumberOHLCV LBClose</th>\n",
       "      <th>LumberOHLCV LBVolume</th>\n",
       "      <th>LumberOHLCV LBopenInterest</th>\n",
       "      <th>LumberOHLCV LBAdjClose</th>\n",
       "      <th>LumberContractSpreads FirstSecond</th>\n",
       "      <th>LumberContractSpreads SecondThird</th>\n",
       "      <th>LumberContractSpreads FirstThird</th>\n",
       "      <th>lumbermovingaverages MA200</th>\n",
       "      <th>...</th>\n",
       "      <th>TAmomentumppo</th>\n",
       "      <th>TAmomentumpposignal</th>\n",
       "      <th>TAmomentumppohist</th>\n",
       "      <th>TAmomentumpvo</th>\n",
       "      <th>TAmomentumpvosignal</th>\n",
       "      <th>TAmomentumpvohist</th>\n",
       "      <th>TAmomentumkama</th>\n",
       "      <th>TAothersdr</th>\n",
       "      <th>TAothersdlr</th>\n",
       "      <th>TAotherscr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>318.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>282.064070</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-47.1950</td>\n",
       "      <td>...</td>\n",
       "      <td>1.375863</td>\n",
       "      <td>1.962720</td>\n",
       "      <td>-0.586857</td>\n",
       "      <td>-18.710412</td>\n",
       "      <td>-14.030077</td>\n",
       "      <td>-4.680335</td>\n",
       "      <td>309.687331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.347275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>328.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>292.337927</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-56.9960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479179</td>\n",
       "      <td>1.866011</td>\n",
       "      <td>-0.386833</td>\n",
       "      <td>-12.209845</td>\n",
       "      <td>-13.666030</td>\n",
       "      <td>1.456186</td>\n",
       "      <td>309.919650</td>\n",
       "      <td>3.144654</td>\n",
       "      <td>3.096223</td>\n",
       "      <td>38.572032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>352.1</td>\n",
       "      <td>332.2</td>\n",
       "      <td>337.5</td>\n",
       "      <td>148.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>284.866031</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-66.1735</td>\n",
       "      <td>...</td>\n",
       "      <td>1.777222</td>\n",
       "      <td>1.848253</td>\n",
       "      <td>-0.071031</td>\n",
       "      <td>-9.260700</td>\n",
       "      <td>-12.784964</td>\n",
       "      <td>3.524264</td>\n",
       "      <td>310.096250</td>\n",
       "      <td>2.896341</td>\n",
       "      <td>2.855190</td>\n",
       "      <td>42.585551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>330.1</td>\n",
       "      <td>322.2</td>\n",
       "      <td>330.1</td>\n",
       "      <td>430.0</td>\n",
       "      <td>7429.0</td>\n",
       "      <td>292.337927</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-58.5715</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805356</td>\n",
       "      <td>1.839674</td>\n",
       "      <td>-0.034318</td>\n",
       "      <td>8.572890</td>\n",
       "      <td>-8.513394</td>\n",
       "      <td>17.086283</td>\n",
       "      <td>310.268337</td>\n",
       "      <td>-2.192593</td>\n",
       "      <td>-2.216987</td>\n",
       "      <td>39.459231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>349.0</td>\n",
       "      <td>340.3</td>\n",
       "      <td>346.8</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2695.0</td>\n",
       "      <td>287.667992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-75.0090</td>\n",
       "      <td>...</td>\n",
       "      <td>2.214262</td>\n",
       "      <td>1.914592</td>\n",
       "      <td>0.299671</td>\n",
       "      <td>10.012560</td>\n",
       "      <td>-4.808203</td>\n",
       "      <td>14.820763</td>\n",
       "      <td>312.216783</td>\n",
       "      <td>5.059073</td>\n",
       "      <td>4.935261</td>\n",
       "      <td>46.514575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-14</th>\n",
       "      <td>379.9</td>\n",
       "      <td>379.9</td>\n",
       "      <td>379.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>237.531656</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>-15.0860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219090</td>\n",
       "      <td>-0.340958</td>\n",
       "      <td>0.121868</td>\n",
       "      <td>-4.393293</td>\n",
       "      <td>7.280338</td>\n",
       "      <td>-11.673631</td>\n",
       "      <td>374.804233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.498521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-15</th>\n",
       "      <td>387.2</td>\n",
       "      <td>387.2</td>\n",
       "      <td>387.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>244.669180</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-22.2205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>-0.265881</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>-12.461942</td>\n",
       "      <td>3.331882</td>\n",
       "      <td>-15.793824</td>\n",
       "      <td>375.621760</td>\n",
       "      <td>1.921558</td>\n",
       "      <td>1.903330</td>\n",
       "      <td>63.582594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-16</th>\n",
       "      <td>383.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>239.653623</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-17.8530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143427</td>\n",
       "      <td>-0.184019</td>\n",
       "      <td>0.327446</td>\n",
       "      <td>11.128500</td>\n",
       "      <td>4.891205</td>\n",
       "      <td>6.237294</td>\n",
       "      <td>375.876932</td>\n",
       "      <td>-1.084711</td>\n",
       "      <td>-1.090637</td>\n",
       "      <td>61.808196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-17</th>\n",
       "      <td>390.2</td>\n",
       "      <td>390.2</td>\n",
       "      <td>390.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>244.283368</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-24.8380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378266</td>\n",
       "      <td>-0.071562</td>\n",
       "      <td>0.449828</td>\n",
       "      <td>2.847373</td>\n",
       "      <td>4.482439</td>\n",
       "      <td>-1.635066</td>\n",
       "      <td>376.770033</td>\n",
       "      <td>1.879896</td>\n",
       "      <td>1.862444</td>\n",
       "      <td>64.850021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-18</th>\n",
       "      <td>390.7</td>\n",
       "      <td>390.7</td>\n",
       "      <td>390.7</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>250.520664</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-25.0940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567432</td>\n",
       "      <td>0.056237</td>\n",
       "      <td>0.511195</td>\n",
       "      <td>17.297526</td>\n",
       "      <td>7.045456</td>\n",
       "      <td>10.252070</td>\n",
       "      <td>377.585053</td>\n",
       "      <td>0.128139</td>\n",
       "      <td>0.128057</td>\n",
       "      <td>65.061259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2216 rows × 762 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LumberOHLCV LBHigh  LumberOHLCV LBLow  LumberOHLCV LBClose  \\\n",
       "2011-01-03               318.0              318.0                318.0   \n",
       "2011-01-04               328.0              328.0                328.0   \n",
       "2011-01-05               352.1              332.2                337.5   \n",
       "2011-01-06               330.1              322.2                330.1   \n",
       "2011-01-07               349.0              340.3                346.8   \n",
       "...                        ...                ...                  ...   \n",
       "2019-10-14               379.9              379.9                379.9   \n",
       "2019-10-15               387.2              387.2                387.2   \n",
       "2019-10-16               383.0              383.0                383.0   \n",
       "2019-10-17               390.2              390.2                390.2   \n",
       "2019-10-18               390.7              390.7                390.7   \n",
       "\n",
       "            LumberOHLCV LBVolume  LumberOHLCV LBopenInterest  \\\n",
       "2011-01-03                  86.0                      1201.0   \n",
       "2011-01-04                 180.0                      1066.0   \n",
       "2011-01-05                 148.0                       918.0   \n",
       "2011-01-06                 430.0                      7429.0   \n",
       "2011-01-07                 214.0                      2695.0   \n",
       "...                          ...                         ...   \n",
       "2019-10-14                   8.0                        60.0   \n",
       "2019-10-15                   2.0                        60.0   \n",
       "2019-10-16                 427.0                      1355.0   \n",
       "2019-10-17                  20.0                        19.0   \n",
       "2019-10-18                 392.0                      1018.0   \n",
       "\n",
       "            LumberOHLCV LBAdjClose  LumberContractSpreads FirstSecond  \\\n",
       "2011-01-03              282.064070                               -1.0   \n",
       "2011-01-04              292.337927                               -1.0   \n",
       "2011-01-05              284.866031                               -1.0   \n",
       "2011-01-06              292.337927                               -1.0   \n",
       "2011-01-07              287.667992                               -1.0   \n",
       "...                            ...                                ...   \n",
       "2019-10-14              237.531656                               -0.6   \n",
       "2019-10-15              244.669180                               -0.5   \n",
       "2019-10-16              239.653623                               -2.7   \n",
       "2019-10-17              244.283368                                0.5   \n",
       "2019-10-18              250.520664                                0.6   \n",
       "\n",
       "            LumberContractSpreads SecondThird  \\\n",
       "2011-01-03                               -2.1   \n",
       "2011-01-04                               -2.1   \n",
       "2011-01-05                               -2.1   \n",
       "2011-01-06                               -2.1   \n",
       "2011-01-07                               -2.1   \n",
       "...                                       ...   \n",
       "2019-10-14                               -6.2   \n",
       "2019-10-15                               -4.0   \n",
       "2019-10-16                               -5.4   \n",
       "2019-10-17                               -5.6   \n",
       "2019-10-18                               -1.0   \n",
       "\n",
       "            LumberContractSpreads FirstThird  lumbermovingaverages MA200  ...  \\\n",
       "2011-01-03                              -3.7                    -47.1950  ...   \n",
       "2011-01-04                              -3.7                    -56.9960  ...   \n",
       "2011-01-05                              -3.7                    -66.1735  ...   \n",
       "2011-01-06                              -3.7                    -58.5715  ...   \n",
       "2011-01-07                              -3.7                    -75.0090  ...   \n",
       "...                                      ...                         ...  ...   \n",
       "2019-10-14                              -6.8                    -15.0860  ...   \n",
       "2019-10-15                              -4.5                    -22.2205  ...   \n",
       "2019-10-16                              -8.1                    -17.8530  ...   \n",
       "2019-10-17                              -5.1                    -24.8380  ...   \n",
       "2019-10-18                              -0.4                    -25.0940  ...   \n",
       "\n",
       "            TAmomentumppo  TAmomentumpposignal  TAmomentumppohist  \\\n",
       "2011-01-03       1.375863             1.962720          -0.586857   \n",
       "2011-01-04       1.479179             1.866011          -0.386833   \n",
       "2011-01-05       1.777222             1.848253          -0.071031   \n",
       "2011-01-06       1.805356             1.839674          -0.034318   \n",
       "2011-01-07       2.214262             1.914592           0.299671   \n",
       "...                   ...                  ...                ...   \n",
       "2019-10-14      -0.219090            -0.340958           0.121868   \n",
       "2019-10-15       0.034429            -0.265881           0.300310   \n",
       "2019-10-16       0.143427            -0.184019           0.327446   \n",
       "2019-10-17       0.378266            -0.071562           0.449828   \n",
       "2019-10-18       0.567432             0.056237           0.511195   \n",
       "\n",
       "            TAmomentumpvo  TAmomentumpvosignal  TAmomentumpvohist  \\\n",
       "2011-01-03     -18.710412           -14.030077          -4.680335   \n",
       "2011-01-04     -12.209845           -13.666030           1.456186   \n",
       "2011-01-05      -9.260700           -12.784964           3.524264   \n",
       "2011-01-06       8.572890            -8.513394          17.086283   \n",
       "2011-01-07      10.012560            -4.808203          14.820763   \n",
       "...                   ...                  ...                ...   \n",
       "2019-10-14      -4.393293             7.280338         -11.673631   \n",
       "2019-10-15     -12.461942             3.331882         -15.793824   \n",
       "2019-10-16      11.128500             4.891205           6.237294   \n",
       "2019-10-17       2.847373             4.482439          -1.635066   \n",
       "2019-10-18      17.297526             7.045456          10.252070   \n",
       "\n",
       "            TAmomentumkama  TAothersdr  TAothersdlr  TAotherscr  \n",
       "2011-01-03      309.687331    0.000000     0.000000   34.347275  \n",
       "2011-01-04      309.919650    3.144654     3.096223   38.572032  \n",
       "2011-01-05      310.096250    2.896341     2.855190   42.585551  \n",
       "2011-01-06      310.268337   -2.192593    -2.216987   39.459231  \n",
       "2011-01-07      312.216783    5.059073     4.935261   46.514575  \n",
       "...                    ...         ...          ...         ...  \n",
       "2019-10-14      374.804233    0.000000     0.000000   60.498521  \n",
       "2019-10-15      375.621760    1.921558     1.903330   63.582594  \n",
       "2019-10-16      375.876932   -1.084711    -1.090637   61.808196  \n",
       "2019-10-17      376.770033    1.879896     1.862444   64.850021  \n",
       "2019-10-18      377.585053    0.128139     0.128057   65.061259  \n",
       "\n",
       "[2216 rows x 762 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the following steps:\n",
    "# 1. Fill the dataset with passed X Variables\n",
    "# 2. Fit Pipeline function\n",
    "# 3. Remove features/Transform train, test, val\n",
    "# 4. Add features to features_df\n",
    "# 5. Print_pipe_removed\n",
    "# 6. Get Shapes\n",
    "# 7. Add metrics to features_df\n",
    "\n",
    "#  = DropConstantFeatures(tol=1, variables=None, missing_values='raise')\n",
    "def apply_pipe_transform(dataset,original_dataset, pipe, model):\n",
    "    fill_with_dataset(dataset,original_dataset)\n",
    "    pipe = pipe.fit(X_train_dict[dataset])\n",
    "    remove_features(dataset,pipe)\n",
    "    add_to_features_df(model,dataset)\n",
    "    print_pipe_removed(pipe)\n",
    "    get_shapes(dataset)\n",
    "    add_metrics(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE confusion matrix for all labels in our dataset - need to pass one label like [-2,-1,0,1,2]\n",
    "def _color_it(val):\n",
    "    if val == 'True Negative':\n",
    "        color = 'red' \n",
    "    elif val == 'False Negative':\n",
    "        color = 'blue'\n",
    "    elif val == 'True Positive':\n",
    "        color = 'green'\n",
    "    elif val == 'False Positive':\n",
    "        color = 'orange'\n",
    "    return 'color: %s' % color\n",
    "    \n",
    "def generate_sample_confusion_matrix(input_label):\n",
    "     # choose any label from the list [-2,-1,0,1,2]\n",
    "    labels_ = lab.tolist()\n",
    "    label_removed = labels_.copy()\n",
    "    label_removed.remove(input_label)\n",
    "    idx = pd.MultiIndex.from_product([['Actual'], lab])\n",
    "    col = pd.MultiIndex.from_product([['Prediction'], lab])\n",
    "    metric_matrix = pd.DataFrame(columns = col, index = idx)\n",
    "    metric_matrix.loc[('Actual',input_label),('Prediction',input_label)] = 'True Positive'\n",
    "    metric_matrix.loc[('Actual',label_removed),('Prediction',input_label)] = 'False Positive'\n",
    "    metric_matrix.loc[('Actual',input_label),('Prediction',label_removed)] = 'False Negative'\n",
    "    metric_matrix.loc[('Actual',label_removed),('Prediction',label_removed)] = 'True Negative'\n",
    "    return metric_matrix.style.applymap(_color_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Models for both Classifiers & Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using xgb_clf for now because it is too slow\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=3, n_jobs=-1)\n",
    "xgb_clf = XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "\n",
    "models = [rf_clf,xgb_clf]\n",
    "# models = [rf_clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe to Store Model Features & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [type(m).__name__ for m in models]\n",
    "dataset = 'Original'\n",
    "multilevel_index = pd.MultiIndex.from_product([model_names,[dataset]],names=['Model', 'Dataset'])\n",
    "cols_names = ['Model_Details','Num_Features','Features_List','Removed_Features'] + ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted']\n",
    "features_df = pd.DataFrame(columns=cols_names, index=multilevel_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset in 3 Dictionaries of Training, Testing & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes for dataset: Original\n",
      "X_train Shape (2216, 762)\n",
      "X_test Shape (555, 762)\n",
      "X_val Shape (124, 762)\n"
     ]
    }
   ],
   "source": [
    "X_train_dict = {}\n",
    "X_test_dict = {}\n",
    "X_val_dict = {}\n",
    "\n",
    "# To make sure test is the most recent\n",
    "Variables.sort_index(ascending = True, inplace = True) \n",
    "Response.sort_index(ascending = True, inplace = True)\n",
    "\n",
    "Validation_date_start = '2022-01-01'\n",
    "X_val_dict['Original'] = Variables[Variables.index >= Validation_date_start]\n",
    "y_val = Response[Response.index >= Validation_date_start]\n",
    "\n",
    "X_train_dict['Original'], X_test_dict['Original'], y_train, y_test = train_test_split(Variables[Variables.index < Validation_date_start], Response[Response.index < Validation_date_start], test_size=0.20, shuffle = False)\n",
    "\n",
    "for m in models:\n",
    "    add_to_features_df(m,dataset='Original')\n",
    "    add_metrics(m,dataset)  \n",
    "\n",
    "# Shapes\n",
    "get_shapes(dataset = 'Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Functions to plot Blocked TimeSeries Splot****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAFgCAYAAAD3tH5OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkjUlEQVR4nO3de3hU5bn38d+dhFMMIkg8gkKRkBAQLYilxRO+ErSItZbixlbtWzce6pa+KB6qWy3abVW09YSIh02ttVKxVjcqSD3UWush0CAgIOKGC9BIEDkqSMj9/rHWxMWYkAQSHsh8P9c1V2bWPPPMvdaaNfldzzqMubsAAAAQRlboAgAAADIZYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIoxhr2FmN5qZJ26fm9lcMxuVaHNi/FyvJnjv1XW0edXMpjbm+8b9Tk6b75puk+tTYxPUNtDMZppZhZltMrPFcS2dGqn/8+P5y2uM/hL9djSze83sQzPbbGYfmdkMM/veTvS11MzGJx5PNrPSxOP+ZnZj41QOoDnKCV0A0EDrJA2J7+8j6XRJD5jZRnd/PFxZkqRLJG1tgn5vkjQx8fi/JO0Xv19KhaQtkv6nCd6/RmY2UNKrkv4i6aeSvpDUU9JISYdLWtEIb/OcpAGSPm+EviRJZtZC0iuSciX9StISSZ0kDZZ0sqL52RU3SWqTeNxf0g2SbtzFfgE0U4Qx7G0q3f3NxOOXzOzbkr4nKWgYc/f3mqjfJYoCgyTJzNZIykpbDimNEYDq62JJCyQN96+uHj1T0l1mZrvSsZllS8p29wpFQbMxnSipl6T+7v5OYvpju1q3VL2+AKDe2E2J5mCDpBa1PWlmuWZ2t5mVx7uk3jGzwTW0O9PM3jazL8zsUzN73swOr6VPM7N7zOwzMzs2nrbdbsrUbkMzO9rM3ox3q/7LzI5L66uVmd1vZmvj973dzH5uZg36eYz03ZSJXbYnm9kzid2Ig80sO36f1Wa20szG1NDfcWb2t7juT83sQTNrm2iyn6RVXsPPeKRPM7MLzGy+mW0xs2VmdmXa85PNrNTMvmdm8yVtlnRsTbspzay1md1mZsvj/uaY2Wlp/Q0zs1nxPH9mZm+Z2QmJuiWpfEd1J9bfd8xsdvzZKYtHBGuV3E1pZudLuie+n9ql/OqOXg8g8xDGsNcxs5z4tq+Z/UjSCZKe3sFLHpT0E0W7pM6UtFzSc8l/qmb2Y0l/VjQC9cO4/fuS8mt4/yxJkySdLWmQu7+1g/fOlfQ7SQ9IOkvRrsQ/m1luos1tks6X9EtJ50g6TNLlO+izoR6Q9LqieV8maaqkeyW1VbRLcaqkO1KhUpLM7DuS/qoosPxA0s8lnSbpvxP9zpZ0kpn9p5l9o7Y3N7Oxku5XtPtvaHz/JjO7NK1pF0XL4hZJp0r631q6nKpoef2Xot3U70h61syOit+vW9zm5fj5cyRNk9Qhfn2ZpCpJj1h0zNuO9hDkSnpM0W7i4ZLWSnrBzA7awWuSnpN0R3x/QHy7pPbmADKSu3PjtlfcFB1z4zXc7kq0OTGe1it+XKToH+95iTZZkuZJmpF4vFLSn+t479WSsiX9XtLHkorT2rwqaWoN9Q5KTDsqnjYkfry/omOtxibamKT5igdqaqhlqqRXa6uxhmVxQ2Jaz3jay2nLo1zSrYlpf5f0Slr/g9KW7b6KAk9qPXykKLQUJF6zr6SNyRri6ePi98yOH0+O+zgqrd358fS8+PHJ8eMT0tq9JunJ+P4PJH1ax2dpjKQv476+kDRd0e7Wmj5vIxPT8iStkfTrxLSlksYnHk+WVJp4fGlt65IbN27c3J2RMex11kk6Jr4NlDRa0nlmdkMt7Y9RFG6eTE1w96r4cWpkrIekQ7T9qE9NsiU9oSjknODu8+tR75eKQlpK6riy1NmGvSW1lvRsoj5X4x6I/1Li/gfx35cT71cl6UNJh0rRbl1FIzh/SoxC5igaXdsqqW/8uvWKwtG3FY1SLZF0gaTZZvbNuPsBik60eDKtr5clHaivloMkrXT3sjrm5f8oCnH/SOvvJUn94jZzJbUzs9/Fu2T3Se/E3e+U1FXSzxQt62Pj+b2lhvd8OvG6jYqOi+tfR50AUG+EMextKt29NL79w93vVjTK8gsz61BD+4MlbXT39LPxPpGUa2atFI1OSdFo147kKtp99rK7v1/PejfEYUeS5O5fxndbx39Tu7vSD1JvzIPW19bw/mvT2nyZqKm9ouA5QVH4St22KDo2r3OiP3f3f7r7te5+nKJAVCXpP+MmHeO/89P6eiWeXt2XonVSl46KltnWtNuNqb7cfZGkMyR9Q9Lzklab2eNmtt0uZ3df6e4T3P2HikLhdEljzWz/RLON7v5FWg2rFH2uAKBRcDYlmoMFklpK6lbDcx9LyjOz3LRAdqCkz919i5l9Gk+r6x/sBkkjFB1v9rG7X72rheurg8jzFe3+UuJxKGsV7Z67UVGYSfdRbS909zIzm6lod6j01TwNVc1ha1Hy5fWobY2iXcrf21Ejd39O0XpqJ+m7kn6r6ED6s2tpv8nMJii6bMoRklKfiTwza5MWyA5Q3cEdAOqNMIbmIHWB1+WSCtOee0fRP/kfSHpUis6EjB+/HrdZpOgf/HmqY/egu79kZsMVHYS/wd1/tYu1z1V05uAZig5eT9V3+i72u9PiYPKmpB7uPq62dmZ2gLuvSptmikJxKnj9U9ExWYfEAWlXvaTo5IaN7r6wrsbuvk7S4/GZlAPiGjtIWufu29Kad4//pofGMxVfNiU+q/MURSdw1NeX8Wtbu/vmBrwOQIYgjGFvk2Nm34rvt1R0/NJ1kp5x93Iz2y6MufsCM/ujpHvjyzIskfTvikLbxXGbqvhSC38wsz9I+qPiA+8l/dHdS9P6/J/47Ms/mNl6d79nZ2fG3T81swcl/dLMtioa5fuJogPfG3Rpi0Z2paJruFUpOmFgg6KzPL8r6dp4N+1D8ZmlTylaru0V1d5H0ZmHcve1Fl19/i6LLhPymqLDIwokneTuZzawrpmSZkiaaWa3Ktr9ua+iEyNau/s1ZnahouA1XdEoXve4nkfjPgZJusXM/ltRWK9SdNzb1ZKmufvSxPt9IelXcQj7SNIVij53dzWg5lRoHG1mL0taH+9KBQBJhDHsfdopGm2RomOFlik6g+/mHbzm3yXdKul6RdeYmitpqLunRsbk7o+b2WZJ1yoKH5skvalajt1y9yfiA8MnxSNkk3dhnq5UdCzWjYqCwe8lPazochJBuPvrZna8ostt/F7RMWTLFAWc1MjRBEVnO16vaBfvWkXhqMTdX0z0dZuZfSTp/yka1dqs6LIhU3aiLjez70v6haLlc5iiXZdliq/nJeldScMk3anochYfK7q8yfXx829JekbRJUyujOdtqaLPUHrI+lzSuXHfRYqC1Wnu3pDdlH+XdLuik01uURRIT2zA6wE0cxaduAVgT2Jmf5XUwt1PqLMxmkQ8onepu3esqy0A7ApGxoDAzOwkRZdWmK1ohGyEoktGDA9ZFwBg9yCMAeFtVHR24DWKLi+xWNL57j51Ry8CADQP7KYEAAAIiIu+AgAABNQkuyk7duzoXbp0aYquAQBADWbNmrXa3UNeMBo7qUnCWJcuXVRaWlp3QwAA0CjMbFnoGrBz2E0JAAAQEGEMAAAgIMIYAABAQIQxAACAgAhjAAAAARHGAAAAAiKMAQAABLRH/zblsyOLNK4kKvHtw0/WtEkzNGPFGN0zbr6mTZohSdo0dqb2uf0UbRo7UyPWjdeUdldoxLrx1W1LOt35tX6Tr0n/K0l3vHuq3j78ZE1pd8V2z6dem7TP7ado6KgSTZs0o/q5fW4/ReNKcnTsw5dp4F2nfq2+VBtJGjqqRJK2e72k6nlIvfeMFWM08K5TJUmvj36hut+aakr2P64kp3rZpbcbsW68/uP6Yr3107t1/YzK7ZbDHe+equtnVEqSZqwYI0m6Z9z87epPzney3hHrxm83T8n5/4/riyVJJZ3u1LiSHF1+5AvV/W0aO3O7eRtXklNdw9BRJeq/7CVJqq41WWNyHaU+M8m+U69/+/CTJal6vpOSz0nabrmklnvqs5dcn6+PfmG7eUqt99T8lnS6U0NHlVQvu1T7ZJvUuk0uf0nbfYZS83b9jMrqz02q1lS9xz58WXUd18+o/Nr6Ty2z1Dwl5yG1rdS0XSQ/u6k607ev9O0oOS+pdZF6z+S6SG3LKenbRLKWoaNKqpdp8rshta2mfxYkVW876Z/tHW3XyflMfc6TkttjTX0kl4P01XdK6jP89uEnV6+71OdAUvW8paQ+T8nP6uVHvlD9GUp9HmesGFO9/lP99V/2ki4/8oXqbSm1nJL1JL8n0/tIzldqHabPV3L+k5KfAUnV662m762aPic1fYcm+07/XCbXU2pbT343JPtMLcPkcpC2/xymv3dq2aS2qWSdqc/DWz+9e7tldMe7p+rYhy+r/t5MrZOalJ43t8bpyByMjAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAEZO7e6J3269fPS0tLG71fAABQMzOb5e79QteBhmNkDAAAICDCGAAAQECEMQAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABBQTugCAADA7jNr1qwDcnJyHpLUSwzK7A5VkuZVVlZe0Ldv31U1NSCMAQCQQXJych466KCDivLz8z/Lyspq/J/hwXaqqqqsoqKiZ3l5+UOShtXUhkQMAEBm6ZWfn7+eILZ7ZGVleX5+/jpFI5E1t9mN9QAAgPCyCGK7V7y8a81chDEAAICAOGYMAIAMtvbOK/r4F5saLQ9Ym30q9xszfk5tz5eXl2efeOKJPSRp9erVLbKysrxDhw6VklRWVragdevWOxy1mzZtWttWrVpVnXLKKZsk6bbbbsvPzc2tuvTSSz9trHmoj/Q6dgVhDACADNaYQaw+/R100EHbFi5c+J4kjRkz5pC8vLxt48aN+6S+/b/88stt8/LytqVC0JVXXlmxaxXvnPQ6dgW7KQEAQFB///vfc4855pgexcXFRQMHDuy+bNmyFpJ08803H9CtW7figoKCnkOHDv3GokWLWj766KP5EydOPLCwsLDn9OnT88aMGXPI9ddff6Ak9e/fv8fFF198aO/evYu6dOnSa/r06XmStGHDhqzTTjvtG926dSs+5ZRTuh155JGFr732Wm56HZdccsmhqfcbNWpUJ0n66KOPckpKSrr16tWrqFevXkUvvvjiPjXVsSvzz8gYAAAIxt112WWXHfbcc899cMghh1Q++OCD7a+44opDn3zyyaV33333QcuWLZvbpk0bX716dXbHjh23nXvuuRXJ0bQXX3xx32R/lZWVNnfu3AVTpkxpN27cuEOGDBny/u23356/3377bVuyZMn8d955p/WAAQOK0+soLy/Pfv7559t/+OGH87KysrR69epsSbrwwgs7jxkz5pOSkpKNixcvbllSUtL9ww8/nJ9ex64gjAEAgGC2bNmStXjx4jaDBg0qkKSqqirl5+dvlaQePXp8ceaZZ3YdNmzY2nPOOWdtffobPnz4Z5L07W9/e9PYsWNbStIbb7yRN3r06FWSdMwxx2wuKCj4PP11+++//7ZWrVpVjRgxosvQoUPXjhgxYp0k/eMf/9h38eLFbVLtNm7cmL1u3bpG3bNIGAMAAMG4u4444ogvysrKFqY/98orryx+4YUX2j7zzDPtxo8ff/CiRYvm19Vf6gSAnJwcbdu2zepbR4sWLVRWVrbg2Wef3Xfq1Knt77///gPefPPN991ds2fPXpCbm9tklwOpV7Izs6VmNtfMysystKmKAQAAmaVVq1ZVa9asyfnrX/+6jyRt2bLFSktLW2/btk1Llixpefrpp2+47777VsYjUtlt27bdtmHDhuyGvMeAAQM2PvHEE+0ladasWa3ff//9Nult1q1bl7VmzZrsESNGrJs4ceLyhQsX5krSwIED199yyy0HpNq98cYbbSRpZ+qoTUOG2U5y96PcvV9jvDEAAAjP2uxTGbK/rKwsPfHEE0uuvvrqTj169OhZXFzc829/+1teZWWljRw5smtBQUHPXr169bzgggtWdezYcdtZZ5219rnnntuvIQfOjx07tuLTTz/N6datW/E111xz6BFHHLG5ffv225Jt1q5dmz1kyJDuBQUFPQcMGNDjpptuWi5JkyZNWj579ux9CgoKenbr1q343nvvzZeknamjNuZe96ibmS2V1M/dV9en0379+nlpKQNoAADsLmY2qz4DJnPmzFnap0+fev0/by4qKyv15ZdfWm5urs+fP7/V4MGDC5YsWTKvrmuaNaY5c+Z07NOnT5eanqvvMWMu6UUzc0kPuPuk9AZmNkrSKEk67LDDdrJUAACAxrVhw4as4447rsfWrVvN3fWb3/xm2e4MYnWpbxgb6O4rzewASTPNbKG7v5ZsEAe0SVI0MtbIdQIAAOyU9u3bV82bN29B6DpqU69jxtx9Zfx3laSnJfVvyqIAAAAyRZ1hzMz2MbO2qfuSBkua19SFAQAAZIL67KY8UNLTZpZq/7i7T2/SqgAAADJEnWHM3T+U1Gc31AIAAJBxuAI/AAAZ7Iz/O6vP+o2VjZYH9s3LqXzmkb5zanu+vLw8+8QTT+whSatXr26RlZXlHTp0qJSksrKyBTs6y/G1117LfeSRR/afPHny8h3VcPTRRxf+61//+toV/Zva1VdffdCvf/3r8oa+jjAGAEAGa8wgVp/+DjrooG0LFy58T5LGjBlzSPqPbW/dulUtWrSo8bXHH3/858cff/zXflcyXYggJkl33333wTsTxhr1hy4BAAAa6qyzzuoycuTIw4488sjCiy++uNMrr7ySe9RRRxUWFRX1PProowvnzJnTSpKmTZvW9qSTTjpCioLc8OHDu/Tv379Hp06det98883VP1mUm5t7dKp9//79ewwZMuQbXbt2LR42bFjXqqoqSdKUKVPade3atbi4uLjo/PPP75zqN6m0tLR17969iwoLC3sWFBT0nDt3bitJmjBhQofU9JEjRx5eWVmpSy655NAtW7ZkFRYW9hw2bFjXhsw/I2MAACC4jz/+uOXs2bMX5uTkaM2aNVnvvPPOwhYtWugvf/lL2yuvvLLTjBkzlqS/5oMPPmj9xhtvLFq7dm12UVFRr7Fjx1a0atVqu92cCxYsaFNWVvZhly5dtvbt27dw5syZeccdd9ym0aNHH/7qq68uLCws/PL000+vMTzdc889+ZdccsknF1988ZrNmzdbZWWlZs+e3Xrq1KkdSktLF7Zq1cp/9KMfHTZx4sT9J0yYsHLy5MkHpEb9GoIwBgAAgvv+97//WU5OFEviH+zuunTp0tZm5lu3brWaXjN48OC1bdq08TZt2lR26NBh64oVK3K6deu2Ndmmd+/em1LTiouLP1+yZEnLtm3bbuvcufOWwsLCLyXp7LPPXvPQQw/lp/c/YMCATePHjz94xYoVLc8+++zPevfuvWX69Olt582bl9unT58iSdq8eXPWAQccsEu/70kYAwAAweXl5VWl7l911VWHnnDCCRtmzpy5ZNGiRS0HDRrUo6bXJEfBsrOzVVlZ+bXQVp82tbnooovWHHfccZuefvrpdkOHDu1+zz33LHN3Gz58+Kf33XffyvrP3Y5xzBgAANijrF+/PrtTp05fStIDDzzQsbH7P/LIIzcvX7681aJFi1pK0pQpUzrU1O69995rWVRUtOW6665bVVJSsrasrKzNkCFD1k+bNq39ypUrcyTpk08+yX7//fdbSlJOTo5v2bKl3mEvhTAGAEAG2zcvZ5d2sTVFf1dddVX5jTfe2KmoqKhnZWWjlidJysvL8zvvvHPZkCFDuhcXFxfl5eVta9u27bb0do899liHgoKC4sLCwp4LFixoc+GFF37at2/fzdddd93Kk08+uaCgoKDnoEGDCpYvX95Cks4555yKoqKiBh/Ab+6N/5ve/fr189LS0kbvFwAA1MzMZrl7v7razZkzZ2mfPn1W746a9mTr1q3LateuXVVVVZXOPffcw7p37775hhtuWNVU7zdnzpyOffr06VLTc4yMAQCAjPPb3/62Y2FhYc/u3bsXr1+/PnvMmDHBAioH8AMAgIxzww03rGrKkbCGYGQMAIDMUlVVVdXgg8yx8+LlXVXb84QxAAAyy7yKiop2BLLdo6qqyioqKtpJmldbG3ZTAgCQQSorKy8oLy9/qLy8vJcYlNkdqiTNq6ysvKC2BoQxAAAySN++fVdJGha6DnyFRAwAABAQI2MAAEnSRbd+FrqEBrl2Wa17ffYanSc8FboE7AEYGQMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiCvwAwAkSROvah+6hAbi6vVoHhgZAwAACIgwBgAAEBBhDAAAICDCGAAAQECEMQAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgoHqHMTPLNrN/mdm0piwIAAAgkzRkZGy0pAVNVQgAAEAmqlcYM7NOkr4r6aGmLQcAACCz1Hdk7LeSrpRUVVsDMxtlZqVmVlpRUdEYtQEAADR7dYYxMxsqaZW7z9pRO3ef5O793L1ffn5+oxUIAADQnNVnZOw7koaZ2VJJT0gaZGaPNWlVAAAAGaLOMObu17h7J3fvIulsSS+7+4+avDIAAIAMwHXGAAAAAsppSGN3f1XSq01SCQAAQAZiZAwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQIQxAACAgAhjAAAAARHGAAAAAiKMAQAABEQYAwAACIgwBgAAEBBhDAAAIKCc0AUAQENcdOtnoUtokGuXXRC6hF3WecJToUsAmjVGxgAAAAIijAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAAC4gr8APYqE69qH7qEBuLq9QB2jJExAACAgAhjAAAAARHGAAAAAiKMAQAABEQYAwAACIgwBgAAEBBhDAAAICDCGAAAQECEMQAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAAB1RnGzKy1mb1tZnPMbL6Z/XJ3FAYAAJAJcurRZoukQe6+0cxaSHrdzF5w9zebuDYAAIBmr84w5u4uaWP8sEV886YsCgAAIFPU65gxM8s2szJJqyTNdPe3amgzysxKzay0oqKikcsEAABonuoVxtx9m7sfJamTpP5m1quGNpPcvZ+798vPz2/kMgEAAJqnBp1N6e5rJb0iaUiTVAMAAJBh6nM2Zb6Z7RffbyPpFEkLm7guAACAjFCfsykPlvQ7M8tWFN7+5O7TmrYsAACAzFCfsynflXT0bqgFAAAg43AFfgAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQIQxAACAgHJCFwA0Rxfd+lnoEurt2mUXhC6hUXSe8FToEgBgpzAyBgAAEBBhDAAAICDCGAAAQECEMQAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABAQV+AHmsDEq9qHLqEBuHI9AITEyBgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQIQxAACAgAhjAAAAARHGAAAAAiKMAQAABEQYAwAACIgwBgAAEBBhDAAAICDCGAAAQECEMQAAgIDqDGNm1tnMXjGz98xsvpmN3h2FAQAAZIKcerSplHS5u882s7aSZpnZTHd/r4lrAwAAaPbqHBlz94/dfXZ8f4OkBZIOberCAAAAMkGDjhkzsy6Sjpb0Vg3PjTKzUjMrraioaKTyAAAAmrd6hzEzy5P0lKSfu/v69OfdfZK793P3fvn5+Y1ZIwAAQLNVrzBmZi0UBbE/uPufm7YkAACAzFGfsylN0sOSFrj7nU1fEgAAQOaoz8jYdyT9WNIgMyuLb6c1cV0AAAAZoc5LW7j765JsN9QCAACQcbgCPwAAQECEMQAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQDmhC0A4F936WegS6u3aZReELqFRdJ7wVOgSAAB7GEbGAAAAAiKMAQAABEQYAwAACIgwBgAAEBBhDAAAICDCGAAAQECEMQAAgIAIYwAAAAERxgAAAALiCvwZbOJV7UOX0ABcuR4A0DwxMgYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQIQxAACAgAhjAAAAARHGAAAAAiKMAQAABEQYAwAACIgwBgAAEBBhDAAAIKA6w5iZPWJmq8xs3u4oCAAAIJPUZ2RssqQhTVwHAABARqozjLn7a5LW7IZaAAAAMk6jHTNmZqPMrNTMSisqKhqrWwAAgGat0cKYu09y937u3i8/P7+xugUAAGjWOJsSAAAgIMIYAABAQPW5tMUfJf1TUg8zW2FmP236sgAAADJDTl0N3P3fdkchAAAAmYjdlAAAAAERxgAAAAIijAEAAAREGAMAAAiIMAYAABAQYQwAACAgwhgAAEBAhDEAAICACGMAAAABEcYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQIQxAACAgAhjAAAAAeWELmBHLrr1s9AlNMi1yy4IXcIu6zzhqdAlAACQURgZAwAACIgwBgAAEBBhDAAAICDCGAAAQECEMQAAgIAIYwAAAAERxgAAAAIijAEAAAREGAMAAAhoj74C/8Sr2ocuoYG4ej0AAGgYRsYAAAACIowBAAAERBgDAAAIiDAGAAAQEGEMAAAgIMIYAABAQIQxAACAgAhjAAAAAZm7N36nZhWSljVytx0lrW7kPrFzWBd7BtbDnoN1sWfI9PVwuLvnhy4CDdckYawpmFmpu/cLXQdYF3sK1sOeg3WxZ2A9YG/FbkoAAICACGMAAAAB7U1hbFLoAlCNdbFnYD3sOVgXewbWA/ZKe80xYwAAAM3R3jQyBgAA0OwQxgAAAALaK8KYmQ0xs0Vm9oGZXR26nubOzJaa2VwzKzOz0nhaBzObaWaL47/t4+lmZnfH6+ZdM/tm2Or3bmb2iJmtMrN5iWkNXvZmdl7cfrGZnRdiXvZmtayHG81sZbxdlJnZaYnnronXwyIzK0lM57trF5hZZzN7xczeM7P5ZjY6ns42gWZljw9jZpYt6T5Jp0rqKenfzKxn2KoywknuflTimj1XS3rJ3btLeil+LEXrpXt8GyXp/t1eafMyWdKQtGkNWvZm1kHSDZKOldRf0g2pf1aot8n6+nqQpN/E28VR7v68JMXfR2dLKo5fM8HMsvnuahSVki53956SviXpZ/EyZJtAs7LHhzFFG84H7v6hu38p6QlJZwSuKROdIel38f3fSfpeYvqjHnlT0n5mdnCA+poFd39N0pq0yQ1d9iWSZrr7Gnf/TNJM1RwsUIta1kNtzpD0hLtvcff/lfSBou8tvrt2kbt/7O6z4/sbJC2QdKjYJtDM7A1h7FBJyxOPV8TT0HRc0otmNsvMRsXTDnT3j+P75ZIOjO+zfppeQ5c966TpXBrv/nokMbLCetgNzKyLpKMlvSW2CTQze0MYw+430N2/qWjI/2dmdnzySY+uh8I1UQJg2Qd1v6Ruko6S9LGkO4JWk0HMLE/SU5J+7u7rk8+xTaA52BvC2EpJnROPO8XT0ETcfWX8d5WkpxXtbvkktfsx/rsqbs76aXoNXfaskybg7p+4+zZ3r5L0oKLtQmI9NCkza6EoiP3B3f8cT2abQLOyN4SxdyR1N7OuZtZS0YGyzwauqdkys33MrG3qvqTBkuYpWuapM5DOk/RMfP9ZSefGZzF9S9K6xO4DNI6GLvsZkgabWft4V9rgeBp2QdqxkGcq2i6kaD2cbWatzKyrooPH3xbfXbvMzEzSw5IWuPudiafYJtCs5IQuoC7uXmlmlyracLIlPeLu8wOX1ZwdKOnp6DtQOZIed/fpZvaOpD+Z2U8lLZP0w7j985JOU3TQ8ueSfrL7S24+zOyPkk6U1NHMVig6A+zXasCyd/c1ZnaTojAgSePcvb4Ho0O1rocTzewoRbvElkq6UJLcfb6Z/UnSe4rO/vuZu2+L++G7a9d8R9KPJc01s7J42i/ENoFmhp9DAgAACGhv2E0JAADQbBHGAAAAAiKMAQAABEQYAwAACIgwBgAAEBBhDAAAICDCGAAAQED/H1/ppIncC0e5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "n_splits = 5\n",
    "cv = BlockingTimeSeriesSplit\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=None)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "        \n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['class']\n",
    "    # ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "    #        xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "    #        ylim=[n_splits+1.2, -.1], xlim=[0, 100])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_timeseries_split(X,y):\n",
    "\n",
    "        this_cv = cv(n_splits=n_splits)\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        plot_cv_indices(this_cv, X, y, ax, n_splits)\n",
    "\n",
    "        ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "                ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(right=.7)\n",
    "                \n",
    "        plt.show()\n",
    "\n",
    "print(\"The horizontal axis is the training set size while the vertical axis represents the cross-validation iterations. The folds used for training are depicted in blue and the folds used for validation are depicted in orange. The final horizontal bar are the FIVE [-2,-1,0,1,2] class labels for the response variable\")\n",
    "plot_timeseries_split(np.array(X_train_dict['Original']),np.array(y_train.Labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all constant Variables\n",
    "<div style=\"color: Green; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>To Do:</b> Check why the following features have only one value\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Constant\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Constant', DropConstantFeatures())])\n",
      "Constant : 46\n",
      "Total removed: 46\n",
      "\n",
      "Shapes for dataset: Constant\n",
      "X_train Shape (2216, 716)\n",
      "X_test Shape (555, 716)\n",
      "X_val Shape (124, 716)\n"
     ]
    }
   ],
   "source": [
    "# Issue with using XGBOOST - takes long time and gives warnigs Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = 'Constant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=1, variables=None, missing_values='raise'))])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0])\n",
    "# apply_pipe_transform(dataset,'Original', pipe, models[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: QuasiConstant\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('QuasiConstant', DropConstantFeatures(tol=0.95))])\n",
      "QuasiConstant : 57\n",
      "Total removed: 57\n",
      "\n",
      "Shapes for dataset: QuasiConstant\n",
      "X_train Shape (2216, 705)\n",
      "X_test Shape (555, 705)\n",
      "X_val Shape (124, 705)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'QuasiConstant'\n",
    "pipe = Pipeline([(dataset, DropConstantFeatures(tol=0.95, variables=None, missing_values='raise')),])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Duplicated\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Duplicated', DropDuplicateFeatures(missing_values='raise'))])\n",
      "Duplicated : 85\n",
      "Total removed: 85\n",
      "\n",
      "Shapes for dataset: Duplicated\n",
      "X_train Shape (2216, 677)\n",
      "X_test Shape (555, 677)\n",
      "X_val Shape (124, 677)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Duplicated'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated & Quasi Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Dupl&QConstant\n",
      "# Features before: 705\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Dupl&QConstant',\n",
      "                 DropDuplicateFeatures(missing_values='raise'))])\n",
      "Dupl&QConstant : 48\n",
      "Total removed: 48\n",
      "\n",
      "Shapes for dataset: Dupl&QConstant\n",
      "X_train Shape (2216, 657)\n",
      "X_test Shape (555, 657)\n",
      "X_val Shape (124, 657)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Dupl&QConstant'\n",
    "pipe = Pipeline([(dataset, DropDuplicateFeatures(variables=None, missing_values='raise')),])\n",
    "apply_pipe_transform(dataset,'QuasiConstant', pipe, models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Correlated\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Correlated',\n",
      "                 SmartCorrelatedSelection(cv=<__main__.BlockingTimeSeriesSplit object at 0x000002192702F130>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "Correlated : 257\n",
      "Total removed: 257\n",
      "\n",
      "Shapes for dataset: Correlated\n",
      "X_train Shape (2216, 505)\n",
      "X_test Shape (555, 505)\n",
      "X_val Shape (124, 505)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Correlated'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_pipe_transform(dataset,'Original', pipe, models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicated, Quasi Constant & Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Clean\n",
      "# Features before: 657\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('Clean',\n",
      "                 SmartCorrelatedSelection(cv=<__main__.BlockingTimeSeriesSplit object at 0x000002192702F130>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "Clean : 206\n",
      "Total removed: 206\n",
      "\n",
      "Shapes for dataset: Clean\n",
      "X_train Shape (2216, 451)\n",
      "X_test Shape (555, 451)\n",
      "X_val Shape (124, 451)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean'\n",
    "pipe = Pipeline([(dataset, SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_pipe_transform(dataset,'Dupl&QConstant', pipe, models[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean1 - Drop constant, quasi Constant, duplicated and correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Features for dataset: Clean1\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('constant', DropConstantFeatures()),\n",
      "                ('quasiConstant', DropConstantFeatures(tol=0.95)),\n",
      "                ('duplicated', DropDuplicateFeatures(missing_values='raise')),\n",
      "                ('correlation',\n",
      "                 SmartCorrelatedSelection(cv=<__main__.BlockingTimeSeriesSplit object at 0x000002192702F130>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "constant : 46\n",
      "quasiConstant : 11\n",
      "duplicated : 48\n",
      "correlation : 206\n",
      "Total removed: 311\n",
      "\n",
      "Shapes for dataset: Clean1\n",
      "X_train Shape (2216, 451)\n",
      "X_test Shape (555, 451)\n",
      "X_val Shape (124, 451)\n",
      "\n",
      "Removing Features for dataset: Clean1\n",
      "# Features before: 762\n",
      "\n",
      "Removed Features for Pipeline: Pipeline(steps=[('constant', DropConstantFeatures()),\n",
      "                ('quasiConstant', DropConstantFeatures(tol=0.95)),\n",
      "                ('duplicated', DropDuplicateFeatures(missing_values='raise')),\n",
      "                ('correlation',\n",
      "                 SmartCorrelatedSelection(cv=<__main__.BlockingTimeSeriesSplit object at 0x000002192702F130>,\n",
      "                                          estimator=RandomForestClassifier(max_depth=3,\n",
      "                                                                           n_jobs=-1),\n",
      "                                          method='spearman',\n",
      "                                          missing_values='raise',\n",
      "                                          selection_method='variance',\n",
      "                                          threshold=0.95))])\n",
      "constant : 46\n",
      "quasiConstant : 11\n",
      "duplicated : 48\n",
      "correlation : 206\n",
      "Total removed: 311\n",
      "\n",
      "Shapes for dataset: Clean1\n",
      "X_train Shape (2216, 451)\n",
      "X_test Shape (555, 451)\n",
      "X_val Shape (124, 451)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smart_correlation_estimator = models[0]\n",
    "dataset = 'Clean1'\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.95, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.95,missing_values=\"raise\",selection_method=\"variance\",estimator=smart_correlation_estimator,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "apply_pipe_transform(dataset,'Original', pipe ,models[0])\n",
    "apply_pipe_transform(dataset,'Original', pipe ,models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Num_Features</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <th>roc_auc_ovo_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>Constant</th>\n",
       "      <td>716</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuasiConstant</th>\n",
       "      <td>705</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duplicated</th>\n",
       "      <td>677</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dupl&amp;QConstant</th>\n",
       "      <td>657</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated</th>\n",
       "      <td>505</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean</th>\n",
       "      <td>451</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean1</th>\n",
       "      <td>451</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Clean1</th>\n",
       "      <td>451</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Num_Features balanced_accuracy  \\\n",
       "Model                  Dataset                                         \n",
       "RandomForestClassifier Original                762              0.25   \n",
       "XGBClassifier          Original                762              0.25   \n",
       "RandomForestClassifier Constant                716              0.21   \n",
       "                       QuasiConstant           705              0.24   \n",
       "                       Duplicated              677              0.21   \n",
       "                       Dupl&QConstant          657              0.26   \n",
       "                       Correlated              505              0.19   \n",
       "                       Clean                   451              0.25   \n",
       "                       Clean1                  451              0.22   \n",
       "XGBClassifier          Clean1                  451              0.25   \n",
       "\n",
       "                                      precision_weighted recall_weighted  \\\n",
       "Model                  Dataset                                             \n",
       "RandomForestClassifier Original                     0.43             0.3   \n",
       "XGBClassifier          Original                     0.41            0.27   \n",
       "RandomForestClassifier Constant                     0.44            0.34   \n",
       "                       QuasiConstant                0.42            0.34   \n",
       "                       Duplicated                   0.43            0.39   \n",
       "                       Dupl&QConstant               0.48            0.38   \n",
       "                       Correlated                   0.49            0.34   \n",
       "                       Clean                        0.41            0.38   \n",
       "                       Clean1                       0.51            0.41   \n",
       "XGBClassifier          Clean1                       0.27            0.32   \n",
       "\n",
       "                                      f1_weighted roc_auc_ovr_weighted  \\\n",
       "Model                  Dataset                                           \n",
       "RandomForestClassifier Original               0.4                  NaN   \n",
       "XGBClassifier          Original              0.29                  NaN   \n",
       "RandomForestClassifier Constant               0.3                  NaN   \n",
       "                       QuasiConstant          0.3                  NaN   \n",
       "                       Duplicated            0.35                  NaN   \n",
       "                       Dupl&QConstant        0.37                  NaN   \n",
       "                       Correlated            0.39                  NaN   \n",
       "                       Clean                 0.37                  NaN   \n",
       "                       Clean1                0.41                  NaN   \n",
       "XGBClassifier          Clean1                0.27                  NaN   \n",
       "\n",
       "                                      roc_auc_ovo_weighted  \n",
       "Model                  Dataset                              \n",
       "RandomForestClassifier Original                        NaN  \n",
       "XGBClassifier          Original                        NaN  \n",
       "RandomForestClassifier Constant                        NaN  \n",
       "                       QuasiConstant                   NaN  \n",
       "                       Duplicated                      NaN  \n",
       "                       Dupl&QConstant                  NaN  \n",
       "                       Correlated                      NaN  \n",
       "                       Clean                           NaN  \n",
       "                       Clean1                          NaN  \n",
       "XGBClassifier          Clean1                          NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2191e510940>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "rf.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "plot_confusion_matrix(rf, X_test_dict['Clean1'], y_test.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model here since it takes > 1 min\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1,eval_metric='mlogloss')\n",
    "lab = Response.Labels.unique()\n",
    "lab.sort()\n",
    "xgb.fit(X_train_dict['Clean1'], y_train.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4053294748974423, 0.3981981981981982, 0.3969526028621697, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = xgb.predict(X_test_dict['Clean1'])\n",
    "df1 = pd.DataFrame(np.transpose(precision_recall_fscore_support(y_test.Labels, y_pred, average=None)),columns=['precision', 'recall', 'fscore', 'support'], index=lab)\n",
    "# df1 = pd.DataFrame(np.transpose(precision_recall_fscore_support(y_test.Labels, y_pred, average='macro')),index = ['precision', 'recall', 'fscore', 'support'])\n",
    "df1\n",
    "\n",
    "precision_recall_fscore_support(y_test.Labels, y_pred, average='weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "    1. Recall/Sensitivity/TPR: tp / (tp + fn) - **%age of a TRUE/Positives class correctly identified/ ability to find all the positive samples**\n",
    "    2. Specificity (TNR) is tn / (tn + fp) - %age of a FALSE/Negatives class correctly identified\n",
    "    3. False Positive Rate (FPR) = 1 - Specificity or fp / (tn + fp)\n",
    "    4. Accuracy is TP/ entire matrix sum ???\n",
    "    5. Precision is tp / (tp + fp) - the ability not to label a negative sample as positive.\n",
    "    6. Support is the number of occurrences of each class  - sum of respective row\n",
    "    7. Macro - unweighted mean. This does not take label imbalance into account.\n",
    "    8. Wt_Avg - average weighted by support\n",
    "\n",
    "**True/False (Positives/Negatives) means if a sample belongs/doesn't belong to a class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_58756_row0_col0 {\n",
       "  color: green;\n",
       "}\n",
       "#T_58756_row0_col1, #T_58756_row0_col2, #T_58756_row0_col3, #T_58756_row0_col4 {\n",
       "  color: blue;\n",
       "}\n",
       "#T_58756_row1_col0, #T_58756_row2_col0, #T_58756_row3_col0, #T_58756_row4_col0 {\n",
       "  color: orange;\n",
       "}\n",
       "#T_58756_row1_col1, #T_58756_row1_col2, #T_58756_row1_col3, #T_58756_row1_col4, #T_58756_row2_col1, #T_58756_row2_col2, #T_58756_row2_col3, #T_58756_row2_col4, #T_58756_row3_col1, #T_58756_row3_col2, #T_58756_row3_col3, #T_58756_row3_col4, #T_58756_row4_col1, #T_58756_row4_col2, #T_58756_row4_col3, #T_58756_row4_col4 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_58756\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_58756_level0_col0\" class=\"col_heading level0 col0\" colspan=\"5\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_58756_level1_col0\" class=\"col_heading level1 col0\" >-2</th>\n",
       "      <th id=\"T_58756_level1_col1\" class=\"col_heading level1 col1\" >-1</th>\n",
       "      <th id=\"T_58756_level1_col2\" class=\"col_heading level1 col2\" >0</th>\n",
       "      <th id=\"T_58756_level1_col3\" class=\"col_heading level1 col3\" >1</th>\n",
       "      <th id=\"T_58756_level1_col4\" class=\"col_heading level1 col4\" >2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_58756_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"5\">Actual</th>\n",
       "      <th id=\"T_58756_level1_row0\" class=\"row_heading level1 row0\" >-2</th>\n",
       "      <td id=\"T_58756_row0_col0\" class=\"data row0 col0\" >True Positive</td>\n",
       "      <td id=\"T_58756_row0_col1\" class=\"data row0 col1\" >False Negative</td>\n",
       "      <td id=\"T_58756_row0_col2\" class=\"data row0 col2\" >False Negative</td>\n",
       "      <td id=\"T_58756_row0_col3\" class=\"data row0 col3\" >False Negative</td>\n",
       "      <td id=\"T_58756_row0_col4\" class=\"data row0 col4\" >False Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58756_level1_row1\" class=\"row_heading level1 row1\" >-1</th>\n",
       "      <td id=\"T_58756_row1_col0\" class=\"data row1 col0\" >False Positive</td>\n",
       "      <td id=\"T_58756_row1_col1\" class=\"data row1 col1\" >True Negative</td>\n",
       "      <td id=\"T_58756_row1_col2\" class=\"data row1 col2\" >True Negative</td>\n",
       "      <td id=\"T_58756_row1_col3\" class=\"data row1 col3\" >True Negative</td>\n",
       "      <td id=\"T_58756_row1_col4\" class=\"data row1 col4\" >True Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58756_level1_row2\" class=\"row_heading level1 row2\" >0</th>\n",
       "      <td id=\"T_58756_row2_col0\" class=\"data row2 col0\" >False Positive</td>\n",
       "      <td id=\"T_58756_row2_col1\" class=\"data row2 col1\" >True Negative</td>\n",
       "      <td id=\"T_58756_row2_col2\" class=\"data row2 col2\" >True Negative</td>\n",
       "      <td id=\"T_58756_row2_col3\" class=\"data row2 col3\" >True Negative</td>\n",
       "      <td id=\"T_58756_row2_col4\" class=\"data row2 col4\" >True Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58756_level1_row3\" class=\"row_heading level1 row3\" >1</th>\n",
       "      <td id=\"T_58756_row3_col0\" class=\"data row3 col0\" >False Positive</td>\n",
       "      <td id=\"T_58756_row3_col1\" class=\"data row3 col1\" >True Negative</td>\n",
       "      <td id=\"T_58756_row3_col2\" class=\"data row3 col2\" >True Negative</td>\n",
       "      <td id=\"T_58756_row3_col3\" class=\"data row3 col3\" >True Negative</td>\n",
       "      <td id=\"T_58756_row3_col4\" class=\"data row3 col4\" >True Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58756_level1_row4\" class=\"row_heading level1 row4\" >2</th>\n",
       "      <td id=\"T_58756_row4_col0\" class=\"data row4 col0\" >False Positive</td>\n",
       "      <td id=\"T_58756_row4_col1\" class=\"data row4 col1\" >True Negative</td>\n",
       "      <td id=\"T_58756_row4_col2\" class=\"data row4 col2\" >True Negative</td>\n",
       "      <td id=\"T_58756_row4_col3\" class=\"data row4 col3\" >True Negative</td>\n",
       "      <td id=\"T_58756_row4_col4\" class=\"data row4 col4\" >True Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21926f98130>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample_confusion_matrix(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -2, -2, -2, -2, -2,  2, -2,  2, -2,  2, -2,  2,  2,  2,  2,  2,\n",
       "        2,  2, -2, -2, -2, -2, -2, -2,  2, -2, -2, -2,  2, -2,  2,  2,  2,\n",
       "        2,  2,  2,  2, -2,  2, -2, -2, -2, -2,  2,  2, -2,  2, -2,  2, -2,\n",
       "       -2, -2,  2,  2,  2,  2,  2,  2,  2, -2, -2,  2, -2, -2, -2, -2, -2,\n",
       "       -2, -2, -2, -2,  2,  2,  2, -2,  2, -2, -2, -2, -2, -2,  2, -2, -2,\n",
       "        2,  2, -2, -2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, -2, -2,\n",
       "       -2, -2, -2, -2, -2, -2,  2,  2,  2,  2,  2,  2,  2,  2,  2, -2, -2,\n",
       "       -2, -2, -2, -2,  2, -2, -2,  2, -2, -2, -2, -2, -2, -2,  2,  2, -2,\n",
       "       -2,  2,  2,  2,  2, -2, -2,  2,  2,  2,  2,  2, -2, -2, -2, -2, -2,\n",
       "       -2, -2, -2, -2, -2,  2,  2,  2, -2,  2, -2,  2, -2, -2, -2, -2, -2,\n",
       "       -2, -2,  2,  2, -2,  2, -2, -2, -2,  2, -2,  2, -2,  2,  2, -2, -2,\n",
       "        2,  2,  2, -2,  2,  2,  2, -2, -2, -2,  2, -2, -2, -2, -2,  2,  2,\n",
       "        2,  2, -2, -2,  2,  2,  2,  2,  2,  2, -2,  2,  2,  2,  2,  2,  2,\n",
       "        2, -2,  2,  2,  2, -2,  2,  2,  2,  2,  2, -2, -2, -2, -2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2,\n",
       "       -2, -2, -2, -2, -2, -2, -2, -2,  2,  2,  2, -2, -2, -2, -2, -2, -2,\n",
       "       -2, -2, -2, -2,  2,  2, -2, -2, -2, -2,  2, -2,  2,  2, -2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2, -2,  2,  2, -2, -2, -2,  2, -2, -2, -2, -2,\n",
       "       -2,  2,  2,  2, -2,  2, -2,  2,  2,  2, -2,  2, -2, -2,  2,  2,  2,\n",
       "        2,  2, -2, -2, -2,  2, -2, -2, -2,  2,  2, -2,  2,  2,  2,  2, -2,\n",
       "       -2,  2, -2,  2,  2, -2,  2, -2, -2, -2, -2, -2, -2, -2, -2,  2, -2,\n",
       "       -2, -2, -2, -2, -2,  2,  2,  2, -2, -2,  2, -2, -2, -2, -2,  2, -2,\n",
       "       -2,  2, -2,  2,  2,  2, -2,  2,  2,  2,  2, -2,  2,  2,  2,  2, -2,\n",
       "       -2, -2,  2,  2,  2, -2,  2,  2, -2,  2,  2,  2, -2, -2,  2,  2,  2,\n",
       "        2,  2,  2,  2, -2, -2, -2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "       -2, -2, -2,  2,  2, -2,  2, -2,  2,  2,  2,  2, -2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2, -2, -2, -2, -2, -2, -2,  2,  2,  2, -2, -2, -2,\n",
       "       -2, -2, -2, -2, -2,  2, -2, -2,  2, -2, -2, -2, -2,  2,  2,  2,  2,\n",
       "       -2,  2,  2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2,  2, -2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2, -2, -2, -2, -2, -2, -2, -2, -2,\n",
       "       -2, -2, -2, -2,  2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2,\n",
       "       -2, -2,  2,  2,  2, -2, -2, -2, -2, -2, -2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "model = models[0]\n",
    "model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "y_pred = model.predict(X_test_dict['Clean1'])\n",
    "\n",
    "# y_pred = cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv=5)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2216,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model here since takes ~ 1.30 minute\n",
    "# model = models[1]\n",
    "# model.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# y_pred = model.predict(X_test_dict['Clean1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2</th>\n",
       "      <td>44%</td>\n",
       "      <td>65%</td>\n",
       "      <td>52%</td>\n",
       "      <td>56%</td>\n",
       "      <td>44%</td>\n",
       "      <td>23%</td>\n",
       "      <td>125.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47%</td>\n",
       "      <td>62%</td>\n",
       "      <td>54%</td>\n",
       "      <td>59%</td>\n",
       "      <td>41%</td>\n",
       "      <td>23%</td>\n",
       "      <td>127.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>18%</td>\n",
       "      <td>25%</td>\n",
       "      <td>21%</td>\n",
       "      <td>83%</td>\n",
       "      <td>17%</td>\n",
       "      <td>9%</td>\n",
       "      <td>50.4</td>\n",
       "      <td>383.4</td>\n",
       "      <td>60.6</td>\n",
       "      <td>60.6</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wt_Avg</th>\n",
       "      <td>30%</td>\n",
       "      <td>42%</td>\n",
       "      <td>35%</td>\n",
       "      <td>72%</td>\n",
       "      <td>28%</td>\n",
       "      <td>15%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision recall fscore specificity  fpr accuracy     tp     tn     fp  \\\n",
       "-2           44%    65%    52%         56%  44%      23%  125.0  202.0  160.0   \n",
       "-1            0%     0%     0%        100%   0%       0%    0.0  496.0    0.0   \n",
       "0             0%     0%     0%        100%   0%       0%    0.0  516.0    0.0   \n",
       "1             0%     0%     0%        100%   0%       0%    0.0  495.0    0.0   \n",
       "2            47%    62%    54%         59%  41%      23%  127.0  208.0  143.0   \n",
       "macro        18%    25%    21%         83%  17%       9%   50.4  383.4   60.6   \n",
       "Wt_Avg       30%    42%    35%         72%  28%      15%    NaN    NaN    NaN   \n",
       "\n",
       "          fn  support  \n",
       "-2      68.0    193.0  \n",
       "-1      59.0     59.0  \n",
       "0       39.0     39.0  \n",
       "1       60.0     60.0  \n",
       "2       77.0    204.0  \n",
       "macro   60.6    111.0  \n",
       "Wt_Avg   NaN      NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lab = Response.Labels.unique()\n",
    "lab.sort()\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test.Labels, y_pred))\n",
    "cm.index = lab\n",
    "cm.columns = lab\n",
    "df = pd.DataFrame()\n",
    "pre = {}\n",
    "rec = {}\n",
    "tp = {}\n",
    "tn = {}\n",
    "fp = {}\n",
    "fn = {}\n",
    "weighted_average = {}\n",
    "for cat in lab:\n",
    "    pre[cat] = np.nan_to_num(cm.loc[cat,cat]/cm.sum(axis=0).loc[cat], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    rec[cat] = np.nan_to_num(cm.loc[cat,cat]/cm.sum(axis=1).loc[cat], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    tp[cat] = cm.loc[cat, cat]\n",
    "    tn[cat] = cm.drop(cat,axis=1).drop(cat,axis=0).sum().sum()\n",
    "    fp[cat] = cm[cat].drop(cat).sum()\n",
    "    fn[cat] = cm.loc[cat].drop(cat).sum()\n",
    "\n",
    "df = pd.concat([pd.DataFrame.from_dict(pre,orient='index', columns=['precision']),pd.DataFrame.from_dict(rec,orient='index', columns=['recall'])], axis=1)\n",
    "df['fscore'] = (2 * (df.precision * df.recall) / (df.precision + df.recall)).fillna(0)\n",
    "df['tp'] = pd.Series(tp)\n",
    "df['tn'] = pd.Series(tn)\n",
    "df['fp'] = pd.Series(fp)\n",
    "df['fn'] = pd.Series(fn)\n",
    "\n",
    "df['specificity'] =  pd.Series(df.tn / (df.tn + df.fp))\n",
    "df['fpr'] = pd.Series(df.fp / (df.tn + df.fp))\n",
    "df['accuracy'] = (df.tp) / (df.tp + df.tn + df.fp + df.fn)\n",
    "df['support'] = cm.sum(axis=1)\n",
    "\n",
    "main_metrics_list = ['precision', 'recall', 'fscore', 'specificity','fpr', 'accuracy']\n",
    "df_perc = df[main_metrics_list]\n",
    "df = pd.concat([df_perc,df.tp,df.tn,df.fp,df.fn,df.support], axis=1)\n",
    "\n",
    "df.loc['macro'] = df.mean()\n",
    "\n",
    "# Weighted average\n",
    "for cols in df.columns:\n",
    "    if cols in main_metrics_list:\n",
    "        weighted_average[cols] = df[cols].dot(df.support)/df.support.sum()\n",
    "    else:\n",
    "        weighted_average[cols] = None\n",
    "\n",
    "weight_df = pd.DataFrame.from_dict(weighted_average,orient='index', columns=['Wt_Avg']).T\n",
    "df = pd.concat([df, weight_df], axis=0)\n",
    "\n",
    "# % Formatting\n",
    "for col in main_metrics_list:\n",
    "    try:\n",
    "        df[col] = df[col].mul(100).round(0).astype(int).astype(str).add('%')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Num_Features</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <th>roc_auc_ovo_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Original</th>\n",
       "      <td>762</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">RandomForestClassifier</th>\n",
       "      <th>Constant</th>\n",
       "      <td>716</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuasiConstant</th>\n",
       "      <td>705</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duplicated</th>\n",
       "      <td>677</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dupl&amp;QConstant</th>\n",
       "      <td>657</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated</th>\n",
       "      <td>505</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean</th>\n",
       "      <td>451</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean1</th>\n",
       "      <td>451</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>Clean1</th>\n",
       "      <td>451</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Num_Features balanced_accuracy  \\\n",
       "Model                  Dataset                                         \n",
       "RandomForestClassifier Original                762              0.25   \n",
       "XGBClassifier          Original                762              0.25   \n",
       "RandomForestClassifier Constant                716              0.21   \n",
       "                       QuasiConstant           705              0.24   \n",
       "                       Duplicated              677              0.21   \n",
       "                       Dupl&QConstant          657              0.26   \n",
       "                       Correlated              505              0.19   \n",
       "                       Clean                   451              0.25   \n",
       "                       Clean1                  451              0.22   \n",
       "XGBClassifier          Clean1                  451              0.25   \n",
       "\n",
       "                                      precision_weighted recall_weighted  \\\n",
       "Model                  Dataset                                             \n",
       "RandomForestClassifier Original                     0.43             0.3   \n",
       "XGBClassifier          Original                     0.41            0.27   \n",
       "RandomForestClassifier Constant                     0.44            0.34   \n",
       "                       QuasiConstant                0.42            0.34   \n",
       "                       Duplicated                   0.43            0.39   \n",
       "                       Dupl&QConstant               0.48            0.38   \n",
       "                       Correlated                   0.49            0.34   \n",
       "                       Clean                        0.41            0.38   \n",
       "                       Clean1                       0.51            0.41   \n",
       "XGBClassifier          Clean1                       0.27            0.32   \n",
       "\n",
       "                                      f1_weighted roc_auc_ovr_weighted  \\\n",
       "Model                  Dataset                                           \n",
       "RandomForestClassifier Original               0.4                  NaN   \n",
       "XGBClassifier          Original              0.29                  NaN   \n",
       "RandomForestClassifier Constant               0.3                  NaN   \n",
       "                       QuasiConstant          0.3                  NaN   \n",
       "                       Duplicated            0.35                  NaN   \n",
       "                       Dupl&QConstant        0.37                  NaN   \n",
       "                       Correlated            0.39                  NaN   \n",
       "                       Clean                 0.37                  NaN   \n",
       "                       Clean1                0.41                  NaN   \n",
       "XGBClassifier          Clean1                0.27                  NaN   \n",
       "\n",
       "                                      roc_auc_ovo_weighted  \n",
       "Model                  Dataset                              \n",
       "RandomForestClassifier Original                        NaN  \n",
       "XGBClassifier          Original                        NaN  \n",
       "RandomForestClassifier Constant                        NaN  \n",
       "                       QuasiConstant                   NaN  \n",
       "                       Duplicated                      NaN  \n",
       "                       Dupl&QConstant                  NaN  \n",
       "                       Correlated                      NaN  \n",
       "                       Clean                           NaN  \n",
       "                       Clean1                          NaN  \n",
       "XGBClassifier          Clean1                          NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['Model_Details','Features_List','Removed_Features'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_test.Labels, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fscore.dot(df.support)/df.support.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X_test_dict['Clean1'], y_test.Labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the dataframe in a cell in features_df\n",
    "features_df['to_delete'] = None\n",
    "features_df['to_delete'].astype(object)\n",
    "features_df.loc[('RandomForestClassifier','Original'),'to_delete'] =  [df]\n",
    "features_df.loc[('RandomForestClassifier','Original'),'to_delete'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted averaged\n",
    "# for col in df.columns[:-1]:\n",
    "#     print(df[col].values.dot(df.support)/df.support.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "# rf.fit(X_train_dict['Clean1'], y_train.Labels, eval_metric='mlogloss')\n",
    "# rf.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# plot_confusion_matrix(rf, X_test_dict['Clean1'], y_test.Labels,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# xgb_m = xgb.XGBClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "# rf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "\n",
    "# xgb_m.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# rf.fit(X_train_dict['Clean1'], y_train.Labels)\n",
    "# y_pred = rf.predict(X_test_dict['Clean1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test.Labels, y_pred)\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection Methods - Mostly just examine linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "# Plot\n",
    "# mi.plot.bar(figsize=(20, 6))\n",
    "# plt.ylabel('Mutual Information')\n",
    "\n",
    "# select features\n",
    "sel_ = SelectKBest(mutual_info_classif, k=15).fit(X_train, y_train)\n",
    "\n",
    "# display features\n",
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-square Statistic - only suited for classification!                                         \n",
    "https://www.udemy.com/course/feature-selection-for-machine-learning/learn/lecture/22495182#questions\n",
    "https://github.com/solegalli/feature-selection-for-machine-learning/blob/main/05-Filter-Statistical-Tests/05.2-Fisher-score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the chi2 p_value between each of the variables and the target\n",
    "# chi2 returns 2 arrays, one contains the F-Scores which are then evaluated against the chi2 distribution to obtain the pvalue. The pvalues are in the second array\n",
    "\n",
    "# Input X must be non-negative\n",
    "X_train_non_negative = X_train[X_train.columns[((X_train < 0).sum(axis=0) == 0).values]]\n",
    "f_score = chi2(X_train_non_negative.fillna(0), y_train)\n",
    "pvalues = pd.Series(f_score[1])\n",
    "pvalues.index = X_train_non_negative.columns\n",
    "pvalues.sort_values(ascending=True, inplace = True)\n",
    "extremely_low_p_values = len(pvalues[pvalues < 1e-100])\n",
    "sel_ = SelectKBest(chi2, k= extremely_low_p_values).fit(X_train_non_negative, y_train)\n",
    "X_train_non_negative.columns[sel_.get_support()] # display features\n",
    "\n",
    "# X_train = sel_.transform(X_train)\n",
    "# X_test = sel_.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anova - tests 2 samples have same mean\n",
    "\n",
    "Assumptions:\n",
    "Sample are independant & normally distributed, homegeneity of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the univariate statistical measure between each of the variables and the target\n",
    "# similarly to chi2, the output is one array with f-scores and one array with the pvalues\n",
    "\n",
    "univariate = f_classif(X_train, y_train)\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=True, inplace = True) # The smaller the p_value the more predictive the feature is\n",
    "\n",
    "pvalue_above_5_percent = len(univariate[univariate < 0.05])\n",
    "sel_ = SelectKBest(f_classif, k=pvalue_above_5_percent).fit(X_train, y_train)\n",
    "features_to_keep = sel_.get_feature_names_out()\n",
    "features_to_keep\n",
    "\n",
    "# select features\n",
    "# X_train_anova = sel_.transform(X_train)\n",
    "# X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# # numpy array to dataframe\n",
    "# X_train_anova = pd.DataFrame(X_train_anova)\n",
    "# X_train_anova.columns = features_to_keep\n",
    "\n",
    "# X_test_anova = pd.DataFrame(X_test_anova)\n",
    "# X_test_anova.columns = features_to_keep\n",
    "\n",
    "# X_train_anova.shape, X_test_anova.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects features whose importance is greater than the threshold. - Thershold is the mean importance of all features\n",
    "sel_ = SelectFromModel(RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "TopNFeatures = pd.DataFrame(index = sel_.estimator_.feature_names_in_.tolist(),data = sel_.estimator_.feature_importances_, columns = ['Imp']).sort_values(by='Imp',ascending=False).head(20).index.tolist()\n",
    "pd.Series(sel_.estimator_.feature_importances_.ravel()).hist(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopNFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods | Tree Importance Recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1:44 mins to run\n",
    "sel_ = RFE(RandomForestClassifier(n_estimators=100,  max_depth=3, n_jobs=-1), n_features_to_select=30).fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sel_.get_support()]\n",
    "print(len(selected_features))\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, n_jobs=-1)\n",
    "rf.fit(X_train[selected_features].fillna(0), y_train)\n",
    "y_pred = rf.predict(X_test[selected_features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[selected_features].fillna(0))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val.fillna(0), y_valid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set')\n",
    "pred = rf.predict_proba(X_train[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "print('Test set')\n",
    "pred = rf.predict_proba(X_test[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "print('Validation set')\n",
    "pred = rf.predict_proba(X_val[selected_features])\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_val, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Random Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 1 min to run - You can use this procedure with any machine learning algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=2, n_jobs=-1)\n",
    "\n",
    "sel = SelectByShuffling(\n",
    "    variables=None, # automatically examine all numerical variables\n",
    "    estimator=rf, # the ML model\n",
    "    scoring='roc_auc', # the metric to evaluate\n",
    "    threshold=0,# the maximum performance drop allowed to select the feature\n",
    "    cv=btscv, # cross validation\n",
    ")\n",
    "\n",
    "sel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_ # performance of model trained with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(sel.performance_drifts_).sort_values(ascending=False).plot.bar(figsize=(16,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that will be removed\n",
    "\n",
    "print(len(sel.features_to_drop_))\n",
    "# remove features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "X_val = sel.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print( 'train auc score: ',roc_auc_score(y_train, (rf.predict_proba(X_train))[:,1]))\n",
    "print('test auc score: ', roc_auc_score(y_test, (rf.predict_proba(X_test))[:, 1]))\n",
    "print('Validation auc score: ', roc_auc_score(y_val, (rf.predict_proba(X_val))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "\n",
    "sel = RecursiveFeatureElimination(\n",
    "    variables=None, # automatically evaluate all numerical variables\n",
    "    estimator = model, # the ML model\n",
    "    scoring = 'roc_auc', # the metric we want to evalute\n",
    "    threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "    cv=btscv, # cross-validation\n",
    ")\n",
    "\n",
    "# this may take quite a while, because\n",
    "# we are building a lot of models with cross-validation\n",
    "# sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of model trained using all features\n",
    "sel.initial_model_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of all features based of initial model\n",
    "sel.feature_importances_.plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sel.performance_drifts_).plot.bar(figsize=(20,6))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Performance change when feature was added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features that will be removed\n",
    "\n",
    "len(sel.features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "y_pred = rf.predict(X_test[features].fillna(0))\n",
    "y_valid_pred = rf.predict(X_val[features].fillna(0))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test.fillna(0), y_pred))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val .fillna(0), y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance in machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_basic_filter.shape, X_test_basic_filter.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300,  max_depth=3, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter methods - basic\n",
    "run_randomForests(X_train_basic_filter,X_test_basic_filter,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression and compare performance in train and test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "run_logistic(scaler.transform(X_train),\n",
    "             scaler.transform(X_test),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<div style=\"color: DarkBlue; font-size:22px;\" class=\"alert alert-block alert-warning\"> \n",
    "<b>Pipelines:</b> Final Code will look like this but for now work through issues above \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=1, variables=None, missing_values='raise')),\n",
    "    ('quasiConstant', DropConstantFeatures(tol=0.9, variables=None, missing_values='raise')),\n",
    "    ('duplicated', DropDuplicateFeatures(variables=None, missing_values='raise')),\n",
    "    ('correlation', SmartCorrelatedSelection(variables=None, method=\"spearman\",threshold=0.9,missing_values=\"raise\",selection_method=\"variance\",estimator=rf,scoring=\"roc_auc\",cv=btscv,)),])\n",
    "\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# remove features\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)\n",
    "X_val = pipe.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pipe.named_steps['constant'].features_to_drop_))\n",
    "pipe.named_steps['duplicated'].features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT USING - for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Brute Force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        \n",
    "        for j in range(i):\n",
    "            \n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "             \n",
    "                print(abs(corr_matrix.iloc[i, j]),\":\", corr_matrix.columns[i], \"<< - >>\", corr_matrix.columns[j])\n",
    "                colname = corr_matrix.columns[j]\n",
    "                \n",
    "                # and add it to our correlated set\n",
    "                col_corr.add(colname)\n",
    "                \n",
    "    return col_corr\n",
    "\n",
    "# corr_features = correlation(X_train, 0.9)\n",
    "# len(set(corr_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_features = correlation(X_train, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Features - Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.9]\n",
    "corrmat = corrmat[corrmat < 1] # Not Interested in the correlation with 1 since will be with the same variable\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    \n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group in correlated_groups:\n",
    "#     print(group)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Group Index\n",
    "group_index = 1\n",
    "\n",
    "group = correlated_groups[group_index]\n",
    "var = group.feature1.unique()[0]\n",
    "\n",
    "# add all features of the group to a list\n",
    "features = list(group['feature2'].unique())+[var]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), y_train)\n",
    "\n",
    "importance = pd.concat([pd.Series(features),pd.Series(rf.feature_importances_)], axis=1)\n",
    "importance.columns = ['feature', 'importance']\n",
    "\n",
    "print(var)\n",
    "importance.sort_values(by='importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in group['feature2']:\n",
    "#     plt.scatter(X_train[var], X_train[feature])\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.ylabel(var)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just an example to show one group of how smart correlation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "group = sel.correlated_feature_sets_[0]\n",
    "\n",
    "# build random forest with cross validation for each feature\n",
    "for f in group:\n",
    "    \n",
    "    model = cross_validate(\n",
    "        rf,\n",
    "        X_train[f].to_frame(),\n",
    "        y_train,\n",
    "        cv=btscv,\n",
    "        return_estimator=False,\n",
    "        scoring='accuracy',\n",
    "    )\n",
    "\n",
    "#  scoring='roc_auc' does not support categorical data.\n",
    "\n",
    "    print(f, model[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****TO USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)\n",
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n",
    "\n",
    "y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);\n",
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation metrics\n",
    "1. cross_val_score\n",
    "2. Area under the ROC Curve\n",
    "3. Confusion Matrix\n",
    "4. Confusion Report\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "cross_val_score(model, Variables, Response.Close_Up_Down, cv = 2, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Original'], y_train.Labels, cv = 5,scoring='roc_auc_ovo_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1)\n",
    "cross_val_score(model, X_train_dict['Clean1'], y_train.Labels, cv = 5,scoring='roc_auc_ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "y_prob = model.predict_proba(X_test_dict['Original'])\n",
    "y_pred = model.predict(X_test_dict['Original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Original'], y_train.Close_Up_Down)\n",
    "\n",
    "for p in [0.475,0.5,0.525]:\n",
    "    \n",
    "    y_pred = (clf.predict_proba(X_test_dict['Original'])[:,1] >= p).astype(bool) # set threshold as 0.3\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_pred,)\n",
    "    print(\"tpr:\",tpr)\n",
    "    print(\"fpr:\",fpr)\n",
    "    print(\"threshold:\",threshold)\n",
    "    print(p,\": \",roc_auc_score(y_test.Close_Up_Down, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/45715018/scikit-learn-how-to-plot-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "clf.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "plt.figure(figsize=(12,5))\n",
    "prediction = clf.predict_proba(X_test_dict['Clean'])[:,1]\n",
    "plt.hist(prediction[y_test.Close_Up_Down==-1], bins=100, label='Negatives')\n",
    "plt.hist(prediction[y_test.Close_Up_Down==1], bins=100, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Probability of being Positive Class', fontsize=10)\n",
    "plt.ylabel('Number of records in each bucket', fontsize=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=25, pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(y_test, model_set, model):\n",
    "    model.fit(X_train_dict[model_set], y_train.Close_Up_Down)\n",
    "    y_prob_positive = model.predict_proba(X_test_dict[model_set])[:,1]\n",
    "    print(f\"ROC_AUC_SCORE: {roc_auc_score(y_test.Close_Up_Down, y_prob_positive):.2f}%\")\n",
    "    fpr, tpr, threshold = roc_curve(y_test.Close_Up_Down, y_prob_positive,)\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "\n",
    "plot_roc_auc_curve(y_test, 'Original', model)\n",
    "# plot_roc_auc_curve(y_test, 'Original', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred == [-1 if x[0] > 0.5 else 1 for x in y_prob]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took 5:20 mins\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "# cross_val_score(model, Variables, Response.Close_Up_Down, cv = 5).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "model.fit(X_train_dict['Clean'], y_train.Close_Up_Down)\n",
    "y_pred = model.predict(X_test_dict['Clean'])\n",
    "confusion_matrix(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "conf_mat = confusion_matrix(y_test.Close_Up_Down, y_pred)\n",
    "sns.heatmap(pd.crosstab(y_test.Close_Up_Down, y_pred, rownames=['Actual'], colnames=['Predicted']), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues');\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test_dict['Clean'], y_test.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_val_dict['Clean'], y_val.Close_Up_Down,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report = classification_report(y_test.Close_Up_Down, y_pred, output_dict=True)\n",
    "pd.DataFrame(clsf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.Close_Up_Down, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf_report['-1.0']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, det_curve\n",
    "precision_score(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, fnr_, thresholds_ = det_curve(y_test.Close_Up_Down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76ed5d48e058170b27340c105dd5e7527dd13aa6b3ab779e1e670a0e63feffe0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
